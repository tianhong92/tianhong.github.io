{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/dxx/source/css/monosocialiconsfont.css","path":"css/monosocialiconsfont.css","modified":0,"renderable":1},{"_id":"themes/dxx/source/css/font-awesome.min.css","path":"css/font-awesome.min.css","modified":0,"renderable":1},{"_id":"themes/dxx/source/css/highlight.css","path":"css/highlight.css","modified":0,"renderable":1},{"_id":"themes/dxx/source/css/highlight.min.css","path":"css/highlight.min.css","modified":0,"renderable":1},{"_id":"themes/dxx/source/css/monosocialiconsfont.min.css","path":"css/monosocialiconsfont.min.css","modified":0,"renderable":1},{"_id":"themes/dxx/source/css/style.css","path":"css/style.css","modified":0,"renderable":1},{"_id":"themes/dxx/source/css/style.min.css","path":"css/style.min.css","modified":0,"renderable":1},{"_id":"themes/dxx/source/fonts/MonoSocialIconsFont-1.10.woff","path":"fonts/MonoSocialIconsFont-1.10.woff","modified":0,"renderable":1},{"_id":"themes/dxx/source/fonts/icons.svg","path":"fonts/icons.svg","modified":0,"renderable":1},{"_id":"themes/dxx/source/fonts/icons.ttf","path":"fonts/icons.ttf","modified":0,"renderable":1},{"_id":"themes/dxx/source/fonts/icons.woff","path":"fonts/icons.woff","modified":0,"renderable":1},{"_id":"themes/dxx/source/images/avatar.png","path":"images/avatar.png","modified":0,"renderable":1},{"_id":"themes/dxx/source/js/index.js","path":"js/index.js","modified":0,"renderable":1},{"_id":"themes/dxx/source/images/avatar@2x.png","path":"images/avatar@2x.png","modified":0,"renderable":1},{"_id":"themes/dxx/source/js/main.js","path":"js/main.js","modified":0,"renderable":1},{"_id":"themes/dxx/source/js/jquery.tagcloud.js","path":"js/jquery.tagcloud.js","modified":0,"renderable":1},{"_id":"themes/dxx/source/fonts/fontawesome-webfont.woff","path":"fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/dxx/source/fonts/fontawesome-webfont.woff2","path":"fonts/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/dxx/source/js/jquery-3.3.1.min.js","path":"js/jquery-3.3.1.min.js","modified":0,"renderable":1},{"_id":"themes/dxx/source/fonts/FontAwesome.otf","path":"fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/dxx/source/fonts/MonoSocialIconsFont-1.10.eot","path":"fonts/MonoSocialIconsFont-1.10.eot","modified":0,"renderable":1},{"_id":"themes/dxx/source/fonts/MonoSocialIconsFont-1.10.ttf","path":"fonts/MonoSocialIconsFont-1.10.ttf","modified":0,"renderable":1},{"_id":"themes/dxx/source/fonts/fontawesome-webfont.eot","path":"fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/dxx/source/fonts/fontawesome-webfont.ttf","path":"fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/dxx/source/fonts/MonoSocialIconsFont-1.10.svg","path":"fonts/MonoSocialIconsFont-1.10.svg","modified":0,"renderable":1},{"_id":"themes/dxx/source/fonts/MonoSocialIconsFont-1.10.otf","path":"fonts/MonoSocialIconsFont-1.10.otf","modified":0,"renderable":1},{"_id":"themes/dxx/source/fonts/fontawesome-webfont.svg","path":"fonts/fontawesome-webfont.svg","modified":0,"renderable":1},{"_id":"themes/dxx/source/js/highlight.min.js","path":"js/highlight.min.js","modified":0,"renderable":1}],"Cache":[{"_id":"source/.DS_Store","hash":"0ff99d46346a84f0e50bdef0e035befbeb3fd68a","modified":1535594310000},{"_id":"themes/dxx/README.md","hash":"76eed282b75fe4193d6847ec5f2ce7beab4946c5","modified":1534750796000},{"_id":"themes/dxx/LICENSE","hash":"507fb070f13c541d64433731f6ca891007303fc1","modified":1534750796000},{"_id":"themes/dxx/_config.yml","hash":"ba99958e41dc7a6189afbc468ad4ad5c2478d6a2","modified":1534757848000},{"_id":"themes/dxx/package.json","hash":"745dc4aedaf5eb9ac28b32ad5e49f4099434dec2","modified":1534750796000},{"_id":"source/_posts/HashMap和ConcurrentHashMap.md","hash":"25c3fbfc904a02651f88b7593d001bdf9cfde5da","modified":1538980366000},{"_id":"source/_posts/.DS_Store","hash":"e2bcd795c43dc84c8aa7e4bc4442da99a859663e","modified":1535595448000},{"_id":"source/_posts/Kafka学习笔记.md","hash":"0e5ff5c2609e645a9b7517b4dde756b9620d5536","modified":1538980366000},{"_id":"source/_posts/Hexo-blog-framework.md","hash":"5ea647d28e275911fbd7747bdd0093902c2da863","modified":1535855836000},{"_id":"source/_posts/monit报警邮件配置避坑.md","hash":"556878ded5d6df8abf95c366ad75331026c05899","modified":1542109806000},{"_id":"source/_posts/JUC-ForkJoin-BlockingQueue.md","hash":"6c8bbbf3951a41c67aae4bd8f43c80b23cc58a1a","modified":1538633417000},{"_id":"source/_posts/ss配置.md","hash":"94a0bba44b29108613ab5e37bfd34203d59c46bb","modified":1536645957000},{"_id":"source/_posts/不可变对象.md","hash":"c4fc83ad1188b53c140e2649c5631e838f2167a7","modified":1536416140000},{"_id":"source/_posts/安全发布对象.md","hash":"1ef3a7b03844156c9ee15850d2bf5ef8b70ba90f","modified":1536416140000},{"_id":"source/_posts/数据库切库分库分表.md","hash":"27b18048c2479560831f80be5eaac7f9959e96de","modified":1542109806000},{"_id":"source/_posts/并发基本概念.md","hash":"216c64d8187fa2ddd92ee4cedcd40a168a30cb96","modified":1536416140000},{"_id":"source/_posts/并发模拟.md","hash":"a6899840165283377b255ac41f35478d89bc1115","modified":1535694570000},{"_id":"source/_posts/数据结构-集合和映射.md","hash":"594c0fd350ea992961b5f8331ed3fe9c08499b49","modified":1536423160000},{"_id":"source/_posts/线程不安全类与写法.md","hash":"937ecf78b2a660c886dcfaaf74adc8aefb842ec2","modified":1536416140000},{"_id":"source/_posts/线程安全-同步容器.md","hash":"b43a9c693bf824e2f7865c68976f745f3094d36e","modified":1536416140000},{"_id":"source/_posts/线程安全-并发容器JUC.md","hash":"bbe884f63fd6fa3f6df612a30a09190d7a3d639a","modified":1538659101000},{"_id":"source/_posts/线程安全性-原子性.md","hash":"4f070960769a51e15f65b60515248b00283ec0c2","modified":1535896379000},{"_id":"source/_posts/线程安全性-有序性.md","hash":"a79a0960fe975a5d9f2096bac7e835b7b918ee70","modified":1538980366000},{"_id":"source/_posts/线程安全性-可见性.md","hash":"59883bc422927492923787eaf0fb602d74aa6e35","modified":1535855198000},{"_id":"source/_posts/线程封闭.md","hash":"1a4d3362e5bdeecb8e181ed5291b028e50fc05f2","modified":1536416140000},{"_id":"source/_posts/线程池.md","hash":"22eae2e857daa0adcea7b1bdf5109e94aa06fde9","modified":1538659098000},{"_id":"source/_posts/缓存学习笔记.md","hash":"81499a69b042123cbe988000114102c3ffe989b8","modified":1542109806000},{"_id":"themes/dxx/layout/archive.pug","hash":"a847b51ac26b4828f57299becbc6b8b4fdb8ffa0","modified":1534750796000},{"_id":"themes/dxx/layout/index.pug","hash":"30d4396269ab0aeddd48bde74fe16e9d0c815d9c","modified":1534750796000},{"_id":"themes/dxx/layout/post.pug","hash":"c8d7f926add037a9f9f7b6b3bda23db361f604ba","modified":1534750796000},{"_id":"source/_posts/monit报警邮件配置避坑/stmp.png","hash":"d2dea2a1d6f9003d12b1240319a1d2a193c28347","modified":1542109806000},{"_id":"source/_posts/Hexo-blog-framework/github_config.png","hash":"3914dcd0557322845e5ab5e45660d14910201441","modified":1535685196000},{"_id":"source/_posts/并发基本概念/.DS_Store","hash":"2a0446865415b3ff621504e36526e6802783bfb9","modified":1535618604000},{"_id":"source/_posts/并发基本概念/MESI_protocal.jpg","hash":"e2f43a4ddffb607d6edfd8cbbfef04697dc17345","modified":1535531723000},{"_id":"source/_posts/缓存学习笔记/GuavaCache.png","hash":"70c39d4bb3dbbf7fcec822b68f31e103c63f1f80","modified":1542109806000},{"_id":"themes/dxx/layout/includes/after_footer.pug","hash":"8bbfffea7787ad51b9a81ef0cea81805556978ea","modified":1534750796000},{"_id":"themes/dxx/layout/includes/comment.pug","hash":"00ce36b299134870d9225ef6d91271d41f92f79e","modified":1534750796000},{"_id":"themes/dxx/layout/includes/disqus.pug","hash":"03fdca9127b7a4f8a1fe298331077f0f158f9f8c","modified":1534750796000},{"_id":"themes/dxx/layout/includes/footer.pug","hash":"6935250e9acfc633172207cfcf813e80b14eb243","modified":1534755044000},{"_id":"themes/dxx/layout/includes/googleAnalytics.pug","hash":"8f827dd7505012c17b98c029a476aa2c152a1e22","modified":1534750796000},{"_id":"themes/dxx/layout/includes/head.pug","hash":"6834384bbf1c8e6d6f353896cc5cd58add7a2480","modified":1534762946000},{"_id":"themes/dxx/layout/includes/layout.pug","hash":"69c4a54f06787b4d2776458bb88b4326ee15c0ce","modified":1534750796000},{"_id":"themes/dxx/layout/includes/nav.pug","hash":"57a681c15da4fd40ae564da7301964c11b82122b","modified":1534750796000},{"_id":"themes/dxx/layout/includes/profile.pug","hash":"4320981f954bcecb2da0368f1274585914956f75","modified":1534762939000},{"_id":"themes/dxx/source/css/monosocialiconsfont.css","hash":"83154fcbf731bccdb247824dc540d804044c3f5b","modified":1534750796000},{"_id":"themes/dxx/source/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1534750796000},{"_id":"themes/dxx/source/css/highlight.css","hash":"1afe807bfb7d7ed2568e8637bd10352c9a13f358","modified":1534750796000},{"_id":"themes/dxx/source/css/highlight.min.css","hash":"afb4f1d3e8917b812e013034470f444491b47bd9","modified":1534750796000},{"_id":"themes/dxx/source/css/monosocialiconsfont.min.css","hash":"d2818e282e540257dffdbbf997fa272c30541507","modified":1534750796000},{"_id":"themes/dxx/source/css/style.css","hash":"0695e19c635d08dfd02c4f3a5eaa14b05457cbd2","modified":1534750796000},{"_id":"themes/dxx/source/css/style.min.css","hash":"d95762020cc919367de30bc559e8fd005d3c8a0d","modified":1534750796000},{"_id":"themes/dxx/source/fonts/MonoSocialIconsFont-1.10.woff","hash":"8755dcf98f0896705d8f84cd9746407c67065727","modified":1534750796000},{"_id":"themes/dxx/source/fonts/icons.svg","hash":"4b05214485b496cf7ca5e1059fa5009b5584c0c1","modified":1534750796000},{"_id":"themes/dxx/source/fonts/icons.ttf","hash":"b78addb6c6c3275c5c62369279e908e2bf03e76b","modified":1534750796000},{"_id":"themes/dxx/source/fonts/icons.woff","hash":"fb24eafcd20cfff29a8d6c59d1ce6c8b2c6456d1","modified":1534750796000},{"_id":"themes/dxx/source/images/avatar.png","hash":"4709534d1b796240bf76d0b93a3fdd681b53fdbe","modified":1534750796000},{"_id":"themes/dxx/source/js/index.js","hash":"23ec645f7c823d565003d803f6e8b13b193f716f","modified":1534750796000},{"_id":"themes/dxx/source/images/avatar@2x.png","hash":"4709534d1b796240bf76d0b93a3fdd681b53fdbe","modified":1534750796000},{"_id":"themes/dxx/source/js/main.js","hash":"9709660bc1bbd5bf053403dbe48f33787762c706","modified":1534750796000},{"_id":"themes/dxx/source/js/jquery.tagcloud.js","hash":"839487d0cbb4b6b498036bf3ecf6c3fd0a7482c4","modified":1534750796000},{"_id":"source/_posts/并发基本概念/JMM_caozuo.png","hash":"118e6c9d5cffc5211c7a5de9e6be12eb4a0fdf57","modified":1535594379000},{"_id":"source/_posts/缓存学习笔记/memcache2.png","hash":"e98eb80ca8c75e179b56ba32c7305ae34f38888c","modified":1542109806000},{"_id":"source/_posts/缓存学习笔记/redis.png","hash":"d9dd699cbd45c9956ad875391cd5cc7a98d93aaf","modified":1542109806000},{"_id":"source/_posts/线程安全性-可见性/reorder_read.png","hash":"b0c9932c9b6b88a7caeeaa2d761ac94b1aa87d0e","modified":1535855075000},{"_id":"source/_posts/线程安全性-可见性/reorder_write.png","hash":"9c162d3134cd703b65e814db373c0cd823227eb7","modified":1535855101000},{"_id":"themes/dxx/source/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1534750796000},{"_id":"themes/dxx/source/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1534750796000},{"_id":"themes/dxx/source/js/jquery-3.3.1.min.js","hash":"0c3192b500a4fd550e483cf77a49806a5872185b","modified":1534750796000},{"_id":"source/_posts/并发基本概念/JMM.png","hash":"19403feb41f0823df0467df31b4cc2076f5f6b58","modified":1535541043000},{"_id":"themes/dxx/source/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1534750796000},{"_id":"themes/dxx/source/fonts/MonoSocialIconsFont-1.10.eot","hash":"4756928c824e4a02561b32d0c0c696530e070f17","modified":1534750796000},{"_id":"themes/dxx/source/fonts/MonoSocialIconsFont-1.10.ttf","hash":"20b5d5c509123ad6f693d4f859684a606baa5109","modified":1534750796000},{"_id":"themes/dxx/source/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1534750796000},{"_id":"themes/dxx/source/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1534750796000},{"_id":"source/_posts/缓存学习笔记/memcache.png","hash":"bb1bac057f9d78830aee4fcca6dcc61846a6221e","modified":1542109806000},{"_id":"themes/dxx/source/fonts/MonoSocialIconsFont-1.10.svg","hash":"8fc9a4fa016790ad7fc20a80c96d23b3c889000a","modified":1534750796000},{"_id":"themes/dxx/source/fonts/MonoSocialIconsFont-1.10.otf","hash":"935bccc3da612f413e5d1aa4e601c8b9cd2a7618","modified":1534750796000},{"_id":"themes/dxx/source/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1534750796000},{"_id":"themes/dxx/source/js/highlight.min.js","hash":"4e152b54b8a2809077d0618033cba0918a9a6de7","modified":1534750796000},{"_id":"source/_posts/并发基本概念/ad_disad.png","hash":"00d7d4fe1133acc9567065dd4020f3c542074ca7","modified":1535595435000},{"_id":"public/2018/10/17/monit报警邮件配置避坑/index.html","hash":"d0e09e3e41a9ae44808b96756cda05d4c73fb60e","modified":1542109865125},{"_id":"public/2018/10/09/缓存学习笔记/index.html","hash":"dc7d4a8a3c56bedba882a0b2c81edcb11017c3a1","modified":1542109865125},{"_id":"public/2018/10/09/数据库切库分库分表/index.html","hash":"f1f123adb71e7067f941e5a64ba057a49fd76ef6","modified":1542109865126},{"_id":"public/2018/10/08/HashMap和ConcurrentHashMap/index.html","hash":"a9c5a0335b0c7376a6c2f305b3d92f2bdee22109","modified":1542109865126},{"_id":"public/2018/10/04/线程池/index.html","hash":"97d7fcbc581795fddf603fbdc69baebd5729fa69","modified":1542109865126},{"_id":"public/2018/10/04/JUC-ForkJoin-BlockingQueue/index.html","hash":"e5eee18375321fc2077ebb6ccb0a2dd240f71bf0","modified":1542109865126},{"_id":"public/2018/09/26/Kafka学习笔记/index.html","hash":"8f080ef5837308032867e0ddda4ee3748eb37ab5","modified":1542109865126},{"_id":"public/2018/09/11/ss配置/index.html","hash":"153fc3959709614a26bdc4664e36de9501af3e1d","modified":1542109865126},{"_id":"public/2018/09/07/数据结构-集合和映射/index.html","hash":"bb31af8c289675837001581ce0139c19f89c4a20","modified":1542109865126},{"_id":"public/2018/09/07/线程安全-并发容器JUC/index.html","hash":"f8dd97aa8275f85d7405653c4df390494cc78ff5","modified":1542109865126},{"_id":"public/2018/09/04/线程安全-同步容器/index.html","hash":"c4f3e433dec181777845b17937c562847094a802","modified":1542109865126},{"_id":"public/2018/09/04/线程不安全类与写法/index.html","hash":"30811a1dfa61821395990894bf8cc89822d82a17","modified":1542109865126},{"_id":"public/2018/09/03/线程封闭/index.html","hash":"0110172f8fb2e1b4651ddd8e37f481957ec8204b","modified":1542109865126},{"_id":"public/2018/09/03/不可变对象/index.html","hash":"855888254d0f12b2b59af56ee2e8ac0d5461dbbf","modified":1542109865127},{"_id":"public/2018/09/02/安全发布对象/index.html","hash":"18f39f39070f190b7c8effe0b3dcb8bb5427f609","modified":1542109865127},{"_id":"public/2018/09/02/线程安全性-有序性/index.html","hash":"226162af7d77a7cfbcea827519462267f59ceff3","modified":1542109865127},{"_id":"public/2018/09/01/线程安全性-可见性/index.html","hash":"6594aa873976c195ec64a9d828652a6616ae1d00","modified":1542109865127},{"_id":"public/2018/08/31/线程安全性-原子性/index.html","hash":"fc6fc0d73742c1c7ba7eb71d034842907bef1640","modified":1542109865127},{"_id":"public/2018/08/30/并发模拟/index.html","hash":"6e172283ad9890ebd21dcd4ac88f96257d699b0b","modified":1542109865127},{"_id":"public/2018/08/29/并发基本概念/index.html","hash":"060cb023b29f42579b3cbc4b728b5df9dbc2964a","modified":1542109865127},{"_id":"public/2018/08/20/Hexo-blog-framework/index.html","hash":"268b48c6c7c2037705267d05c9cbea9af443be2a","modified":1542109865127},{"_id":"public/archives/index.html","hash":"d151ef09a05377a500776eb3dbfc85e5b88ea0e7","modified":1542109865127},{"_id":"public/archives/page/2/index.html","hash":"d151ef09a05377a500776eb3dbfc85e5b88ea0e7","modified":1542109865127},{"_id":"public/archives/page/3/index.html","hash":"d151ef09a05377a500776eb3dbfc85e5b88ea0e7","modified":1542109865127},{"_id":"public/archives/2018/index.html","hash":"d151ef09a05377a500776eb3dbfc85e5b88ea0e7","modified":1542109865127},{"_id":"public/archives/2018/page/2/index.html","hash":"d151ef09a05377a500776eb3dbfc85e5b88ea0e7","modified":1542109865127},{"_id":"public/archives/2018/page/3/index.html","hash":"d151ef09a05377a500776eb3dbfc85e5b88ea0e7","modified":1542109865127},{"_id":"public/archives/2018/08/index.html","hash":"d151ef09a05377a500776eb3dbfc85e5b88ea0e7","modified":1542109865127},{"_id":"public/archives/2018/09/index.html","hash":"d151ef09a05377a500776eb3dbfc85e5b88ea0e7","modified":1542109865127},{"_id":"public/archives/2018/09/page/2/index.html","hash":"d151ef09a05377a500776eb3dbfc85e5b88ea0e7","modified":1542109865128},{"_id":"public/archives/2018/10/index.html","hash":"d151ef09a05377a500776eb3dbfc85e5b88ea0e7","modified":1542109865128},{"_id":"public/index.html","hash":"e9d4fbb37d6d9c624785a4e385256ffac2a42054","modified":1542109865128},{"_id":"public/page/2/index.html","hash":"97a7e7117082e2429fb5fdf6861e31246a3ad21b","modified":1542109865128},{"_id":"public/page/3/index.html","hash":"ec05891502d4d1a9793a3fed5fbe7579d6d840bd","modified":1542109865128},{"_id":"public/fonts/MonoSocialIconsFont-1.10.woff","hash":"8755dcf98f0896705d8f84cd9746407c67065727","modified":1542109865133},{"_id":"public/fonts/icons.svg","hash":"4b05214485b496cf7ca5e1059fa5009b5584c0c1","modified":1542109865133},{"_id":"public/fonts/icons.ttf","hash":"b78addb6c6c3275c5c62369279e908e2bf03e76b","modified":1542109865134},{"_id":"public/fonts/icons.woff","hash":"fb24eafcd20cfff29a8d6c59d1ce6c8b2c6456d1","modified":1542109865134},{"_id":"public/images/avatar.png","hash":"4709534d1b796240bf76d0b93a3fdd681b53fdbe","modified":1542109865134},{"_id":"public/images/avatar@2x.png","hash":"4709534d1b796240bf76d0b93a3fdd681b53fdbe","modified":1542109865134},{"_id":"public/2018/08/20/Hexo-blog-framework/github_config.png","hash":"3914dcd0557322845e5ab5e45660d14910201441","modified":1542109865134},{"_id":"public/2018/10/17/monit报警邮件配置避坑/stmp.png","hash":"d2dea2a1d6f9003d12b1240319a1d2a193c28347","modified":1542109865134},{"_id":"public/2018/08/29/并发基本概念/MESI_protocal.jpg","hash":"e2f43a4ddffb607d6edfd8cbbfef04697dc17345","modified":1542109865134},{"_id":"public/2018/10/09/缓存学习笔记/GuavaCache.png","hash":"70c39d4bb3dbbf7fcec822b68f31e103c63f1f80","modified":1542109865134},{"_id":"public/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1542109865141},{"_id":"public/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1542109865142},{"_id":"public/2018/09/01/线程安全性-可见性/reorder_write.png","hash":"9c162d3134cd703b65e814db373c0cd823227eb7","modified":1542109865147},{"_id":"public/2018/09/01/线程安全性-可见性/reorder_read.png","hash":"b0c9932c9b6b88a7caeeaa2d761ac94b1aa87d0e","modified":1542109865147},{"_id":"public/2018/08/29/并发基本概念/JMM_caozuo.png","hash":"118e6c9d5cffc5211c7a5de9e6be12eb4a0fdf57","modified":1542109865147},{"_id":"public/2018/10/09/缓存学习笔记/redis.png","hash":"d9dd699cbd45c9956ad875391cd5cc7a98d93aaf","modified":1542109865147},{"_id":"public/2018/10/09/缓存学习笔记/memcache2.png","hash":"e98eb80ca8c75e179b56ba32c7305ae34f38888c","modified":1542109865147},{"_id":"public/css/monosocialiconsfont.css","hash":"83154fcbf731bccdb247824dc540d804044c3f5b","modified":1542109865155},{"_id":"public/css/highlight.css","hash":"1afe807bfb7d7ed2568e8637bd10352c9a13f358","modified":1542109865155},{"_id":"public/css/highlight.min.css","hash":"afb4f1d3e8917b812e013034470f444491b47bd9","modified":1542109865156},{"_id":"public/css/monosocialiconsfont.min.css","hash":"d2818e282e540257dffdbbf997fa272c30541507","modified":1542109865156},{"_id":"public/css/style.css","hash":"0695e19c635d08dfd02c4f3a5eaa14b05457cbd2","modified":1542109865156},{"_id":"public/css/style.min.css","hash":"d95762020cc919367de30bc559e8fd005d3c8a0d","modified":1542109865156},{"_id":"public/js/index.js","hash":"04460c4d2be494b361958f2a7a28e85ed2a530a6","modified":1542109865156},{"_id":"public/js/main.js","hash":"4d6e423fb5556c8376c51184664150ccf8557c47","modified":1542109865156},{"_id":"public/js/jquery.tagcloud.js","hash":"45f7625f93128ec1fd0319dbc691de0936866e85","modified":1542109865156},{"_id":"public/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1542109865156},{"_id":"public/js/jquery-3.3.1.min.js","hash":"0dc32db4aa9c5f03f3b38c47d883dbd4fed13aae","modified":1542109865156},{"_id":"public/js/highlight.min.js","hash":"45151d184f32b36eb762126d068f6568ae99231e","modified":1542109865157},{"_id":"public/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1542109865157},{"_id":"public/fonts/MonoSocialIconsFont-1.10.eot","hash":"4756928c824e4a02561b32d0c0c696530e070f17","modified":1542109865157},{"_id":"public/fonts/MonoSocialIconsFont-1.10.ttf","hash":"20b5d5c509123ad6f693d4f859684a606baa5109","modified":1542109865157},{"_id":"public/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1542109865158},{"_id":"public/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1542109865158},{"_id":"public/2018/08/29/并发基本概念/JMM.png","hash":"19403feb41f0823df0467df31b4cc2076f5f6b58","modified":1542109865159},{"_id":"public/2018/10/09/缓存学习笔记/memcache.png","hash":"bb1bac057f9d78830aee4fcca6dcc61846a6221e","modified":1542109865166},{"_id":"public/fonts/MonoSocialIconsFont-1.10.svg","hash":"8fc9a4fa016790ad7fc20a80c96d23b3c889000a","modified":1542109865169},{"_id":"public/fonts/MonoSocialIconsFont-1.10.otf","hash":"935bccc3da612f413e5d1aa4e601c8b9cd2a7618","modified":1542109865173},{"_id":"public/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1542109865177},{"_id":"public/2018/08/29/并发基本概念/ad_disad.png","hash":"00d7d4fe1133acc9567065dd4020f3c542074ca7","modified":1542109865197}],"Category":[],"Data":[],"Page":[],"Post":[{"title":"Hexo blog framework","date":"2018-08-20T09:00:41.000Z","_content":"\nI have been thinking for a while to create my own personal tech blog to record my tech studies. And I came accross Hexo, a simple blog framework for us to create our own blogs. It's super helpful for non front-end developers. Here are the steps you can follow.\n\n# Steps \n\n## Download node.js\nHere I use node-v5.6.0\n\n## Install Hexo and packages\nScreen Shot 2018-08-20 at 5.34.24 PM\n\t$ npm install -g hexo\n\t$ hexo init\n\t$ npm install\n\nYou will be able to view the default blog page (localhost:4000) generated by hexo locally after type in,\n    \n    $ hexo g \n    $ hexo s\n\n## Deploy code to github\n\nYou need to create a github repository following the naming pattern: \"yourname.github.io\", then edit the config.yml file in the root path.\n\n![github_config](github_config.png)\n\nDownload the hexo-deployer-git plugin.\n\n\t$ npm install hexo-deployer-git --save\n\nAfter set up the ssh keys, you should be able to deploy code to github. \n\n\t$ hexo g\n\t$ hexo d\n\nThen, you can view the blog page from github using the url: yourname.github.io\n\n\n## Add themes to your blog\n\nDownload a theme for your blog is easy, you can do it like this:\n\n\t$ git clone https://github.com/wuchong/jacman.git themes/jacman\n\nAfter you execute this command, a theme \"jacman\" will be intalled to the \"themes\" folder, and what you need to do is adding to config_yml file, replace the default theme \"landscape\".\n\nMore themes would be available in [Hexo](https://hexo.io/themes/).\n\n## Add new blog\n\nAt this point, creat a new blog is simply by typing the command\n\n\t$ hexo new\n\n\t\n","source":"_posts/Hexo-blog-framework.md","raw":"---\ntitle: Hexo blog framework\ndate: 2018-08-20 17:00:41\ntags:\n---\n\nI have been thinking for a while to create my own personal tech blog to record my tech studies. And I came accross Hexo, a simple blog framework for us to create our own blogs. It's super helpful for non front-end developers. Here are the steps you can follow.\n\n# Steps \n\n## Download node.js\nHere I use node-v5.6.0\n\n## Install Hexo and packages\nScreen Shot 2018-08-20 at 5.34.24 PM\n\t$ npm install -g hexo\n\t$ hexo init\n\t$ npm install\n\nYou will be able to view the default blog page (localhost:4000) generated by hexo locally after type in,\n    \n    $ hexo g \n    $ hexo s\n\n## Deploy code to github\n\nYou need to create a github repository following the naming pattern: \"yourname.github.io\", then edit the config.yml file in the root path.\n\n![github_config](github_config.png)\n\nDownload the hexo-deployer-git plugin.\n\n\t$ npm install hexo-deployer-git --save\n\nAfter set up the ssh keys, you should be able to deploy code to github. \n\n\t$ hexo g\n\t$ hexo d\n\nThen, you can view the blog page from github using the url: yourname.github.io\n\n\n## Add themes to your blog\n\nDownload a theme for your blog is easy, you can do it like this:\n\n\t$ git clone https://github.com/wuchong/jacman.git themes/jacman\n\nAfter you execute this command, a theme \"jacman\" will be intalled to the \"themes\" folder, and what you need to do is adding to config_yml file, replace the default theme \"landscape\".\n\nMore themes would be available in [Hexo](https://hexo.io/themes/).\n\n## Add new blog\n\nAt this point, creat a new blog is simply by typing the command\n\n\t$ hexo new\n\n\t\n","slug":"Hexo-blog-framework","published":1,"updated":"2018-09-02T02:37:16.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjofoeaue0000d922bhwxv17r","content":"<p>I have been thinking for a while to create my own personal tech blog to record my tech studies. And I came accross Hexo, a simple blog framework for us to create our own blogs. It’s super helpful for non front-end developers. Here are the steps you can follow.</p>\n<h1 id=\"Steps\"><a href=\"#Steps\" class=\"headerlink\" title=\"Steps\"></a>Steps</h1><h2 id=\"Download-node-js\"><a href=\"#Download-node-js\" class=\"headerlink\" title=\"Download node.js\"></a>Download node.js</h2><p>Here I use node-v5.6.0</p>\n<h2 id=\"Install-Hexo-and-packages\"><a href=\"#Install-Hexo-and-packages\" class=\"headerlink\" title=\"Install Hexo and packages\"></a>Install Hexo and packages</h2><p>Screen Shot 2018-08-20 at 5.34.24 PM<br>    $ npm install -g hexo<br>    $ hexo init<br>    $ npm install</p>\n<p>You will be able to view the default blog page (localhost:4000) generated by hexo locally after type in,</p>\n<pre><code>$ hexo g \n$ hexo s\n</code></pre><h2 id=\"Deploy-code-to-github\"><a href=\"#Deploy-code-to-github\" class=\"headerlink\" title=\"Deploy code to github\"></a>Deploy code to github</h2><p>You need to create a github repository following the naming pattern: “yourname.github.io”, then edit the config.yml file in the root path.</p>\n<p><img src=\"github_config.png\" alt=\"github_config\"></p>\n<p>Download the hexo-deployer-git plugin.</p>\n<pre><code>$ npm install hexo-deployer-git --save\n</code></pre><p>After set up the ssh keys, you should be able to deploy code to github. </p>\n<pre><code>$ hexo g\n$ hexo d\n</code></pre><p>Then, you can view the blog page from github using the url: yourname.github.io</p>\n<h2 id=\"Add-themes-to-your-blog\"><a href=\"#Add-themes-to-your-blog\" class=\"headerlink\" title=\"Add themes to your blog\"></a>Add themes to your blog</h2><p>Download a theme for your blog is easy, you can do it like this:</p>\n<pre><code>$ git clone https://github.com/wuchong/jacman.git themes/jacman\n</code></pre><p>After you execute this command, a theme “jacman” will be intalled to the “themes” folder, and what you need to do is adding to config_yml file, replace the default theme “landscape”.</p>\n<p>More themes would be available in <a href=\"https://hexo.io/themes/\" target=\"_blank\" rel=\"noopener\">Hexo</a>.</p>\n<h2 id=\"Add-new-blog\"><a href=\"#Add-new-blog\" class=\"headerlink\" title=\"Add new blog\"></a>Add new blog</h2><p>At this point, creat a new blog is simply by typing the command</p>\n<pre><code>$ hexo new\n</code></pre>","site":{"data":{}},"excerpt":"","more":"<p>I have been thinking for a while to create my own personal tech blog to record my tech studies. And I came accross Hexo, a simple blog framework for us to create our own blogs. It’s super helpful for non front-end developers. Here are the steps you can follow.</p>\n<h1 id=\"Steps\"><a href=\"#Steps\" class=\"headerlink\" title=\"Steps\"></a>Steps</h1><h2 id=\"Download-node-js\"><a href=\"#Download-node-js\" class=\"headerlink\" title=\"Download node.js\"></a>Download node.js</h2><p>Here I use node-v5.6.0</p>\n<h2 id=\"Install-Hexo-and-packages\"><a href=\"#Install-Hexo-and-packages\" class=\"headerlink\" title=\"Install Hexo and packages\"></a>Install Hexo and packages</h2><p>Screen Shot 2018-08-20 at 5.34.24 PM<br>    $ npm install -g hexo<br>    $ hexo init<br>    $ npm install</p>\n<p>You will be able to view the default blog page (localhost:4000) generated by hexo locally after type in,</p>\n<pre><code>$ hexo g \n$ hexo s\n</code></pre><h2 id=\"Deploy-code-to-github\"><a href=\"#Deploy-code-to-github\" class=\"headerlink\" title=\"Deploy code to github\"></a>Deploy code to github</h2><p>You need to create a github repository following the naming pattern: “yourname.github.io”, then edit the config.yml file in the root path.</p>\n<p><img src=\"github_config.png\" alt=\"github_config\"></p>\n<p>Download the hexo-deployer-git plugin.</p>\n<pre><code>$ npm install hexo-deployer-git --save\n</code></pre><p>After set up the ssh keys, you should be able to deploy code to github. </p>\n<pre><code>$ hexo g\n$ hexo d\n</code></pre><p>Then, you can view the blog page from github using the url: yourname.github.io</p>\n<h2 id=\"Add-themes-to-your-blog\"><a href=\"#Add-themes-to-your-blog\" class=\"headerlink\" title=\"Add themes to your blog\"></a>Add themes to your blog</h2><p>Download a theme for your blog is easy, you can do it like this:</p>\n<pre><code>$ git clone https://github.com/wuchong/jacman.git themes/jacman\n</code></pre><p>After you execute this command, a theme “jacman” will be intalled to the “themes” folder, and what you need to do is adding to config_yml file, replace the default theme “landscape”.</p>\n<p>More themes would be available in <a href=\"https://hexo.io/themes/\" target=\"_blank\" rel=\"noopener\">Hexo</a>.</p>\n<h2 id=\"Add-new-blog\"><a href=\"#Add-new-blog\" class=\"headerlink\" title=\"Add new blog\"></a>Add new blog</h2><p>At this point, creat a new blog is simply by typing the command</p>\n<pre><code>$ hexo new\n</code></pre>"},{"title":"Kafka学习笔记","date":"2018-09-26T07:44:19.000Z","_content":"\n# Kafka基本概念\n\n* Producer: 消息和数据生产者， 向Kafka的一个topic发布消息和进程/代码/服务\n* Consumer: 消息和数据的消费者， 订阅数据（Topic）并且处理其发布的消息的进程/代码/服务\n* Consumer Group: 逻辑概念， 对于同一个topic， 会广播给不同的group, 一个group中， 只有一个consumer可以消费该消息\n* Broker: 物理概念， Kafka集群中的每个Kafka节点\n* Topic：逻辑概念， Kafka消息的类别， 对数据区分， 隔离\n* Partition: 物理概念， Kafka下数据存储的基本单元。 一个Topic数据， 会被分散存储到多个Partition， 每一个Partition是有序的\n* Replication: 同一个Partition可能会有多个Replica， 多个Replica之间数据是一样的\n* Replication Leader: 一个Partition的多个Replica上， 需要一个leader负责该Partition上的Producer和Consumer交互\n* ReplicaManager: 负责管理当前Broker所有分区和副本的信息， 处理KafkaController发起的一些请求， 副本状态的切换，添加，读取消息等\n\n","source":"_posts/Kafka学习笔记.md","raw":"---\ntitle: Kafka学习笔记\ndate: 2018-09-26 15:44:19\ntags:\n---\n\n# Kafka基本概念\n\n* Producer: 消息和数据生产者， 向Kafka的一个topic发布消息和进程/代码/服务\n* Consumer: 消息和数据的消费者， 订阅数据（Topic）并且处理其发布的消息的进程/代码/服务\n* Consumer Group: 逻辑概念， 对于同一个topic， 会广播给不同的group, 一个group中， 只有一个consumer可以消费该消息\n* Broker: 物理概念， Kafka集群中的每个Kafka节点\n* Topic：逻辑概念， Kafka消息的类别， 对数据区分， 隔离\n* Partition: 物理概念， Kafka下数据存储的基本单元。 一个Topic数据， 会被分散存储到多个Partition， 每一个Partition是有序的\n* Replication: 同一个Partition可能会有多个Replica， 多个Replica之间数据是一样的\n* Replication Leader: 一个Partition的多个Replica上， 需要一个leader负责该Partition上的Producer和Consumer交互\n* ReplicaManager: 负责管理当前Broker所有分区和副本的信息， 处理KafkaController发起的一些请求， 副本状态的切换，添加，读取消息等\n\n","slug":"Kafka学习笔记","published":1,"updated":"2018-10-08T06:32:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjofoeaui0001d922ky033rn5","content":"<h1 id=\"Kafka基本概念\"><a href=\"#Kafka基本概念\" class=\"headerlink\" title=\"Kafka基本概念\"></a>Kafka基本概念</h1><ul>\n<li>Producer: 消息和数据生产者， 向Kafka的一个topic发布消息和进程/代码/服务</li>\n<li>Consumer: 消息和数据的消费者， 订阅数据（Topic）并且处理其发布的消息的进程/代码/服务</li>\n<li>Consumer Group: 逻辑概念， 对于同一个topic， 会广播给不同的group, 一个group中， 只有一个consumer可以消费该消息</li>\n<li>Broker: 物理概念， Kafka集群中的每个Kafka节点</li>\n<li>Topic：逻辑概念， Kafka消息的类别， 对数据区分， 隔离</li>\n<li>Partition: 物理概念， Kafka下数据存储的基本单元。 一个Topic数据， 会被分散存储到多个Partition， 每一个Partition是有序的</li>\n<li>Replication: 同一个Partition可能会有多个Replica， 多个Replica之间数据是一样的</li>\n<li>Replication Leader: 一个Partition的多个Replica上， 需要一个leader负责该Partition上的Producer和Consumer交互</li>\n<li>ReplicaManager: 负责管理当前Broker所有分区和副本的信息， 处理KafkaController发起的一些请求， 副本状态的切换，添加，读取消息等</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Kafka基本概念\"><a href=\"#Kafka基本概念\" class=\"headerlink\" title=\"Kafka基本概念\"></a>Kafka基本概念</h1><ul>\n<li>Producer: 消息和数据生产者， 向Kafka的一个topic发布消息和进程/代码/服务</li>\n<li>Consumer: 消息和数据的消费者， 订阅数据（Topic）并且处理其发布的消息的进程/代码/服务</li>\n<li>Consumer Group: 逻辑概念， 对于同一个topic， 会广播给不同的group, 一个group中， 只有一个consumer可以消费该消息</li>\n<li>Broker: 物理概念， Kafka集群中的每个Kafka节点</li>\n<li>Topic：逻辑概念， Kafka消息的类别， 对数据区分， 隔离</li>\n<li>Partition: 物理概念， Kafka下数据存储的基本单元。 一个Topic数据， 会被分散存储到多个Partition， 每一个Partition是有序的</li>\n<li>Replication: 同一个Partition可能会有多个Replica， 多个Replica之间数据是一样的</li>\n<li>Replication Leader: 一个Partition的多个Replica上， 需要一个leader负责该Partition上的Producer和Consumer交互</li>\n<li>ReplicaManager: 负责管理当前Broker所有分区和副本的信息， 处理KafkaController发起的一些请求， 副本状态的切换，添加，读取消息等</li>\n</ul>\n"},{"title":"HashMap和ConcurrentHashMap","date":"2018-10-08T01:19:50.000Z","_content":"\n# HashMap\n* 初始容量 - 哈希表中桶的数量\n* 加载因子\n\n默认大小为16， 当条目数超过12（16乘以0.75）时， 调用resize方法\n\n## 寻址 \nkey值算出哈希值对数组长度进行取模作为index。因为取模代价远远大于位运算。 hashmap要求数组长度必须为2的n次方。\nkey的哈希值与2的n-1次方进行与运算， 结果与取模的结果是相同的。\n\n## 线程不安全\nrehash过程不是线程安全的， 多线程调用过程中可能出现死循环。\nfast fail问题： 使用迭代器过程中hashmap被修改了， 就会抛出concurrent modification exception。\n可以使用collections里面的synchMap方法构造同步map或者ConcurrentHashMap来避免fast fail\n\n# ConcurrentHashMap\n线程安全， 根据哈希码高位决定segment数组， 再根据哈希码决定hash entry数组的index， segment上面加了reentrant lock。\nhashmap允许key和value为空， ConcurrentHashMap不允许。 \n\nJava7为实现并行访问实现了segment分段锁，理论上最大并发度和segment的个数相等。 \nJava8废弃了分段锁，直接使用大的数组。 当链表长度超过8（默认）， 链表转化为红黑树。\n\n","source":"_posts/HashMap和ConcurrentHashMap.md","raw":"---\ntitle: HashMap和ConcurrentHashMap\ndate: 2018-10-08 09:19:50\ntags:\n---\n\n# HashMap\n* 初始容量 - 哈希表中桶的数量\n* 加载因子\n\n默认大小为16， 当条目数超过12（16乘以0.75）时， 调用resize方法\n\n## 寻址 \nkey值算出哈希值对数组长度进行取模作为index。因为取模代价远远大于位运算。 hashmap要求数组长度必须为2的n次方。\nkey的哈希值与2的n-1次方进行与运算， 结果与取模的结果是相同的。\n\n## 线程不安全\nrehash过程不是线程安全的， 多线程调用过程中可能出现死循环。\nfast fail问题： 使用迭代器过程中hashmap被修改了， 就会抛出concurrent modification exception。\n可以使用collections里面的synchMap方法构造同步map或者ConcurrentHashMap来避免fast fail\n\n# ConcurrentHashMap\n线程安全， 根据哈希码高位决定segment数组， 再根据哈希码决定hash entry数组的index， segment上面加了reentrant lock。\nhashmap允许key和value为空， ConcurrentHashMap不允许。 \n\nJava7为实现并行访问实现了segment分段锁，理论上最大并发度和segment的个数相等。 \nJava8废弃了分段锁，直接使用大的数组。 当链表长度超过8（默认）， 链表转化为红黑树。\n\n","slug":"HashMap和ConcurrentHashMap","published":1,"updated":"2018-10-08T06:32:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjofoeaul0002d9224i4dtvc1","content":"<h1 id=\"HashMap\"><a href=\"#HashMap\" class=\"headerlink\" title=\"HashMap\"></a>HashMap</h1><ul>\n<li>初始容量 - 哈希表中桶的数量</li>\n<li>加载因子</li>\n</ul>\n<p>默认大小为16， 当条目数超过12（16乘以0.75）时， 调用resize方法</p>\n<h2 id=\"寻址\"><a href=\"#寻址\" class=\"headerlink\" title=\"寻址\"></a>寻址</h2><p>key值算出哈希值对数组长度进行取模作为index。因为取模代价远远大于位运算。 hashmap要求数组长度必须为2的n次方。<br>key的哈希值与2的n-1次方进行与运算， 结果与取模的结果是相同的。</p>\n<h2 id=\"线程不安全\"><a href=\"#线程不安全\" class=\"headerlink\" title=\"线程不安全\"></a>线程不安全</h2><p>rehash过程不是线程安全的， 多线程调用过程中可能出现死循环。<br>fast fail问题： 使用迭代器过程中hashmap被修改了， 就会抛出concurrent modification exception。<br>可以使用collections里面的synchMap方法构造同步map或者ConcurrentHashMap来避免fast fail</p>\n<h1 id=\"ConcurrentHashMap\"><a href=\"#ConcurrentHashMap\" class=\"headerlink\" title=\"ConcurrentHashMap\"></a>ConcurrentHashMap</h1><p>线程安全， 根据哈希码高位决定segment数组， 再根据哈希码决定hash entry数组的index， segment上面加了reentrant lock。<br>hashmap允许key和value为空， ConcurrentHashMap不允许。 </p>\n<p>Java7为实现并行访问实现了segment分段锁，理论上最大并发度和segment的个数相等。<br>Java8废弃了分段锁，直接使用大的数组。 当链表长度超过8（默认）， 链表转化为红黑树。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"HashMap\"><a href=\"#HashMap\" class=\"headerlink\" title=\"HashMap\"></a>HashMap</h1><ul>\n<li>初始容量 - 哈希表中桶的数量</li>\n<li>加载因子</li>\n</ul>\n<p>默认大小为16， 当条目数超过12（16乘以0.75）时， 调用resize方法</p>\n<h2 id=\"寻址\"><a href=\"#寻址\" class=\"headerlink\" title=\"寻址\"></a>寻址</h2><p>key值算出哈希值对数组长度进行取模作为index。因为取模代价远远大于位运算。 hashmap要求数组长度必须为2的n次方。<br>key的哈希值与2的n-1次方进行与运算， 结果与取模的结果是相同的。</p>\n<h2 id=\"线程不安全\"><a href=\"#线程不安全\" class=\"headerlink\" title=\"线程不安全\"></a>线程不安全</h2><p>rehash过程不是线程安全的， 多线程调用过程中可能出现死循环。<br>fast fail问题： 使用迭代器过程中hashmap被修改了， 就会抛出concurrent modification exception。<br>可以使用collections里面的synchMap方法构造同步map或者ConcurrentHashMap来避免fast fail</p>\n<h1 id=\"ConcurrentHashMap\"><a href=\"#ConcurrentHashMap\" class=\"headerlink\" title=\"ConcurrentHashMap\"></a>ConcurrentHashMap</h1><p>线程安全， 根据哈希码高位决定segment数组， 再根据哈希码决定hash entry数组的index， segment上面加了reentrant lock。<br>hashmap允许key和value为空， ConcurrentHashMap不允许。 </p>\n<p>Java7为实现并行访问实现了segment分段锁，理论上最大并发度和segment的个数相等。<br>Java8废弃了分段锁，直接使用大的数组。 当链表长度超过8（默认）， 链表转化为红黑树。</p>\n"},{"title":"monit报警邮件配置闭坑","date":"2018-10-17T09:30:11.000Z","_content":"\n# monit报警邮件配置\n\nmonit配置报警邮件， 现在以qq smtp服务为例。\n\n## 根据官方文档配置mailserver \n\n\tset mailserver smtp.qq.com port xx\n\tusername \"qq号\" password \"不是密码是授权码\"\n\tusing SSL\n\n## 配置mail-format\n\n\tset mail-format {\n    \tfrom: 454648xx@qq.com\n    \tsubject: monit alert -- $EVENT\n    \tmessage: Date: $DATE\n             Description: $DESCRIPTION\n \t}\n\n\n## 配置邮件接收者\n\n\tset alert 406507715@qq.com\n\n发现启动monit后eventqueue有日志但是没有收到邮件！ 百思不得其解！！\n原来是因为： \n* 随着网络上垃圾邮件的泛滥,越来越多的免费电子邮箱服务商对邮箱的安全策略进行了提升,有多种不同的方式,最常见的就是开启的SMTP授权功能 *\n\n所以需要在qq邮箱里面开启SMTP服务，得到授权码。\n\n![stmp](stmp.png)\n\n接收邮件服务器：imap.qq.com，使用SSL，端口号993\n发送邮件服务器：smtp.qq.com，使用SSL，端口号465或587","source":"_posts/monit报警邮件配置避坑.md","raw":"---\ntitle: monit报警邮件配置闭坑\ndate: 2018-10-17 17:30:11\ntags:\n---\n\n# monit报警邮件配置\n\nmonit配置报警邮件， 现在以qq smtp服务为例。\n\n## 根据官方文档配置mailserver \n\n\tset mailserver smtp.qq.com port xx\n\tusername \"qq号\" password \"不是密码是授权码\"\n\tusing SSL\n\n## 配置mail-format\n\n\tset mail-format {\n    \tfrom: 454648xx@qq.com\n    \tsubject: monit alert -- $EVENT\n    \tmessage: Date: $DATE\n             Description: $DESCRIPTION\n \t}\n\n\n## 配置邮件接收者\n\n\tset alert 406507715@qq.com\n\n发现启动monit后eventqueue有日志但是没有收到邮件！ 百思不得其解！！\n原来是因为： \n* 随着网络上垃圾邮件的泛滥,越来越多的免费电子邮箱服务商对邮箱的安全策略进行了提升,有多种不同的方式,最常见的就是开启的SMTP授权功能 *\n\n所以需要在qq邮箱里面开启SMTP服务，得到授权码。\n\n![stmp](stmp.png)\n\n接收邮件服务器：imap.qq.com，使用SSL，端口号993\n发送邮件服务器：smtp.qq.com，使用SSL，端口号465或587","slug":"monit报警邮件配置避坑","published":1,"updated":"2018-11-13T11:50:06.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjofoeaun0003d922rs8e5ion","content":"<h1 id=\"monit报警邮件配置\"><a href=\"#monit报警邮件配置\" class=\"headerlink\" title=\"monit报警邮件配置\"></a>monit报警邮件配置</h1><p>monit配置报警邮件， 现在以qq smtp服务为例。</p>\n<h2 id=\"根据官方文档配置mailserver\"><a href=\"#根据官方文档配置mailserver\" class=\"headerlink\" title=\"根据官方文档配置mailserver\"></a>根据官方文档配置mailserver</h2><pre><code>set mailserver smtp.qq.com port xx\nusername &quot;qq号&quot; password &quot;不是密码是授权码&quot;\nusing SSL\n</code></pre><h2 id=\"配置mail-format\"><a href=\"#配置mail-format\" class=\"headerlink\" title=\"配置mail-format\"></a>配置mail-format</h2><pre><code>set mail-format {\n    from: 454648xx@qq.com\n    subject: monit alert -- $EVENT\n    message: Date: $DATE\n         Description: $DESCRIPTION\n }\n</code></pre><h2 id=\"配置邮件接收者\"><a href=\"#配置邮件接收者\" class=\"headerlink\" title=\"配置邮件接收者\"></a>配置邮件接收者</h2><pre><code>set alert 406507715@qq.com\n</code></pre><p>发现启动monit后eventqueue有日志但是没有收到邮件！ 百思不得其解！！<br>原来是因为： </p>\n<ul>\n<li>随着网络上垃圾邮件的泛滥,越来越多的免费电子邮箱服务商对邮箱的安全策略进行了提升,有多种不同的方式,最常见的就是开启的SMTP授权功能 *</li>\n</ul>\n<p>所以需要在qq邮箱里面开启SMTP服务，得到授权码。</p>\n<p><img src=\"stmp.png\" alt=\"stmp\"></p>\n<p>接收邮件服务器：imap.qq.com，使用SSL，端口号993<br>发送邮件服务器：smtp.qq.com，使用SSL，端口号465或587</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"monit报警邮件配置\"><a href=\"#monit报警邮件配置\" class=\"headerlink\" title=\"monit报警邮件配置\"></a>monit报警邮件配置</h1><p>monit配置报警邮件， 现在以qq smtp服务为例。</p>\n<h2 id=\"根据官方文档配置mailserver\"><a href=\"#根据官方文档配置mailserver\" class=\"headerlink\" title=\"根据官方文档配置mailserver\"></a>根据官方文档配置mailserver</h2><pre><code>set mailserver smtp.qq.com port xx\nusername &quot;qq号&quot; password &quot;不是密码是授权码&quot;\nusing SSL\n</code></pre><h2 id=\"配置mail-format\"><a href=\"#配置mail-format\" class=\"headerlink\" title=\"配置mail-format\"></a>配置mail-format</h2><pre><code>set mail-format {\n    from: 454648xx@qq.com\n    subject: monit alert -- $EVENT\n    message: Date: $DATE\n         Description: $DESCRIPTION\n }\n</code></pre><h2 id=\"配置邮件接收者\"><a href=\"#配置邮件接收者\" class=\"headerlink\" title=\"配置邮件接收者\"></a>配置邮件接收者</h2><pre><code>set alert 406507715@qq.com\n</code></pre><p>发现启动monit后eventqueue有日志但是没有收到邮件！ 百思不得其解！！<br>原来是因为： </p>\n<ul>\n<li>随着网络上垃圾邮件的泛滥,越来越多的免费电子邮箱服务商对邮箱的安全策略进行了提升,有多种不同的方式,最常见的就是开启的SMTP授权功能 *</li>\n</ul>\n<p>所以需要在qq邮箱里面开启SMTP服务，得到授权码。</p>\n<p><img src=\"stmp.png\" alt=\"stmp\"></p>\n<p>接收邮件服务器：imap.qq.com，使用SSL，端口号993<br>发送邮件服务器：smtp.qq.com，使用SSL，端口号465或587</p>\n"},{"title":"JUC-ForkJoin","date":"2018-10-04T05:35:32.000Z","_content":"\nJava 7 提供的用于并行执行任务的框架， 把大任务分为多个小任务， 再汇总每个小任务结果得到大任务结果\n\n# Fork Join框架 \n* Fork 把大任务分为多个小任务并行执行\n* Join 合并子任务结果\n* 工作窃取算法， 使用双端队列， 窃取线程从被窃取线程队列尾部开始拿任务， 被窃取线程从头部开始拿任务。减少线程竞争， 某些场合还是有竞争， 比如双端队列只有一个任务时候。\n\n## 局限性\n\n1. 任务只能通过fork join来同步\n2. 小任务不能执行IO任务\n\n# Blocking Queue\n\n阻塞的情况：\n1. 队列满了入队\n2. 队列空出队\n阻塞队列是线程安全的， 其实就是一个线程生产， 另外一个线程消费的场景\n\n实现类\n1. ArrayBlockingQueue: 有界阻塞队列， 容量有限， 初始化时候定大小。 先进先出。\n2. DelayQueue: 无界阻塞队列，继承comparable接口， 因为delayqueue内部元素需要排序。 一般按元素过期时间优先级进行排序。 用于定时关闭连接， 缓存对象， 超时处理。内部实现用到锁和排序\n3. LinkedBlockingQueue: 初始化指定大小就是有边界， 不然无边界。 \n4. PriorityBlcokingQueue： 允许null对象， 无边界有排序规则。\n5. SynchronousQueue: 只允许容纳一个元素， 有一个元素就阻塞。\n\n\n","source":"_posts/JUC-ForkJoin-BlockingQueue.md","raw":"---\ntitle: JUC-ForkJoin\ndate: 2018-10-04 13:35:32\ntags:\n---\n\nJava 7 提供的用于并行执行任务的框架， 把大任务分为多个小任务， 再汇总每个小任务结果得到大任务结果\n\n# Fork Join框架 \n* Fork 把大任务分为多个小任务并行执行\n* Join 合并子任务结果\n* 工作窃取算法， 使用双端队列， 窃取线程从被窃取线程队列尾部开始拿任务， 被窃取线程从头部开始拿任务。减少线程竞争， 某些场合还是有竞争， 比如双端队列只有一个任务时候。\n\n## 局限性\n\n1. 任务只能通过fork join来同步\n2. 小任务不能执行IO任务\n\n# Blocking Queue\n\n阻塞的情况：\n1. 队列满了入队\n2. 队列空出队\n阻塞队列是线程安全的， 其实就是一个线程生产， 另外一个线程消费的场景\n\n实现类\n1. ArrayBlockingQueue: 有界阻塞队列， 容量有限， 初始化时候定大小。 先进先出。\n2. DelayQueue: 无界阻塞队列，继承comparable接口， 因为delayqueue内部元素需要排序。 一般按元素过期时间优先级进行排序。 用于定时关闭连接， 缓存对象， 超时处理。内部实现用到锁和排序\n3. LinkedBlockingQueue: 初始化指定大小就是有边界， 不然无边界。 \n4. PriorityBlcokingQueue： 允许null对象， 无边界有排序规则。\n5. SynchronousQueue: 只允许容纳一个元素， 有一个元素就阻塞。\n\n\n","slug":"JUC-ForkJoin-BlockingQueue","published":1,"updated":"2018-10-04T06:10:17.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjofoeaup0004d922g1bgh4t4","content":"<p>Java 7 提供的用于并行执行任务的框架， 把大任务分为多个小任务， 再汇总每个小任务结果得到大任务结果</p>\n<h1 id=\"Fork-Join框架\"><a href=\"#Fork-Join框架\" class=\"headerlink\" title=\"Fork Join框架\"></a>Fork Join框架</h1><ul>\n<li>Fork 把大任务分为多个小任务并行执行</li>\n<li>Join 合并子任务结果</li>\n<li>工作窃取算法， 使用双端队列， 窃取线程从被窃取线程队列尾部开始拿任务， 被窃取线程从头部开始拿任务。减少线程竞争， 某些场合还是有竞争， 比如双端队列只有一个任务时候。</li>\n</ul>\n<h2 id=\"局限性\"><a href=\"#局限性\" class=\"headerlink\" title=\"局限性\"></a>局限性</h2><ol>\n<li>任务只能通过fork join来同步</li>\n<li>小任务不能执行IO任务</li>\n</ol>\n<h1 id=\"Blocking-Queue\"><a href=\"#Blocking-Queue\" class=\"headerlink\" title=\"Blocking Queue\"></a>Blocking Queue</h1><p>阻塞的情况：</p>\n<ol>\n<li>队列满了入队</li>\n<li>队列空出队<br>阻塞队列是线程安全的， 其实就是一个线程生产， 另外一个线程消费的场景</li>\n</ol>\n<p>实现类</p>\n<ol>\n<li>ArrayBlockingQueue: 有界阻塞队列， 容量有限， 初始化时候定大小。 先进先出。</li>\n<li>DelayQueue: 无界阻塞队列，继承comparable接口， 因为delayqueue内部元素需要排序。 一般按元素过期时间优先级进行排序。 用于定时关闭连接， 缓存对象， 超时处理。内部实现用到锁和排序</li>\n<li>LinkedBlockingQueue: 初始化指定大小就是有边界， 不然无边界。 </li>\n<li>PriorityBlcokingQueue： 允许null对象， 无边界有排序规则。</li>\n<li>SynchronousQueue: 只允许容纳一个元素， 有一个元素就阻塞。</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<p>Java 7 提供的用于并行执行任务的框架， 把大任务分为多个小任务， 再汇总每个小任务结果得到大任务结果</p>\n<h1 id=\"Fork-Join框架\"><a href=\"#Fork-Join框架\" class=\"headerlink\" title=\"Fork Join框架\"></a>Fork Join框架</h1><ul>\n<li>Fork 把大任务分为多个小任务并行执行</li>\n<li>Join 合并子任务结果</li>\n<li>工作窃取算法， 使用双端队列， 窃取线程从被窃取线程队列尾部开始拿任务， 被窃取线程从头部开始拿任务。减少线程竞争， 某些场合还是有竞争， 比如双端队列只有一个任务时候。</li>\n</ul>\n<h2 id=\"局限性\"><a href=\"#局限性\" class=\"headerlink\" title=\"局限性\"></a>局限性</h2><ol>\n<li>任务只能通过fork join来同步</li>\n<li>小任务不能执行IO任务</li>\n</ol>\n<h1 id=\"Blocking-Queue\"><a href=\"#Blocking-Queue\" class=\"headerlink\" title=\"Blocking Queue\"></a>Blocking Queue</h1><p>阻塞的情况：</p>\n<ol>\n<li>队列满了入队</li>\n<li>队列空出队<br>阻塞队列是线程安全的， 其实就是一个线程生产， 另外一个线程消费的场景</li>\n</ol>\n<p>实现类</p>\n<ol>\n<li>ArrayBlockingQueue: 有界阻塞队列， 容量有限， 初始化时候定大小。 先进先出。</li>\n<li>DelayQueue: 无界阻塞队列，继承comparable接口， 因为delayqueue内部元素需要排序。 一般按元素过期时间优先级进行排序。 用于定时关闭连接， 缓存对象， 超时处理。内部实现用到锁和排序</li>\n<li>LinkedBlockingQueue: 初始化指定大小就是有边界， 不然无边界。 </li>\n<li>PriorityBlcokingQueue： 允许null对象， 无边界有排序规则。</li>\n<li>SynchronousQueue: 只允许容纳一个元素， 有一个元素就阻塞。</li>\n</ol>\n"},{"title":"ss配置","date":"2018-09-11T05:43:12.000Z","_content":"\n\n# Server搭建\n## 下载shadowsocks服务安装脚本\t\n\n\twget --no-check-certificate  https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks.sh\n\n## 修改脚本权限\n\t\n\tchmod +x shadowsocks.sh\n\n## 运行安装脚本\n\t\t\n\t./shadowsocks.sh 2>&1 | tee shadowsocks.log\n\n  设置密码， 加密算法选择aes-256-cfb\n\n# Server Config\n\n## 卸载方法\n\t\n\t./shadowsocks.sh uninstall\n\n## 多用户多端口配置文件示例\n\n\t{\n\t\t\"server\":\"0.0.0.0\",\n\t\t\"local_address\":\"127.0.0.1\",\n\t \t\t\"local_port\":1080,\n\t\t\"port_password\":{\n     \t\t\"8989\":\"password0\",\n     \t\t\"9001\":\"password1\",\n     \t\t\"9002\":\"password2\",\n     \t\t\"9003\":\"password3\",\n     \t\t\"9004\":\"password4\"\n\t\t},\n\t\t\"timeout\":300,\n\t\t\"method\":\"your_encryption_method\",\n\t\t\"fast_open\": false\n\t}\n\n  \n## 防火墙设置\n\t\n\tcentos7 防火墙命令\n\tfirewall-cmd --permanent --zone=public --add-port=8990/tcp\n\tfirewall-cmd --permanent --zone=public --add-port=8990/udp\n\tfirewall-cmd  --reload\t\n\n\n用我爱共产党命令\n\t\n\t启动：/etc/init.d/shadowsocks start\n\t停止：/etc/init.d/shadowsocks stop\n\t重启：/etc/init.d/shadowsocks restart\n\t状态：/etc/init.d/shadowsocks status\n\n# 安装锐速+bbr 加速     \n## 更换centos内核\n\trpm -ivh http://soft.91yun.org/ISO/Linux/CentOS/kernel/kernel-3.10.0-229.1.2.el7.x86_64.rpm --force\n## 安装锐速\n\twget -N --no-check-certificate https://raw.githubusercontent.com/91yun/serverspeeder/master/serverspeeder-all.sh && bash serverspeeder-all.sh\n\n可能会提示内核版本问题，选择一个最接近的版本即可\n\n## 使用google bbr\n\twget --no-check-certificate https://github.com/teddysun/across/raw/master/bbr.sh\n\tchmod +x bbr.sh\n\t./bbr.sh\n\nGoogle 开源了其 TCP BBR 拥塞控制算法，并提交到了 Linux 内核，从 4.9 开始，Linux 内核已经用上了该算法。\t\n\n# Clients\n不同平台有对应的客户端：https://shadowsocks.org/en/download/clients.html\n","source":"_posts/ss配置.md","raw":"---\ntitle: ss配置\ndate: 2018-09-11 13:43:12\ntags:\n---\n\n\n# Server搭建\n## 下载shadowsocks服务安装脚本\t\n\n\twget --no-check-certificate  https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks.sh\n\n## 修改脚本权限\n\t\n\tchmod +x shadowsocks.sh\n\n## 运行安装脚本\n\t\t\n\t./shadowsocks.sh 2>&1 | tee shadowsocks.log\n\n  设置密码， 加密算法选择aes-256-cfb\n\n# Server Config\n\n## 卸载方法\n\t\n\t./shadowsocks.sh uninstall\n\n## 多用户多端口配置文件示例\n\n\t{\n\t\t\"server\":\"0.0.0.0\",\n\t\t\"local_address\":\"127.0.0.1\",\n\t \t\t\"local_port\":1080,\n\t\t\"port_password\":{\n     \t\t\"8989\":\"password0\",\n     \t\t\"9001\":\"password1\",\n     \t\t\"9002\":\"password2\",\n     \t\t\"9003\":\"password3\",\n     \t\t\"9004\":\"password4\"\n\t\t},\n\t\t\"timeout\":300,\n\t\t\"method\":\"your_encryption_method\",\n\t\t\"fast_open\": false\n\t}\n\n  \n## 防火墙设置\n\t\n\tcentos7 防火墙命令\n\tfirewall-cmd --permanent --zone=public --add-port=8990/tcp\n\tfirewall-cmd --permanent --zone=public --add-port=8990/udp\n\tfirewall-cmd  --reload\t\n\n\n用我爱共产党命令\n\t\n\t启动：/etc/init.d/shadowsocks start\n\t停止：/etc/init.d/shadowsocks stop\n\t重启：/etc/init.d/shadowsocks restart\n\t状态：/etc/init.d/shadowsocks status\n\n# 安装锐速+bbr 加速     \n## 更换centos内核\n\trpm -ivh http://soft.91yun.org/ISO/Linux/CentOS/kernel/kernel-3.10.0-229.1.2.el7.x86_64.rpm --force\n## 安装锐速\n\twget -N --no-check-certificate https://raw.githubusercontent.com/91yun/serverspeeder/master/serverspeeder-all.sh && bash serverspeeder-all.sh\n\n可能会提示内核版本问题，选择一个最接近的版本即可\n\n## 使用google bbr\n\twget --no-check-certificate https://github.com/teddysun/across/raw/master/bbr.sh\n\tchmod +x bbr.sh\n\t./bbr.sh\n\nGoogle 开源了其 TCP BBR 拥塞控制算法，并提交到了 Linux 内核，从 4.9 开始，Linux 内核已经用上了该算法。\t\n\n# Clients\n不同平台有对应的客户端：https://shadowsocks.org/en/download/clients.html\n","slug":"ss配置","published":1,"updated":"2018-09-11T06:05:57.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjofoeauq0005d922uw36ry4v","content":"<h1 id=\"Server搭建\"><a href=\"#Server搭建\" class=\"headerlink\" title=\"Server搭建\"></a>Server搭建</h1><h2 id=\"下载shadowsocks服务安装脚本\"><a href=\"#下载shadowsocks服务安装脚本\" class=\"headerlink\" title=\"下载shadowsocks服务安装脚本\"></a>下载shadowsocks服务安装脚本</h2><pre><code>wget --no-check-certificate  https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks.sh\n</code></pre><h2 id=\"修改脚本权限\"><a href=\"#修改脚本权限\" class=\"headerlink\" title=\"修改脚本权限\"></a>修改脚本权限</h2><pre><code>chmod +x shadowsocks.sh\n</code></pre><h2 id=\"运行安装脚本\"><a href=\"#运行安装脚本\" class=\"headerlink\" title=\"运行安装脚本\"></a>运行安装脚本</h2><pre><code>./shadowsocks.sh 2&gt;&amp;1 | tee shadowsocks.log\n</code></pre><p>  设置密码， 加密算法选择aes-256-cfb</p>\n<h1 id=\"Server-Config\"><a href=\"#Server-Config\" class=\"headerlink\" title=\"Server Config\"></a>Server Config</h1><h2 id=\"卸载方法\"><a href=\"#卸载方法\" class=\"headerlink\" title=\"卸载方法\"></a>卸载方法</h2><pre><code>./shadowsocks.sh uninstall\n</code></pre><h2 id=\"多用户多端口配置文件示例\"><a href=\"#多用户多端口配置文件示例\" class=\"headerlink\" title=\"多用户多端口配置文件示例\"></a>多用户多端口配置文件示例</h2><pre><code>{\n    &quot;server&quot;:&quot;0.0.0.0&quot;,\n    &quot;local_address&quot;:&quot;127.0.0.1&quot;,\n         &quot;local_port&quot;:1080,\n    &quot;port_password&quot;:{\n         &quot;8989&quot;:&quot;password0&quot;,\n         &quot;9001&quot;:&quot;password1&quot;,\n         &quot;9002&quot;:&quot;password2&quot;,\n         &quot;9003&quot;:&quot;password3&quot;,\n         &quot;9004&quot;:&quot;password4&quot;\n    },\n    &quot;timeout&quot;:300,\n    &quot;method&quot;:&quot;your_encryption_method&quot;,\n    &quot;fast_open&quot;: false\n}\n</code></pre><h2 id=\"防火墙设置\"><a href=\"#防火墙设置\" class=\"headerlink\" title=\"防火墙设置\"></a>防火墙设置</h2><pre><code>centos7 防火墙命令\nfirewall-cmd --permanent --zone=public --add-port=8990/tcp\nfirewall-cmd --permanent --zone=public --add-port=8990/udp\nfirewall-cmd  --reload    \n</code></pre><p>用我爱共产党命令</p>\n<pre><code>启动：/etc/init.d/shadowsocks start\n停止：/etc/init.d/shadowsocks stop\n重启：/etc/init.d/shadowsocks restart\n状态：/etc/init.d/shadowsocks status\n</code></pre><h1 id=\"安装锐速-bbr-加速\"><a href=\"#安装锐速-bbr-加速\" class=\"headerlink\" title=\"安装锐速+bbr 加速\"></a>安装锐速+bbr 加速</h1><h2 id=\"更换centos内核\"><a href=\"#更换centos内核\" class=\"headerlink\" title=\"更换centos内核\"></a>更换centos内核</h2><pre><code>rpm -ivh http://soft.91yun.org/ISO/Linux/CentOS/kernel/kernel-3.10.0-229.1.2.el7.x86_64.rpm --force\n</code></pre><h2 id=\"安装锐速\"><a href=\"#安装锐速\" class=\"headerlink\" title=\"安装锐速\"></a>安装锐速</h2><pre><code>wget -N --no-check-certificate https://raw.githubusercontent.com/91yun/serverspeeder/master/serverspeeder-all.sh &amp;&amp; bash serverspeeder-all.sh\n</code></pre><p>可能会提示内核版本问题，选择一个最接近的版本即可</p>\n<h2 id=\"使用google-bbr\"><a href=\"#使用google-bbr\" class=\"headerlink\" title=\"使用google bbr\"></a>使用google bbr</h2><pre><code>wget --no-check-certificate https://github.com/teddysun/across/raw/master/bbr.sh\nchmod +x bbr.sh\n./bbr.sh\n</code></pre><p>Google 开源了其 TCP BBR 拥塞控制算法，并提交到了 Linux 内核，从 4.9 开始，Linux 内核已经用上了该算法。    </p>\n<h1 id=\"Clients\"><a href=\"#Clients\" class=\"headerlink\" title=\"Clients\"></a>Clients</h1><p>不同平台有对应的客户端：<a href=\"https://shadowsocks.org/en/download/clients.html\" target=\"_blank\" rel=\"noopener\">https://shadowsocks.org/en/download/clients.html</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Server搭建\"><a href=\"#Server搭建\" class=\"headerlink\" title=\"Server搭建\"></a>Server搭建</h1><h2 id=\"下载shadowsocks服务安装脚本\"><a href=\"#下载shadowsocks服务安装脚本\" class=\"headerlink\" title=\"下载shadowsocks服务安装脚本\"></a>下载shadowsocks服务安装脚本</h2><pre><code>wget --no-check-certificate  https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks.sh\n</code></pre><h2 id=\"修改脚本权限\"><a href=\"#修改脚本权限\" class=\"headerlink\" title=\"修改脚本权限\"></a>修改脚本权限</h2><pre><code>chmod +x shadowsocks.sh\n</code></pre><h2 id=\"运行安装脚本\"><a href=\"#运行安装脚本\" class=\"headerlink\" title=\"运行安装脚本\"></a>运行安装脚本</h2><pre><code>./shadowsocks.sh 2&gt;&amp;1 | tee shadowsocks.log\n</code></pre><p>  设置密码， 加密算法选择aes-256-cfb</p>\n<h1 id=\"Server-Config\"><a href=\"#Server-Config\" class=\"headerlink\" title=\"Server Config\"></a>Server Config</h1><h2 id=\"卸载方法\"><a href=\"#卸载方法\" class=\"headerlink\" title=\"卸载方法\"></a>卸载方法</h2><pre><code>./shadowsocks.sh uninstall\n</code></pre><h2 id=\"多用户多端口配置文件示例\"><a href=\"#多用户多端口配置文件示例\" class=\"headerlink\" title=\"多用户多端口配置文件示例\"></a>多用户多端口配置文件示例</h2><pre><code>{\n    &quot;server&quot;:&quot;0.0.0.0&quot;,\n    &quot;local_address&quot;:&quot;127.0.0.1&quot;,\n         &quot;local_port&quot;:1080,\n    &quot;port_password&quot;:{\n         &quot;8989&quot;:&quot;password0&quot;,\n         &quot;9001&quot;:&quot;password1&quot;,\n         &quot;9002&quot;:&quot;password2&quot;,\n         &quot;9003&quot;:&quot;password3&quot;,\n         &quot;9004&quot;:&quot;password4&quot;\n    },\n    &quot;timeout&quot;:300,\n    &quot;method&quot;:&quot;your_encryption_method&quot;,\n    &quot;fast_open&quot;: false\n}\n</code></pre><h2 id=\"防火墙设置\"><a href=\"#防火墙设置\" class=\"headerlink\" title=\"防火墙设置\"></a>防火墙设置</h2><pre><code>centos7 防火墙命令\nfirewall-cmd --permanent --zone=public --add-port=8990/tcp\nfirewall-cmd --permanent --zone=public --add-port=8990/udp\nfirewall-cmd  --reload    \n</code></pre><p>用我爱共产党命令</p>\n<pre><code>启动：/etc/init.d/shadowsocks start\n停止：/etc/init.d/shadowsocks stop\n重启：/etc/init.d/shadowsocks restart\n状态：/etc/init.d/shadowsocks status\n</code></pre><h1 id=\"安装锐速-bbr-加速\"><a href=\"#安装锐速-bbr-加速\" class=\"headerlink\" title=\"安装锐速+bbr 加速\"></a>安装锐速+bbr 加速</h1><h2 id=\"更换centos内核\"><a href=\"#更换centos内核\" class=\"headerlink\" title=\"更换centos内核\"></a>更换centos内核</h2><pre><code>rpm -ivh http://soft.91yun.org/ISO/Linux/CentOS/kernel/kernel-3.10.0-229.1.2.el7.x86_64.rpm --force\n</code></pre><h2 id=\"安装锐速\"><a href=\"#安装锐速\" class=\"headerlink\" title=\"安装锐速\"></a>安装锐速</h2><pre><code>wget -N --no-check-certificate https://raw.githubusercontent.com/91yun/serverspeeder/master/serverspeeder-all.sh &amp;&amp; bash serverspeeder-all.sh\n</code></pre><p>可能会提示内核版本问题，选择一个最接近的版本即可</p>\n<h2 id=\"使用google-bbr\"><a href=\"#使用google-bbr\" class=\"headerlink\" title=\"使用google bbr\"></a>使用google bbr</h2><pre><code>wget --no-check-certificate https://github.com/teddysun/across/raw/master/bbr.sh\nchmod +x bbr.sh\n./bbr.sh\n</code></pre><p>Google 开源了其 TCP BBR 拥塞控制算法，并提交到了 Linux 内核，从 4.9 开始，Linux 内核已经用上了该算法。    </p>\n<h1 id=\"Clients\"><a href=\"#Clients\" class=\"headerlink\" title=\"Clients\"></a>Clients</h1><p>不同平台有对应的客户端：<a href=\"https://shadowsocks.org/en/download/clients.html\" target=\"_blank\" rel=\"noopener\">https://shadowsocks.org/en/download/clients.html</a></p>\n"},{"title":"不可变对象","date":"2018-09-03T08:45:40.000Z","_content":"\n# 不可变对象需要满足条件\n1. 对象创建以后状态不能修改\n2. 对象所有域都是final类型\n3. 对象是正确创建的（在对象创建期间， this引用没有逸出）\n\n## final关键字\nfinal能修饰类、 方法和变量\n* 修饰类： 不能被继承\n* final类中的方法默认为final\n* 修饰方法： 1、 锁定方法不能被继承类修改； 2、 效率， 早期java版本中会把final方法转为内嵌调用， \n但是如果方法过大， 看不到内嵌方法带来的性能提升， 3、 private方法默认是final的，不能被子类覆盖\n* 修饰变量： 基本数据类型变量初始化后不能修改， 引用类型初始化后不能指向别的对象， 比如final的hashmapp， 里面的值还是可以修改的。也可以修饰方法的参数，参数在方法执行过程中不能变化。\n\n\n## Collections.unmodifiableXXX\n\t\n## Guava: ImmutableXXX\n\n\n\n","source":"_posts/不可变对象.md","raw":"---\ntitle: 不可变对象\ndate: 2018-09-03 16:45:40\ntags:\n---\n\n# 不可变对象需要满足条件\n1. 对象创建以后状态不能修改\n2. 对象所有域都是final类型\n3. 对象是正确创建的（在对象创建期间， this引用没有逸出）\n\n## final关键字\nfinal能修饰类、 方法和变量\n* 修饰类： 不能被继承\n* final类中的方法默认为final\n* 修饰方法： 1、 锁定方法不能被继承类修改； 2、 效率， 早期java版本中会把final方法转为内嵌调用， \n但是如果方法过大， 看不到内嵌方法带来的性能提升， 3、 private方法默认是final的，不能被子类覆盖\n* 修饰变量： 基本数据类型变量初始化后不能修改， 引用类型初始化后不能指向别的对象， 比如final的hashmapp， 里面的值还是可以修改的。也可以修饰方法的参数，参数在方法执行过程中不能变化。\n\n\n## Collections.unmodifiableXXX\n\t\n## Guava: ImmutableXXX\n\n\n\n","slug":"不可变对象","published":1,"updated":"2018-09-08T14:15:40.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjofoeaur0006d922s5q7gzxt","content":"<h1 id=\"不可变对象需要满足条件\"><a href=\"#不可变对象需要满足条件\" class=\"headerlink\" title=\"不可变对象需要满足条件\"></a>不可变对象需要满足条件</h1><ol>\n<li>对象创建以后状态不能修改</li>\n<li>对象所有域都是final类型</li>\n<li>对象是正确创建的（在对象创建期间， this引用没有逸出）</li>\n</ol>\n<h2 id=\"final关键字\"><a href=\"#final关键字\" class=\"headerlink\" title=\"final关键字\"></a>final关键字</h2><p>final能修饰类、 方法和变量</p>\n<ul>\n<li>修饰类： 不能被继承</li>\n<li>final类中的方法默认为final</li>\n<li>修饰方法： 1、 锁定方法不能被继承类修改； 2、 效率， 早期java版本中会把final方法转为内嵌调用，<br>但是如果方法过大， 看不到内嵌方法带来的性能提升， 3、 private方法默认是final的，不能被子类覆盖</li>\n<li>修饰变量： 基本数据类型变量初始化后不能修改， 引用类型初始化后不能指向别的对象， 比如final的hashmapp， 里面的值还是可以修改的。也可以修饰方法的参数，参数在方法执行过程中不能变化。</li>\n</ul>\n<h2 id=\"Collections-unmodifiableXXX\"><a href=\"#Collections-unmodifiableXXX\" class=\"headerlink\" title=\"Collections.unmodifiableXXX\"></a>Collections.unmodifiableXXX</h2><h2 id=\"Guava-ImmutableXXX\"><a href=\"#Guava-ImmutableXXX\" class=\"headerlink\" title=\"Guava: ImmutableXXX\"></a>Guava: ImmutableXXX</h2>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"不可变对象需要满足条件\"><a href=\"#不可变对象需要满足条件\" class=\"headerlink\" title=\"不可变对象需要满足条件\"></a>不可变对象需要满足条件</h1><ol>\n<li>对象创建以后状态不能修改</li>\n<li>对象所有域都是final类型</li>\n<li>对象是正确创建的（在对象创建期间， this引用没有逸出）</li>\n</ol>\n<h2 id=\"final关键字\"><a href=\"#final关键字\" class=\"headerlink\" title=\"final关键字\"></a>final关键字</h2><p>final能修饰类、 方法和变量</p>\n<ul>\n<li>修饰类： 不能被继承</li>\n<li>final类中的方法默认为final</li>\n<li>修饰方法： 1、 锁定方法不能被继承类修改； 2、 效率， 早期java版本中会把final方法转为内嵌调用，<br>但是如果方法过大， 看不到内嵌方法带来的性能提升， 3、 private方法默认是final的，不能被子类覆盖</li>\n<li>修饰变量： 基本数据类型变量初始化后不能修改， 引用类型初始化后不能指向别的对象， 比如final的hashmapp， 里面的值还是可以修改的。也可以修饰方法的参数，参数在方法执行过程中不能变化。</li>\n</ul>\n<h2 id=\"Collections-unmodifiableXXX\"><a href=\"#Collections-unmodifiableXXX\" class=\"headerlink\" title=\"Collections.unmodifiableXXX\"></a>Collections.unmodifiableXXX</h2><h2 id=\"Guava-ImmutableXXX\"><a href=\"#Guava-ImmutableXXX\" class=\"headerlink\" title=\"Guava: ImmutableXXX\"></a>Guava: ImmutableXXX</h2>"},{"title":"安全发布对象","date":"2018-09-02T02:49:35.000Z","_content":"\n# 基本概念\n1. 发布对象： 使一个对象能够被当前范围之外的代码所使用\n2. 对象逸出： 一种错误的发布， 当一个对象还没构造完成时， 就使它被其他线程所见\n\n# 安全发布的方法\n1. 在静态初始化函数中初始化一个对象引用\n2. 将对象的引用保存在volatile类型域或者AtomicReference对象中\n3. 将对象的引用保存在某个正确构造对象的final类型域中\n4. 将对象的引用保存在一个由锁保护的域中\n\n## 单例模式发布对象\n1. 懒汉模式（通过加锁来确保线程安全， 第一次使用到单例实例的时候进行创建）\n\n// 双重同步锁检测机制不是线程安全的\n// 1. memory = allocate() 分配对象内存空间\n// 2. ctorInstance() 初始化对象\n// 3. instance = memory 设置instance指向刚分配的内存\n// JVM和cpu优化， 发生了指令重拍\n// 1. memory = allocate() 分配对象内存空间\n// 3. instance = memory 设置instance指向刚分配的内存\n// 2. ctorInstance() 初始化对象\n// 线程A执行到3， 线程B会以为instance已经创建好了， 实际上还没有初始化\n\n     // 单例对象\n    private static SingletonExample1 instance = null;\n\n    // 静态的工厂方法\n    public static SingletonExample1 getInstance(){\n        if(instance == null){ //双重检测机制\n            synchronized (SingletonExample2.class) {\n                if (instance == null) {\n                    instance = new SingletonExample1();\n                }\n            }\n        }\n        return instance;\n    }\n\n    *所以单例对象要加volatile， 总结下， volatile使用场景， 一个是状态表示量， 一个是双重检测*   \n\n2. 饿汉模式（线程安全，单例实例在类装载的时候进行创建）\n\n可以通过静态域或者静态块的方式， 单例模式构造方法为private， 防止程序其他地方调用构造方法\n\t\n\tprivate SingletonExample2(){ }\n    public static SingletonExample2 instance = null;\n    static{\n        instance = new SingletonExample2();\n    }\n    public SingletonExample2 getInstance(){\n        return instance;\n    }\n\n3. 枚举模式\n\n\tpublic class SingletonExample3 {\n    \tprivate SingletonExample3(){ }\n    \tpublic static SingletonExample3 getInstance(){\n      \t  return Singleton.INSTANCE.getInstance();\n    \t}\n    \tprivate enum Singleton {\n        \tINSTANCE;\n        \tprivate SingletonExample3 singletonExample;\n\t        // JVM 保证这个方法绝对只调用一次\n    \t    Singleton(){\n        \t    singletonExample = new SingletonExample3();\n        \t}\n        \tpublic SingletonExample3 getInstance(){\n            \treturn singletonExample;\n        \t}\n    \t}\n\t}\n\n最安全， 同时像饿汉模式一样在类加载时候初始化","source":"_posts/安全发布对象.md","raw":"---\ntitle: 安全发布对象\ndate: 2018-09-02 10:49:35\ntags:\n---\n\n# 基本概念\n1. 发布对象： 使一个对象能够被当前范围之外的代码所使用\n2. 对象逸出： 一种错误的发布， 当一个对象还没构造完成时， 就使它被其他线程所见\n\n# 安全发布的方法\n1. 在静态初始化函数中初始化一个对象引用\n2. 将对象的引用保存在volatile类型域或者AtomicReference对象中\n3. 将对象的引用保存在某个正确构造对象的final类型域中\n4. 将对象的引用保存在一个由锁保护的域中\n\n## 单例模式发布对象\n1. 懒汉模式（通过加锁来确保线程安全， 第一次使用到单例实例的时候进行创建）\n\n// 双重同步锁检测机制不是线程安全的\n// 1. memory = allocate() 分配对象内存空间\n// 2. ctorInstance() 初始化对象\n// 3. instance = memory 设置instance指向刚分配的内存\n// JVM和cpu优化， 发生了指令重拍\n// 1. memory = allocate() 分配对象内存空间\n// 3. instance = memory 设置instance指向刚分配的内存\n// 2. ctorInstance() 初始化对象\n// 线程A执行到3， 线程B会以为instance已经创建好了， 实际上还没有初始化\n\n     // 单例对象\n    private static SingletonExample1 instance = null;\n\n    // 静态的工厂方法\n    public static SingletonExample1 getInstance(){\n        if(instance == null){ //双重检测机制\n            synchronized (SingletonExample2.class) {\n                if (instance == null) {\n                    instance = new SingletonExample1();\n                }\n            }\n        }\n        return instance;\n    }\n\n    *所以单例对象要加volatile， 总结下， volatile使用场景， 一个是状态表示量， 一个是双重检测*   \n\n2. 饿汉模式（线程安全，单例实例在类装载的时候进行创建）\n\n可以通过静态域或者静态块的方式， 单例模式构造方法为private， 防止程序其他地方调用构造方法\n\t\n\tprivate SingletonExample2(){ }\n    public static SingletonExample2 instance = null;\n    static{\n        instance = new SingletonExample2();\n    }\n    public SingletonExample2 getInstance(){\n        return instance;\n    }\n\n3. 枚举模式\n\n\tpublic class SingletonExample3 {\n    \tprivate SingletonExample3(){ }\n    \tpublic static SingletonExample3 getInstance(){\n      \t  return Singleton.INSTANCE.getInstance();\n    \t}\n    \tprivate enum Singleton {\n        \tINSTANCE;\n        \tprivate SingletonExample3 singletonExample;\n\t        // JVM 保证这个方法绝对只调用一次\n    \t    Singleton(){\n        \t    singletonExample = new SingletonExample3();\n        \t}\n        \tpublic SingletonExample3 getInstance(){\n            \treturn singletonExample;\n        \t}\n    \t}\n\t}\n\n最安全， 同时像饿汉模式一样在类加载时候初始化","slug":"安全发布对象","published":1,"updated":"2018-09-08T14:15:40.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjofoeaut0007d922454epe5u","content":"<h1 id=\"基本概念\"><a href=\"#基本概念\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h1><ol>\n<li>发布对象： 使一个对象能够被当前范围之外的代码所使用</li>\n<li>对象逸出： 一种错误的发布， 当一个对象还没构造完成时， 就使它被其他线程所见</li>\n</ol>\n<h1 id=\"安全发布的方法\"><a href=\"#安全发布的方法\" class=\"headerlink\" title=\"安全发布的方法\"></a>安全发布的方法</h1><ol>\n<li>在静态初始化函数中初始化一个对象引用</li>\n<li>将对象的引用保存在volatile类型域或者AtomicReference对象中</li>\n<li>将对象的引用保存在某个正确构造对象的final类型域中</li>\n<li>将对象的引用保存在一个由锁保护的域中</li>\n</ol>\n<h2 id=\"单例模式发布对象\"><a href=\"#单例模式发布对象\" class=\"headerlink\" title=\"单例模式发布对象\"></a>单例模式发布对象</h2><ol>\n<li>懒汉模式（通过加锁来确保线程安全， 第一次使用到单例实例的时候进行创建）</li>\n</ol>\n<p>// 双重同步锁检测机制不是线程安全的<br>// 1. memory = allocate() 分配对象内存空间<br>// 2. ctorInstance() 初始化对象<br>// 3. instance = memory 设置instance指向刚分配的内存<br>// JVM和cpu优化， 发生了指令重拍<br>// 1. memory = allocate() 分配对象内存空间<br>// 3. instance = memory 设置instance指向刚分配的内存<br>// 2. ctorInstance() 初始化对象<br>// 线程A执行到3， 线程B会以为instance已经创建好了， 实际上还没有初始化</p>\n<pre><code> // 单例对象\nprivate static SingletonExample1 instance = null;\n\n// 静态的工厂方法\npublic static SingletonExample1 getInstance(){\n    if(instance == null){ //双重检测机制\n        synchronized (SingletonExample2.class) {\n            if (instance == null) {\n                instance = new SingletonExample1();\n            }\n        }\n    }\n    return instance;\n}\n\n*所以单例对象要加volatile， 总结下， volatile使用场景， 一个是状态表示量， 一个是双重检测*   \n</code></pre><ol start=\"2\">\n<li>饿汉模式（线程安全，单例实例在类装载的时候进行创建）</li>\n</ol>\n<p>可以通过静态域或者静态块的方式， 单例模式构造方法为private， 防止程序其他地方调用构造方法</p>\n<pre><code>private SingletonExample2(){ }\npublic static SingletonExample2 instance = null;\nstatic{\n    instance = new SingletonExample2();\n}\npublic SingletonExample2 getInstance(){\n    return instance;\n}\n</code></pre><ol start=\"3\">\n<li><p>枚举模式</p>\n<p> public class SingletonExample3 {</p>\n<pre><code>private SingletonExample3(){ }\npublic static SingletonExample3 getInstance(){\n    return Singleton.INSTANCE.getInstance();\n}\nprivate enum Singleton {\n    INSTANCE;\n    private SingletonExample3 singletonExample;\n    // JVM 保证这个方法绝对只调用一次\n    Singleton(){\n        singletonExample = new SingletonExample3();\n    }\n    public SingletonExample3 getInstance(){\n        return singletonExample;\n    }\n}\n</code></pre><p> }</p>\n</li>\n</ol>\n<p>最安全， 同时像饿汉模式一样在类加载时候初始化</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"基本概念\"><a href=\"#基本概念\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h1><ol>\n<li>发布对象： 使一个对象能够被当前范围之外的代码所使用</li>\n<li>对象逸出： 一种错误的发布， 当一个对象还没构造完成时， 就使它被其他线程所见</li>\n</ol>\n<h1 id=\"安全发布的方法\"><a href=\"#安全发布的方法\" class=\"headerlink\" title=\"安全发布的方法\"></a>安全发布的方法</h1><ol>\n<li>在静态初始化函数中初始化一个对象引用</li>\n<li>将对象的引用保存在volatile类型域或者AtomicReference对象中</li>\n<li>将对象的引用保存在某个正确构造对象的final类型域中</li>\n<li>将对象的引用保存在一个由锁保护的域中</li>\n</ol>\n<h2 id=\"单例模式发布对象\"><a href=\"#单例模式发布对象\" class=\"headerlink\" title=\"单例模式发布对象\"></a>单例模式发布对象</h2><ol>\n<li>懒汉模式（通过加锁来确保线程安全， 第一次使用到单例实例的时候进行创建）</li>\n</ol>\n<p>// 双重同步锁检测机制不是线程安全的<br>// 1. memory = allocate() 分配对象内存空间<br>// 2. ctorInstance() 初始化对象<br>// 3. instance = memory 设置instance指向刚分配的内存<br>// JVM和cpu优化， 发生了指令重拍<br>// 1. memory = allocate() 分配对象内存空间<br>// 3. instance = memory 设置instance指向刚分配的内存<br>// 2. ctorInstance() 初始化对象<br>// 线程A执行到3， 线程B会以为instance已经创建好了， 实际上还没有初始化</p>\n<pre><code> // 单例对象\nprivate static SingletonExample1 instance = null;\n\n// 静态的工厂方法\npublic static SingletonExample1 getInstance(){\n    if(instance == null){ //双重检测机制\n        synchronized (SingletonExample2.class) {\n            if (instance == null) {\n                instance = new SingletonExample1();\n            }\n        }\n    }\n    return instance;\n}\n\n*所以单例对象要加volatile， 总结下， volatile使用场景， 一个是状态表示量， 一个是双重检测*   \n</code></pre><ol start=\"2\">\n<li>饿汉模式（线程安全，单例实例在类装载的时候进行创建）</li>\n</ol>\n<p>可以通过静态域或者静态块的方式， 单例模式构造方法为private， 防止程序其他地方调用构造方法</p>\n<pre><code>private SingletonExample2(){ }\npublic static SingletonExample2 instance = null;\nstatic{\n    instance = new SingletonExample2();\n}\npublic SingletonExample2 getInstance(){\n    return instance;\n}\n</code></pre><ol start=\"3\">\n<li><p>枚举模式</p>\n<p> public class SingletonExample3 {</p>\n<pre><code>private SingletonExample3(){ }\npublic static SingletonExample3 getInstance(){\n    return Singleton.INSTANCE.getInstance();\n}\nprivate enum Singleton {\n    INSTANCE;\n    private SingletonExample3 singletonExample;\n    // JVM 保证这个方法绝对只调用一次\n    Singleton(){\n        singletonExample = new SingletonExample3();\n    }\n    public SingletonExample3 getInstance(){\n        return singletonExample;\n    }\n}\n</code></pre><p> }</p>\n</li>\n</ol>\n<p>最安全， 同时像饿汉模式一样在类加载时候初始化</p>\n"},{"title":"数据库切库分库分表","date":"2018-10-09T03:15:41.000Z","_content":"\n# 数据库瓶颈\n单个库数据量太大（1T到2T）：  多个库\n单个数据库服务器压力过大, 读写瓶颈：  多个库\n单个表数据量过： 分表\n\n# 数据库切库\n切库的的实际应用： 读写分离\n主库主要负责数据更新和实时数据查找\n从库负责非实时数据的查找\n\n目前的方式：\n* 动态数据源切换： 通过注解， spring AOP\n* 数据库支持多数据源： 代码实现\n\n# 数据库分表\n## 横向分表\n比如股票数据表， 分为100张表， 按股票id取余的方式选择存储表\n## 纵向分表\n最好冷热数据分到不同的表中\n可以使用mybatis分表插件shardbatis2.0\n\n\n\n\n\n","source":"_posts/数据库切库分库分表.md","raw":"---\ntitle: 数据库切库分库分表\ndate: 2018-10-09 11:15:41\ntags:\n---\n\n# 数据库瓶颈\n单个库数据量太大（1T到2T）：  多个库\n单个数据库服务器压力过大, 读写瓶颈：  多个库\n单个表数据量过： 分表\n\n# 数据库切库\n切库的的实际应用： 读写分离\n主库主要负责数据更新和实时数据查找\n从库负责非实时数据的查找\n\n目前的方式：\n* 动态数据源切换： 通过注解， spring AOP\n* 数据库支持多数据源： 代码实现\n\n# 数据库分表\n## 横向分表\n比如股票数据表， 分为100张表， 按股票id取余的方式选择存储表\n## 纵向分表\n最好冷热数据分到不同的表中\n可以使用mybatis分表插件shardbatis2.0\n\n\n\n\n\n","slug":"数据库切库分库分表","published":1,"updated":"2018-11-13T11:50:06.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjofoeauu0008d922c5pay1be","content":"<h1 id=\"数据库瓶颈\"><a href=\"#数据库瓶颈\" class=\"headerlink\" title=\"数据库瓶颈\"></a>数据库瓶颈</h1><p>单个库数据量太大（1T到2T）：  多个库<br>单个数据库服务器压力过大, 读写瓶颈：  多个库<br>单个表数据量过： 分表</p>\n<h1 id=\"数据库切库\"><a href=\"#数据库切库\" class=\"headerlink\" title=\"数据库切库\"></a>数据库切库</h1><p>切库的的实际应用： 读写分离<br>主库主要负责数据更新和实时数据查找<br>从库负责非实时数据的查找</p>\n<p>目前的方式：</p>\n<ul>\n<li>动态数据源切换： 通过注解， spring AOP</li>\n<li>数据库支持多数据源： 代码实现</li>\n</ul>\n<h1 id=\"数据库分表\"><a href=\"#数据库分表\" class=\"headerlink\" title=\"数据库分表\"></a>数据库分表</h1><h2 id=\"横向分表\"><a href=\"#横向分表\" class=\"headerlink\" title=\"横向分表\"></a>横向分表</h2><p>比如股票数据表， 分为100张表， 按股票id取余的方式选择存储表</p>\n<h2 id=\"纵向分表\"><a href=\"#纵向分表\" class=\"headerlink\" title=\"纵向分表\"></a>纵向分表</h2><p>最好冷热数据分到不同的表中<br>可以使用mybatis分表插件shardbatis2.0</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"数据库瓶颈\"><a href=\"#数据库瓶颈\" class=\"headerlink\" title=\"数据库瓶颈\"></a>数据库瓶颈</h1><p>单个库数据量太大（1T到2T）：  多个库<br>单个数据库服务器压力过大, 读写瓶颈：  多个库<br>单个表数据量过： 分表</p>\n<h1 id=\"数据库切库\"><a href=\"#数据库切库\" class=\"headerlink\" title=\"数据库切库\"></a>数据库切库</h1><p>切库的的实际应用： 读写分离<br>主库主要负责数据更新和实时数据查找<br>从库负责非实时数据的查找</p>\n<p>目前的方式：</p>\n<ul>\n<li>动态数据源切换： 通过注解， spring AOP</li>\n<li>数据库支持多数据源： 代码实现</li>\n</ul>\n<h1 id=\"数据库分表\"><a href=\"#数据库分表\" class=\"headerlink\" title=\"数据库分表\"></a>数据库分表</h1><h2 id=\"横向分表\"><a href=\"#横向分表\" class=\"headerlink\" title=\"横向分表\"></a>横向分表</h2><p>比如股票数据表， 分为100张表， 按股票id取余的方式选择存储表</p>\n<h2 id=\"纵向分表\"><a href=\"#纵向分表\" class=\"headerlink\" title=\"纵向分表\"></a>纵向分表</h2><p>最好冷热数据分到不同的表中<br>可以使用mybatis分表插件shardbatis2.0</p>\n"},{"title":"并发基本概念","date":"2018-08-29T07:59:58.000Z","_content":"\n## 基本概念\n\n并发： 同时拥有两个或者多个线程， 如果程序在单核处理器上运行， 多个线程将交替地换入或者换出内存， 这些线程是同时“存在”的，每个线程处于执行过程中的某个状态， 如果运行在多核处理器上， 此时每个线程都能分配到一个处理器核上， 因此可以同时运行。\n\n高并发（High Concurrency）是互联网分布式系统架构设计中必须考虑的因素之一， 它通常是指， 通过设计保证系统能够**同时并行处理**很多请求。\n\n\n## CPU多级缓存\n\nCPU频率太快， 主存跟不上， 这样在处理器时钟周期内， CPU常常需要等待主存， 浪费资源。 cache出现， 是为了缓解CPU和主存之间速度不匹配 **（速度 cpu > cache > memory）**.\n\n### 缓存的意义（就算cache远远小于主存， CPU访问经常不命中）：\n\t\n\t* 时间局部性： 如果某个数据被访问， 那么不久将来也会被访问\n\t* 空间局部性： 如果某个数据被访问， 那么与它相邻的数据很快会被访问\n\n### cpu多级缓存 - 缓存一致性（MESI协议）\n\nMESI协议为了保证多个CPU cache之间缓存共享数据的一致性， 缓存控制器监听本地和远程操作的时候需要对地址一定的cache line状态做出修改。\n\n![MESI Protocal](MESI_protocal.jpg)\n\n#### 四个状态\n\n1. Modified: 该缓存行只被缓存在该CPU的缓存中，并且是被修改过（dirty），与主存的数据不一致。在允许其它CPU读取主存中相应内存之前需要写回（write back）主存。 写回后该缓存行状态变为独享（exclusive）状态。\n2. Exclusive：该缓存行只被缓存在该CPU的缓存中， 未被修改。 和主存数据一致。任何时候在其它CPU读取内存时变为共享状态（shared）。\n3. Shared：该缓存行被多个CPU缓存，各个缓存中数据与主存一致， 当一个CPU修改该缓存行， 其它CPU中该缓存行可以被作废（Invalid）\n4. Invalid：该缓存是无效的。\n\n#### 四种操作\n\n1. Local read: 读本地缓存中的数据 \n2. Local write: 数据写入本地缓存\n3. Remote read: 读取主存中的数据\n4. Remote write: 数据写回主存\n\n### 乱序执行优化\n\n处理器为提高运算速度而做出违背代码原有顺序的优化。 举个例子：\n一个核上执行数据准备操作，最后写一个标记表示准备就绪。 另外一个核通过标记来判断数据是否准备好。 这种操作存在标记位先写入问题。 数据可能还没有准备好。可能是没有计算完成， 也可能是数据没有从处理器缓存刷新到主存中。\n\n## JAVA内存模型\n\n屏蔽硬件和操作系统内存访问的差异， 在各种平台下达到一致的并发效果。JMM（Java Memory Model）是**一种规范，规范了虚拟机与计算机内存是怎么工作的。一个线程如何，何时能看到其它线程修改过的共享变量的值。以及必须时如何同步的访问共享变量。**\n\n堆（Heap）： 运行时数据区， 运行时动态分配内存， 存取速度相对慢一些。\n栈（Stack）： 存取速度比堆要快。仅次于寄存器。数据可以共享， 但是存在栈中的数据大小和生存期必须是确定的。缺乏灵活性。主要存放基本类型的变量和对象句柄。\n\n**当一个线程可以访问一个对象的时候， 它也可以访问该对象的成员变量。 如果两个线程同时调用同一个对象上的同一个方法， 它们将会都访问该对象的成员变量， 但是每个线程都拥有了该成员变量的私有拷贝。**\n\n![JMM](JMM.png)\n\nJMM主内存就是硬件的内存，本地内存是cpu的寄存器和高速缓存的一个抽象描述。JVM的内存模型只是对物理内存的划分， 只存在内存中。\n\n### 同步八种操作\n\n![JMM_8_Op](JMM_caozuo.png)\n\n1. lock: 作用于主内存变量， 把一个变量标识为一条线程独占状态 \n2. unlock： 作用于主内存变量， 把一个处于锁定状态的变量释放出来， 释放后的变量才可以被其他线程锁定\n3. read： 作用于主内存的变量， 把一个变量从主内存传输到线程的工作内存中， 以便随后的load动作使用 \n4. load： 作用于工作内存的变量， 它把read操作从主内存中得到的变量值放入工作内存的变量副本中\n5. use： 作用于工作内存的变量， 把工作内存的一个变量值传递给执行引擎\n6. assign： 作用于工作内存的变量， 它把一个从执行引擎接收到的值赋值给工作内存的变量\n7. store： 作用于工作内存的变量， 把工作内存的一个变量的值传送到主内存中， 以便随后的write操作\n8. write： 作用于主内存的变量， 它把store操作从工作内存中得到的变量值放入主内存变量\n\n### 同步规则 \n1. 不允许read和load、store和write操作之一单独出现\n2. 把变量从主内存复制到工作内存， 就需要按顺序地执行read和load操作， 如果把变量从工作内存同步到主内存中， 就需要按顺序地执行store和write操作。 java内存模型只要求上述操作按顺序执行， 而没有保证必须是连续执行。\n3. 不允许一个线程丢弃它最近的assign操作， 即变量在工作内存中改变之后必须同步到主内存中\n4. 不允许一个线程没原因（没有发生任何assign操作）把数据同步回主内存中\n5. 一个新的变量只能在主内存诞生，不允许工作内存中直接使用一个未被初始化（load或assign）的变量。也就是对一个变量实施use和store操作前， 必须先执行assign和load操作\n6. 一个变量同一时刻只允许一条线程对其lock操作， lock可以被同一条线程重复执行多次， lock和unlock必须成对出现\n7. 对一个变量的lock操作， 将会清空工作内存中此变量的值， 在执行引擎使用这个变量前需要重新执行load或者assign操作初始化这个变量的值\n8. 如果一个变量事先没有被lock操作锁定， 则不允许对它执行unlock操作， 也不允许去unlock一个被其他线程锁定的变量\n9. 对一个变量执行unlcok操作前， 必须先把变量同步到主内存中（执行store和write操作）\n\n## 并发的优势和风险\n\n![ad_disad](ad_disad.png)\n\n多线程环境下必须使用同步机制， 这导致很多编译器做的优化被抑制。\n\n\n\n\n\n\n","source":"_posts/并发基本概念.md","raw":"---\ntitle: 并发基本概念\ndate: 2018-08-29 15:59:58\ntags:\n---\n\n## 基本概念\n\n并发： 同时拥有两个或者多个线程， 如果程序在单核处理器上运行， 多个线程将交替地换入或者换出内存， 这些线程是同时“存在”的，每个线程处于执行过程中的某个状态， 如果运行在多核处理器上， 此时每个线程都能分配到一个处理器核上， 因此可以同时运行。\n\n高并发（High Concurrency）是互联网分布式系统架构设计中必须考虑的因素之一， 它通常是指， 通过设计保证系统能够**同时并行处理**很多请求。\n\n\n## CPU多级缓存\n\nCPU频率太快， 主存跟不上， 这样在处理器时钟周期内， CPU常常需要等待主存， 浪费资源。 cache出现， 是为了缓解CPU和主存之间速度不匹配 **（速度 cpu > cache > memory）**.\n\n### 缓存的意义（就算cache远远小于主存， CPU访问经常不命中）：\n\t\n\t* 时间局部性： 如果某个数据被访问， 那么不久将来也会被访问\n\t* 空间局部性： 如果某个数据被访问， 那么与它相邻的数据很快会被访问\n\n### cpu多级缓存 - 缓存一致性（MESI协议）\n\nMESI协议为了保证多个CPU cache之间缓存共享数据的一致性， 缓存控制器监听本地和远程操作的时候需要对地址一定的cache line状态做出修改。\n\n![MESI Protocal](MESI_protocal.jpg)\n\n#### 四个状态\n\n1. Modified: 该缓存行只被缓存在该CPU的缓存中，并且是被修改过（dirty），与主存的数据不一致。在允许其它CPU读取主存中相应内存之前需要写回（write back）主存。 写回后该缓存行状态变为独享（exclusive）状态。\n2. Exclusive：该缓存行只被缓存在该CPU的缓存中， 未被修改。 和主存数据一致。任何时候在其它CPU读取内存时变为共享状态（shared）。\n3. Shared：该缓存行被多个CPU缓存，各个缓存中数据与主存一致， 当一个CPU修改该缓存行， 其它CPU中该缓存行可以被作废（Invalid）\n4. Invalid：该缓存是无效的。\n\n#### 四种操作\n\n1. Local read: 读本地缓存中的数据 \n2. Local write: 数据写入本地缓存\n3. Remote read: 读取主存中的数据\n4. Remote write: 数据写回主存\n\n### 乱序执行优化\n\n处理器为提高运算速度而做出违背代码原有顺序的优化。 举个例子：\n一个核上执行数据准备操作，最后写一个标记表示准备就绪。 另外一个核通过标记来判断数据是否准备好。 这种操作存在标记位先写入问题。 数据可能还没有准备好。可能是没有计算完成， 也可能是数据没有从处理器缓存刷新到主存中。\n\n## JAVA内存模型\n\n屏蔽硬件和操作系统内存访问的差异， 在各种平台下达到一致的并发效果。JMM（Java Memory Model）是**一种规范，规范了虚拟机与计算机内存是怎么工作的。一个线程如何，何时能看到其它线程修改过的共享变量的值。以及必须时如何同步的访问共享变量。**\n\n堆（Heap）： 运行时数据区， 运行时动态分配内存， 存取速度相对慢一些。\n栈（Stack）： 存取速度比堆要快。仅次于寄存器。数据可以共享， 但是存在栈中的数据大小和生存期必须是确定的。缺乏灵活性。主要存放基本类型的变量和对象句柄。\n\n**当一个线程可以访问一个对象的时候， 它也可以访问该对象的成员变量。 如果两个线程同时调用同一个对象上的同一个方法， 它们将会都访问该对象的成员变量， 但是每个线程都拥有了该成员变量的私有拷贝。**\n\n![JMM](JMM.png)\n\nJMM主内存就是硬件的内存，本地内存是cpu的寄存器和高速缓存的一个抽象描述。JVM的内存模型只是对物理内存的划分， 只存在内存中。\n\n### 同步八种操作\n\n![JMM_8_Op](JMM_caozuo.png)\n\n1. lock: 作用于主内存变量， 把一个变量标识为一条线程独占状态 \n2. unlock： 作用于主内存变量， 把一个处于锁定状态的变量释放出来， 释放后的变量才可以被其他线程锁定\n3. read： 作用于主内存的变量， 把一个变量从主内存传输到线程的工作内存中， 以便随后的load动作使用 \n4. load： 作用于工作内存的变量， 它把read操作从主内存中得到的变量值放入工作内存的变量副本中\n5. use： 作用于工作内存的变量， 把工作内存的一个变量值传递给执行引擎\n6. assign： 作用于工作内存的变量， 它把一个从执行引擎接收到的值赋值给工作内存的变量\n7. store： 作用于工作内存的变量， 把工作内存的一个变量的值传送到主内存中， 以便随后的write操作\n8. write： 作用于主内存的变量， 它把store操作从工作内存中得到的变量值放入主内存变量\n\n### 同步规则 \n1. 不允许read和load、store和write操作之一单独出现\n2. 把变量从主内存复制到工作内存， 就需要按顺序地执行read和load操作， 如果把变量从工作内存同步到主内存中， 就需要按顺序地执行store和write操作。 java内存模型只要求上述操作按顺序执行， 而没有保证必须是连续执行。\n3. 不允许一个线程丢弃它最近的assign操作， 即变量在工作内存中改变之后必须同步到主内存中\n4. 不允许一个线程没原因（没有发生任何assign操作）把数据同步回主内存中\n5. 一个新的变量只能在主内存诞生，不允许工作内存中直接使用一个未被初始化（load或assign）的变量。也就是对一个变量实施use和store操作前， 必须先执行assign和load操作\n6. 一个变量同一时刻只允许一条线程对其lock操作， lock可以被同一条线程重复执行多次， lock和unlock必须成对出现\n7. 对一个变量的lock操作， 将会清空工作内存中此变量的值， 在执行引擎使用这个变量前需要重新执行load或者assign操作初始化这个变量的值\n8. 如果一个变量事先没有被lock操作锁定， 则不允许对它执行unlock操作， 也不允许去unlock一个被其他线程锁定的变量\n9. 对一个变量执行unlcok操作前， 必须先把变量同步到主内存中（执行store和write操作）\n\n## 并发的优势和风险\n\n![ad_disad](ad_disad.png)\n\n多线程环境下必须使用同步机制， 这导致很多编译器做的优化被抑制。\n\n\n\n\n\n\n","slug":"并发基本概念","published":1,"updated":"2018-09-08T14:15:40.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjofoeauw0009d922ppjuarv4","content":"<h2 id=\"基本概念\"><a href=\"#基本概念\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h2><p>并发： 同时拥有两个或者多个线程， 如果程序在单核处理器上运行， 多个线程将交替地换入或者换出内存， 这些线程是同时“存在”的，每个线程处于执行过程中的某个状态， 如果运行在多核处理器上， 此时每个线程都能分配到一个处理器核上， 因此可以同时运行。</p>\n<p>高并发（High Concurrency）是互联网分布式系统架构设计中必须考虑的因素之一， 它通常是指， 通过设计保证系统能够<strong>同时并行处理</strong>很多请求。</p>\n<h2 id=\"CPU多级缓存\"><a href=\"#CPU多级缓存\" class=\"headerlink\" title=\"CPU多级缓存\"></a>CPU多级缓存</h2><p>CPU频率太快， 主存跟不上， 这样在处理器时钟周期内， CPU常常需要等待主存， 浪费资源。 cache出现， 是为了缓解CPU和主存之间速度不匹配 <strong>（速度 cpu &gt; cache &gt; memory）</strong>.</p>\n<h3 id=\"缓存的意义（就算cache远远小于主存，-CPU访问经常不命中）：\"><a href=\"#缓存的意义（就算cache远远小于主存，-CPU访问经常不命中）：\" class=\"headerlink\" title=\"缓存的意义（就算cache远远小于主存， CPU访问经常不命中）：\"></a>缓存的意义（就算cache远远小于主存， CPU访问经常不命中）：</h3><pre><code>* 时间局部性： 如果某个数据被访问， 那么不久将来也会被访问\n* 空间局部性： 如果某个数据被访问， 那么与它相邻的数据很快会被访问\n</code></pre><h3 id=\"cpu多级缓存-缓存一致性（MESI协议）\"><a href=\"#cpu多级缓存-缓存一致性（MESI协议）\" class=\"headerlink\" title=\"cpu多级缓存 - 缓存一致性（MESI协议）\"></a>cpu多级缓存 - 缓存一致性（MESI协议）</h3><p>MESI协议为了保证多个CPU cache之间缓存共享数据的一致性， 缓存控制器监听本地和远程操作的时候需要对地址一定的cache line状态做出修改。</p>\n<p><img src=\"MESI_protocal.jpg\" alt=\"MESI Protocal\"></p>\n<h4 id=\"四个状态\"><a href=\"#四个状态\" class=\"headerlink\" title=\"四个状态\"></a>四个状态</h4><ol>\n<li>Modified: 该缓存行只被缓存在该CPU的缓存中，并且是被修改过（dirty），与主存的数据不一致。在允许其它CPU读取主存中相应内存之前需要写回（write back）主存。 写回后该缓存行状态变为独享（exclusive）状态。</li>\n<li>Exclusive：该缓存行只被缓存在该CPU的缓存中， 未被修改。 和主存数据一致。任何时候在其它CPU读取内存时变为共享状态（shared）。</li>\n<li>Shared：该缓存行被多个CPU缓存，各个缓存中数据与主存一致， 当一个CPU修改该缓存行， 其它CPU中该缓存行可以被作废（Invalid）</li>\n<li>Invalid：该缓存是无效的。</li>\n</ol>\n<h4 id=\"四种操作\"><a href=\"#四种操作\" class=\"headerlink\" title=\"四种操作\"></a>四种操作</h4><ol>\n<li>Local read: 读本地缓存中的数据 </li>\n<li>Local write: 数据写入本地缓存</li>\n<li>Remote read: 读取主存中的数据</li>\n<li>Remote write: 数据写回主存</li>\n</ol>\n<h3 id=\"乱序执行优化\"><a href=\"#乱序执行优化\" class=\"headerlink\" title=\"乱序执行优化\"></a>乱序执行优化</h3><p>处理器为提高运算速度而做出违背代码原有顺序的优化。 举个例子：<br>一个核上执行数据准备操作，最后写一个标记表示准备就绪。 另外一个核通过标记来判断数据是否准备好。 这种操作存在标记位先写入问题。 数据可能还没有准备好。可能是没有计算完成， 也可能是数据没有从处理器缓存刷新到主存中。</p>\n<h2 id=\"JAVA内存模型\"><a href=\"#JAVA内存模型\" class=\"headerlink\" title=\"JAVA内存模型\"></a>JAVA内存模型</h2><p>屏蔽硬件和操作系统内存访问的差异， 在各种平台下达到一致的并发效果。JMM（Java Memory Model）是<strong>一种规范，规范了虚拟机与计算机内存是怎么工作的。一个线程如何，何时能看到其它线程修改过的共享变量的值。以及必须时如何同步的访问共享变量。</strong></p>\n<p>堆（Heap）： 运行时数据区， 运行时动态分配内存， 存取速度相对慢一些。<br>栈（Stack）： 存取速度比堆要快。仅次于寄存器。数据可以共享， 但是存在栈中的数据大小和生存期必须是确定的。缺乏灵活性。主要存放基本类型的变量和对象句柄。</p>\n<p><strong>当一个线程可以访问一个对象的时候， 它也可以访问该对象的成员变量。 如果两个线程同时调用同一个对象上的同一个方法， 它们将会都访问该对象的成员变量， 但是每个线程都拥有了该成员变量的私有拷贝。</strong></p>\n<p><img src=\"JMM.png\" alt=\"JMM\"></p>\n<p>JMM主内存就是硬件的内存，本地内存是cpu的寄存器和高速缓存的一个抽象描述。JVM的内存模型只是对物理内存的划分， 只存在内存中。</p>\n<h3 id=\"同步八种操作\"><a href=\"#同步八种操作\" class=\"headerlink\" title=\"同步八种操作\"></a>同步八种操作</h3><p><img src=\"JMM_caozuo.png\" alt=\"JMM_8_Op\"></p>\n<ol>\n<li>lock: 作用于主内存变量， 把一个变量标识为一条线程独占状态 </li>\n<li>unlock： 作用于主内存变量， 把一个处于锁定状态的变量释放出来， 释放后的变量才可以被其他线程锁定</li>\n<li>read： 作用于主内存的变量， 把一个变量从主内存传输到线程的工作内存中， 以便随后的load动作使用 </li>\n<li>load： 作用于工作内存的变量， 它把read操作从主内存中得到的变量值放入工作内存的变量副本中</li>\n<li>use： 作用于工作内存的变量， 把工作内存的一个变量值传递给执行引擎</li>\n<li>assign： 作用于工作内存的变量， 它把一个从执行引擎接收到的值赋值给工作内存的变量</li>\n<li>store： 作用于工作内存的变量， 把工作内存的一个变量的值传送到主内存中， 以便随后的write操作</li>\n<li>write： 作用于主内存的变量， 它把store操作从工作内存中得到的变量值放入主内存变量</li>\n</ol>\n<h3 id=\"同步规则\"><a href=\"#同步规则\" class=\"headerlink\" title=\"同步规则\"></a>同步规则</h3><ol>\n<li>不允许read和load、store和write操作之一单独出现</li>\n<li>把变量从主内存复制到工作内存， 就需要按顺序地执行read和load操作， 如果把变量从工作内存同步到主内存中， 就需要按顺序地执行store和write操作。 java内存模型只要求上述操作按顺序执行， 而没有保证必须是连续执行。</li>\n<li>不允许一个线程丢弃它最近的assign操作， 即变量在工作内存中改变之后必须同步到主内存中</li>\n<li>不允许一个线程没原因（没有发生任何assign操作）把数据同步回主内存中</li>\n<li>一个新的变量只能在主内存诞生，不允许工作内存中直接使用一个未被初始化（load或assign）的变量。也就是对一个变量实施use和store操作前， 必须先执行assign和load操作</li>\n<li>一个变量同一时刻只允许一条线程对其lock操作， lock可以被同一条线程重复执行多次， lock和unlock必须成对出现</li>\n<li>对一个变量的lock操作， 将会清空工作内存中此变量的值， 在执行引擎使用这个变量前需要重新执行load或者assign操作初始化这个变量的值</li>\n<li>如果一个变量事先没有被lock操作锁定， 则不允许对它执行unlock操作， 也不允许去unlock一个被其他线程锁定的变量</li>\n<li>对一个变量执行unlcok操作前， 必须先把变量同步到主内存中（执行store和write操作）</li>\n</ol>\n<h2 id=\"并发的优势和风险\"><a href=\"#并发的优势和风险\" class=\"headerlink\" title=\"并发的优势和风险\"></a>并发的优势和风险</h2><p><img src=\"ad_disad.png\" alt=\"ad_disad\"></p>\n<p>多线程环境下必须使用同步机制， 这导致很多编译器做的优化被抑制。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"基本概念\"><a href=\"#基本概念\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h2><p>并发： 同时拥有两个或者多个线程， 如果程序在单核处理器上运行， 多个线程将交替地换入或者换出内存， 这些线程是同时“存在”的，每个线程处于执行过程中的某个状态， 如果运行在多核处理器上， 此时每个线程都能分配到一个处理器核上， 因此可以同时运行。</p>\n<p>高并发（High Concurrency）是互联网分布式系统架构设计中必须考虑的因素之一， 它通常是指， 通过设计保证系统能够<strong>同时并行处理</strong>很多请求。</p>\n<h2 id=\"CPU多级缓存\"><a href=\"#CPU多级缓存\" class=\"headerlink\" title=\"CPU多级缓存\"></a>CPU多级缓存</h2><p>CPU频率太快， 主存跟不上， 这样在处理器时钟周期内， CPU常常需要等待主存， 浪费资源。 cache出现， 是为了缓解CPU和主存之间速度不匹配 <strong>（速度 cpu &gt; cache &gt; memory）</strong>.</p>\n<h3 id=\"缓存的意义（就算cache远远小于主存，-CPU访问经常不命中）：\"><a href=\"#缓存的意义（就算cache远远小于主存，-CPU访问经常不命中）：\" class=\"headerlink\" title=\"缓存的意义（就算cache远远小于主存， CPU访问经常不命中）：\"></a>缓存的意义（就算cache远远小于主存， CPU访问经常不命中）：</h3><pre><code>* 时间局部性： 如果某个数据被访问， 那么不久将来也会被访问\n* 空间局部性： 如果某个数据被访问， 那么与它相邻的数据很快会被访问\n</code></pre><h3 id=\"cpu多级缓存-缓存一致性（MESI协议）\"><a href=\"#cpu多级缓存-缓存一致性（MESI协议）\" class=\"headerlink\" title=\"cpu多级缓存 - 缓存一致性（MESI协议）\"></a>cpu多级缓存 - 缓存一致性（MESI协议）</h3><p>MESI协议为了保证多个CPU cache之间缓存共享数据的一致性， 缓存控制器监听本地和远程操作的时候需要对地址一定的cache line状态做出修改。</p>\n<p><img src=\"MESI_protocal.jpg\" alt=\"MESI Protocal\"></p>\n<h4 id=\"四个状态\"><a href=\"#四个状态\" class=\"headerlink\" title=\"四个状态\"></a>四个状态</h4><ol>\n<li>Modified: 该缓存行只被缓存在该CPU的缓存中，并且是被修改过（dirty），与主存的数据不一致。在允许其它CPU读取主存中相应内存之前需要写回（write back）主存。 写回后该缓存行状态变为独享（exclusive）状态。</li>\n<li>Exclusive：该缓存行只被缓存在该CPU的缓存中， 未被修改。 和主存数据一致。任何时候在其它CPU读取内存时变为共享状态（shared）。</li>\n<li>Shared：该缓存行被多个CPU缓存，各个缓存中数据与主存一致， 当一个CPU修改该缓存行， 其它CPU中该缓存行可以被作废（Invalid）</li>\n<li>Invalid：该缓存是无效的。</li>\n</ol>\n<h4 id=\"四种操作\"><a href=\"#四种操作\" class=\"headerlink\" title=\"四种操作\"></a>四种操作</h4><ol>\n<li>Local read: 读本地缓存中的数据 </li>\n<li>Local write: 数据写入本地缓存</li>\n<li>Remote read: 读取主存中的数据</li>\n<li>Remote write: 数据写回主存</li>\n</ol>\n<h3 id=\"乱序执行优化\"><a href=\"#乱序执行优化\" class=\"headerlink\" title=\"乱序执行优化\"></a>乱序执行优化</h3><p>处理器为提高运算速度而做出违背代码原有顺序的优化。 举个例子：<br>一个核上执行数据准备操作，最后写一个标记表示准备就绪。 另外一个核通过标记来判断数据是否准备好。 这种操作存在标记位先写入问题。 数据可能还没有准备好。可能是没有计算完成， 也可能是数据没有从处理器缓存刷新到主存中。</p>\n<h2 id=\"JAVA内存模型\"><a href=\"#JAVA内存模型\" class=\"headerlink\" title=\"JAVA内存模型\"></a>JAVA内存模型</h2><p>屏蔽硬件和操作系统内存访问的差异， 在各种平台下达到一致的并发效果。JMM（Java Memory Model）是<strong>一种规范，规范了虚拟机与计算机内存是怎么工作的。一个线程如何，何时能看到其它线程修改过的共享变量的值。以及必须时如何同步的访问共享变量。</strong></p>\n<p>堆（Heap）： 运行时数据区， 运行时动态分配内存， 存取速度相对慢一些。<br>栈（Stack）： 存取速度比堆要快。仅次于寄存器。数据可以共享， 但是存在栈中的数据大小和生存期必须是确定的。缺乏灵活性。主要存放基本类型的变量和对象句柄。</p>\n<p><strong>当一个线程可以访问一个对象的时候， 它也可以访问该对象的成员变量。 如果两个线程同时调用同一个对象上的同一个方法， 它们将会都访问该对象的成员变量， 但是每个线程都拥有了该成员变量的私有拷贝。</strong></p>\n<p><img src=\"JMM.png\" alt=\"JMM\"></p>\n<p>JMM主内存就是硬件的内存，本地内存是cpu的寄存器和高速缓存的一个抽象描述。JVM的内存模型只是对物理内存的划分， 只存在内存中。</p>\n<h3 id=\"同步八种操作\"><a href=\"#同步八种操作\" class=\"headerlink\" title=\"同步八种操作\"></a>同步八种操作</h3><p><img src=\"JMM_caozuo.png\" alt=\"JMM_8_Op\"></p>\n<ol>\n<li>lock: 作用于主内存变量， 把一个变量标识为一条线程独占状态 </li>\n<li>unlock： 作用于主内存变量， 把一个处于锁定状态的变量释放出来， 释放后的变量才可以被其他线程锁定</li>\n<li>read： 作用于主内存的变量， 把一个变量从主内存传输到线程的工作内存中， 以便随后的load动作使用 </li>\n<li>load： 作用于工作内存的变量， 它把read操作从主内存中得到的变量值放入工作内存的变量副本中</li>\n<li>use： 作用于工作内存的变量， 把工作内存的一个变量值传递给执行引擎</li>\n<li>assign： 作用于工作内存的变量， 它把一个从执行引擎接收到的值赋值给工作内存的变量</li>\n<li>store： 作用于工作内存的变量， 把工作内存的一个变量的值传送到主内存中， 以便随后的write操作</li>\n<li>write： 作用于主内存的变量， 它把store操作从工作内存中得到的变量值放入主内存变量</li>\n</ol>\n<h3 id=\"同步规则\"><a href=\"#同步规则\" class=\"headerlink\" title=\"同步规则\"></a>同步规则</h3><ol>\n<li>不允许read和load、store和write操作之一单独出现</li>\n<li>把变量从主内存复制到工作内存， 就需要按顺序地执行read和load操作， 如果把变量从工作内存同步到主内存中， 就需要按顺序地执行store和write操作。 java内存模型只要求上述操作按顺序执行， 而没有保证必须是连续执行。</li>\n<li>不允许一个线程丢弃它最近的assign操作， 即变量在工作内存中改变之后必须同步到主内存中</li>\n<li>不允许一个线程没原因（没有发生任何assign操作）把数据同步回主内存中</li>\n<li>一个新的变量只能在主内存诞生，不允许工作内存中直接使用一个未被初始化（load或assign）的变量。也就是对一个变量实施use和store操作前， 必须先执行assign和load操作</li>\n<li>一个变量同一时刻只允许一条线程对其lock操作， lock可以被同一条线程重复执行多次， lock和unlock必须成对出现</li>\n<li>对一个变量的lock操作， 将会清空工作内存中此变量的值， 在执行引擎使用这个变量前需要重新执行load或者assign操作初始化这个变量的值</li>\n<li>如果一个变量事先没有被lock操作锁定， 则不允许对它执行unlock操作， 也不允许去unlock一个被其他线程锁定的变量</li>\n<li>对一个变量执行unlcok操作前， 必须先把变量同步到主内存中（执行store和write操作）</li>\n</ol>\n<h2 id=\"并发的优势和风险\"><a href=\"#并发的优势和风险\" class=\"headerlink\" title=\"并发的优势和风险\"></a>并发的优势和风险</h2><p><img src=\"ad_disad.png\" alt=\"ad_disad\"></p>\n<p>多线程环境下必须使用同步机制， 这导致很多编译器做的优化被抑制。</p>\n"},{"title":"简单并发场景模拟","date":"2018-08-30T13:43:30.000Z","_content":"\n## Postman\n\nHttp请求模拟工具， 也能模拟并发， 但是不是很专业\n\n## Apache Bench (AB)\n\nApache附带的工具， 测试网站性能， 简单好用， 没有强大的图形界面支持\n\n## JMeter\n\nApache开发的压力测试工具\n\n## 并发模拟代码\n\n模拟多线程并发累加count计数器变量。\n\n### Semaphore\n\n用到Semaphore信号量来模拟同时允许多少线程执行， 如果不能获取信号量， 线程就阻塞。 Semaphore内部主要通过AQS（AbstractQueuedSynchronizer）实现线程的管理。 线程运行时首先获取许可permits, 如果成功， 书可数减1， 如果线程运行完释放许可， 许可数就加1. 许可数为0， 则获取失败。 \n\n### CountDownLatch\n\nCountDownLatch模拟计数器闭锁， 赋值为总的请求数， 每个请求执行完countdown一次。 await操作能被执行说明所有线程执行完。 一个典型的应用场景是启动一个服务时， 主线程需要等待多个组件加载完毕， 之后再继续执行。\n\n\n\n\tpublic class ConcurrencyTest {\n    \t// 请求总数\n    \tpublic static int clientTotal = 5000;\n    \t// 同时并发执行的线程数\n    \tpublic static int threadTotal = 200;\n\n    \tpublic static int count = 0;\n    \tpublic static void main(String[] args) throws InterruptedException {\n        \tExecutorService executorService = Executors.newCachedThreadPool();\n        \t// 信号量\n        \tfinal Semaphore semaphore = new Semaphore(threadTotal);\n        \t// 计数器闭锁\n        \tfinal CountDownLatch countDownLatch = new CountDownLatch(clientTotal);\n        \tfor(int i = 0; i < clientTotal; i++){\n            \texecutorService.execute(() -> {\n                \ttry {\n                    \t// 信号量模拟同时允许多少个线程执行， 达到一定并发数add会被阻塞\n                    \tsemaphore.acquire();\n                    \tadd();\n                    \tsemaphore.release();\n                \t} catch (InterruptedException e) {\n                    \te.printStackTrace();\n                    \tlog.error(\"Exception\", e);\n                \t}\n                \t// 执行完一次， 计数值减一\n                \tcountDownLatch.countDown();\n            \t});\n        \t}\n        \t// 保证countdownLatch必须减为0， 这表明所有线程都执行完\n        \tcountDownLatch.await();\n        \texecutorService.shutdown();\n        \tlog.info(\"Count:{}\", count);\n    \t}\n    \tprivate static void add(){\n        \tcount++;\n    \t}\n\t}\n\n\n每次执行结果count值会变， 说明存在并发问题。\n\t\n\n","source":"_posts/并发模拟.md","raw":"---\ntitle: 简单并发场景模拟\ndate: 2018-08-30 21:43:30\ntags:\n---\n\n## Postman\n\nHttp请求模拟工具， 也能模拟并发， 但是不是很专业\n\n## Apache Bench (AB)\n\nApache附带的工具， 测试网站性能， 简单好用， 没有强大的图形界面支持\n\n## JMeter\n\nApache开发的压力测试工具\n\n## 并发模拟代码\n\n模拟多线程并发累加count计数器变量。\n\n### Semaphore\n\n用到Semaphore信号量来模拟同时允许多少线程执行， 如果不能获取信号量， 线程就阻塞。 Semaphore内部主要通过AQS（AbstractQueuedSynchronizer）实现线程的管理。 线程运行时首先获取许可permits, 如果成功， 书可数减1， 如果线程运行完释放许可， 许可数就加1. 许可数为0， 则获取失败。 \n\n### CountDownLatch\n\nCountDownLatch模拟计数器闭锁， 赋值为总的请求数， 每个请求执行完countdown一次。 await操作能被执行说明所有线程执行完。 一个典型的应用场景是启动一个服务时， 主线程需要等待多个组件加载完毕， 之后再继续执行。\n\n\n\n\tpublic class ConcurrencyTest {\n    \t// 请求总数\n    \tpublic static int clientTotal = 5000;\n    \t// 同时并发执行的线程数\n    \tpublic static int threadTotal = 200;\n\n    \tpublic static int count = 0;\n    \tpublic static void main(String[] args) throws InterruptedException {\n        \tExecutorService executorService = Executors.newCachedThreadPool();\n        \t// 信号量\n        \tfinal Semaphore semaphore = new Semaphore(threadTotal);\n        \t// 计数器闭锁\n        \tfinal CountDownLatch countDownLatch = new CountDownLatch(clientTotal);\n        \tfor(int i = 0; i < clientTotal; i++){\n            \texecutorService.execute(() -> {\n                \ttry {\n                    \t// 信号量模拟同时允许多少个线程执行， 达到一定并发数add会被阻塞\n                    \tsemaphore.acquire();\n                    \tadd();\n                    \tsemaphore.release();\n                \t} catch (InterruptedException e) {\n                    \te.printStackTrace();\n                    \tlog.error(\"Exception\", e);\n                \t}\n                \t// 执行完一次， 计数值减一\n                \tcountDownLatch.countDown();\n            \t});\n        \t}\n        \t// 保证countdownLatch必须减为0， 这表明所有线程都执行完\n        \tcountDownLatch.await();\n        \texecutorService.shutdown();\n        \tlog.info(\"Count:{}\", count);\n    \t}\n    \tprivate static void add(){\n        \tcount++;\n    \t}\n\t}\n\n\n每次执行结果count值会变， 说明存在并发问题。\n\t\n\n","slug":"并发模拟","published":1,"updated":"2018-08-31T05:49:30.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjofoeaux000ad922gwyoqfr3","content":"<h2 id=\"Postman\"><a href=\"#Postman\" class=\"headerlink\" title=\"Postman\"></a>Postman</h2><p>Http请求模拟工具， 也能模拟并发， 但是不是很专业</p>\n<h2 id=\"Apache-Bench-AB\"><a href=\"#Apache-Bench-AB\" class=\"headerlink\" title=\"Apache Bench (AB)\"></a>Apache Bench (AB)</h2><p>Apache附带的工具， 测试网站性能， 简单好用， 没有强大的图形界面支持</p>\n<h2 id=\"JMeter\"><a href=\"#JMeter\" class=\"headerlink\" title=\"JMeter\"></a>JMeter</h2><p>Apache开发的压力测试工具</p>\n<h2 id=\"并发模拟代码\"><a href=\"#并发模拟代码\" class=\"headerlink\" title=\"并发模拟代码\"></a>并发模拟代码</h2><p>模拟多线程并发累加count计数器变量。</p>\n<h3 id=\"Semaphore\"><a href=\"#Semaphore\" class=\"headerlink\" title=\"Semaphore\"></a>Semaphore</h3><p>用到Semaphore信号量来模拟同时允许多少线程执行， 如果不能获取信号量， 线程就阻塞。 Semaphore内部主要通过AQS（AbstractQueuedSynchronizer）实现线程的管理。 线程运行时首先获取许可permits, 如果成功， 书可数减1， 如果线程运行完释放许可， 许可数就加1. 许可数为0， 则获取失败。 </p>\n<h3 id=\"CountDownLatch\"><a href=\"#CountDownLatch\" class=\"headerlink\" title=\"CountDownLatch\"></a>CountDownLatch</h3><p>CountDownLatch模拟计数器闭锁， 赋值为总的请求数， 每个请求执行完countdown一次。 await操作能被执行说明所有线程执行完。 一个典型的应用场景是启动一个服务时， 主线程需要等待多个组件加载完毕， 之后再继续执行。</p>\n<pre><code>public class ConcurrencyTest {\n    // 请求总数\n    public static int clientTotal = 5000;\n    // 同时并发执行的线程数\n    public static int threadTotal = 200;\n\n    public static int count = 0;\n    public static void main(String[] args) throws InterruptedException {\n        ExecutorService executorService = Executors.newCachedThreadPool();\n        // 信号量\n        final Semaphore semaphore = new Semaphore(threadTotal);\n        // 计数器闭锁\n        final CountDownLatch countDownLatch = new CountDownLatch(clientTotal);\n        for(int i = 0; i &lt; clientTotal; i++){\n            executorService.execute(() -&gt; {\n                try {\n                    // 信号量模拟同时允许多少个线程执行， 达到一定并发数add会被阻塞\n                    semaphore.acquire();\n                    add();\n                    semaphore.release();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                    log.error(&quot;Exception&quot;, e);\n                }\n                // 执行完一次， 计数值减一\n                countDownLatch.countDown();\n            });\n        }\n        // 保证countdownLatch必须减为0， 这表明所有线程都执行完\n        countDownLatch.await();\n        executorService.shutdown();\n        log.info(&quot;Count:{}&quot;, count);\n    }\n    private static void add(){\n        count++;\n    }\n}\n</code></pre><p>每次执行结果count值会变， 说明存在并发问题。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Postman\"><a href=\"#Postman\" class=\"headerlink\" title=\"Postman\"></a>Postman</h2><p>Http请求模拟工具， 也能模拟并发， 但是不是很专业</p>\n<h2 id=\"Apache-Bench-AB\"><a href=\"#Apache-Bench-AB\" class=\"headerlink\" title=\"Apache Bench (AB)\"></a>Apache Bench (AB)</h2><p>Apache附带的工具， 测试网站性能， 简单好用， 没有强大的图形界面支持</p>\n<h2 id=\"JMeter\"><a href=\"#JMeter\" class=\"headerlink\" title=\"JMeter\"></a>JMeter</h2><p>Apache开发的压力测试工具</p>\n<h2 id=\"并发模拟代码\"><a href=\"#并发模拟代码\" class=\"headerlink\" title=\"并发模拟代码\"></a>并发模拟代码</h2><p>模拟多线程并发累加count计数器变量。</p>\n<h3 id=\"Semaphore\"><a href=\"#Semaphore\" class=\"headerlink\" title=\"Semaphore\"></a>Semaphore</h3><p>用到Semaphore信号量来模拟同时允许多少线程执行， 如果不能获取信号量， 线程就阻塞。 Semaphore内部主要通过AQS（AbstractQueuedSynchronizer）实现线程的管理。 线程运行时首先获取许可permits, 如果成功， 书可数减1， 如果线程运行完释放许可， 许可数就加1. 许可数为0， 则获取失败。 </p>\n<h3 id=\"CountDownLatch\"><a href=\"#CountDownLatch\" class=\"headerlink\" title=\"CountDownLatch\"></a>CountDownLatch</h3><p>CountDownLatch模拟计数器闭锁， 赋值为总的请求数， 每个请求执行完countdown一次。 await操作能被执行说明所有线程执行完。 一个典型的应用场景是启动一个服务时， 主线程需要等待多个组件加载完毕， 之后再继续执行。</p>\n<pre><code>public class ConcurrencyTest {\n    // 请求总数\n    public static int clientTotal = 5000;\n    // 同时并发执行的线程数\n    public static int threadTotal = 200;\n\n    public static int count = 0;\n    public static void main(String[] args) throws InterruptedException {\n        ExecutorService executorService = Executors.newCachedThreadPool();\n        // 信号量\n        final Semaphore semaphore = new Semaphore(threadTotal);\n        // 计数器闭锁\n        final CountDownLatch countDownLatch = new CountDownLatch(clientTotal);\n        for(int i = 0; i &lt; clientTotal; i++){\n            executorService.execute(() -&gt; {\n                try {\n                    // 信号量模拟同时允许多少个线程执行， 达到一定并发数add会被阻塞\n                    semaphore.acquire();\n                    add();\n                    semaphore.release();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                    log.error(&quot;Exception&quot;, e);\n                }\n                // 执行完一次， 计数值减一\n                countDownLatch.countDown();\n            });\n        }\n        // 保证countdownLatch必须减为0， 这表明所有线程都执行完\n        countDownLatch.await();\n        executorService.shutdown();\n        log.info(&quot;Count:{}&quot;, count);\n    }\n    private static void add(){\n        count++;\n    }\n}\n</code></pre><p>每次执行结果count值会变， 说明存在并发问题。</p>\n"},{"title":"数据结构-集合和映射","date":"2018-09-07T06:21:21.000Z","_content":"\n# 集合\n为了去重，可以用于客户统计（同一个ip访问网站算一次， 本文词汇量统计。。）， 二分搜索树不能盛放重复元素， 所以是一个非常好的实现集合的底层数据结构。\n\n\n","source":"_posts/数据结构-集合和映射.md","raw":"---\ntitle: 数据结构-集合和映射\ndate: 2018-09-07 14:21:21\ntags:\n---\n\n# 集合\n为了去重，可以用于客户统计（同一个ip访问网站算一次， 本文词汇量统计。。）， 二分搜索树不能盛放重复元素， 所以是一个非常好的实现集合的底层数据结构。\n\n\n","slug":"数据结构-集合和映射","published":1,"updated":"2018-09-08T16:12:40.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjofoeauy000bd922z6bmzo0g","content":"<h1 id=\"集合\"><a href=\"#集合\" class=\"headerlink\" title=\"集合\"></a>集合</h1><p>为了去重，可以用于客户统计（同一个ip访问网站算一次， 本文词汇量统计。。）， 二分搜索树不能盛放重复元素， 所以是一个非常好的实现集合的底层数据结构。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"集合\"><a href=\"#集合\" class=\"headerlink\" title=\"集合\"></a>集合</h1><p>为了去重，可以用于客户统计（同一个ip访问网站算一次， 本文词汇量统计。。）， 二分搜索树不能盛放重复元素， 所以是一个非常好的实现集合的底层数据结构。</p>\n"},{"title":"线程不安全类与写法","date":"2018-09-04T03:29:24.000Z","_content":"\n# StingBuilder -> StringBuffer\nStringBuffer线程安全， 方法通过synchronized实现， 单线程环境或者堆栈封闭情况下使用StringBuilder\n\n# SimpleDateFormat -> JodaTime\nSimpleDateFormat不是线程安全的， 可以通过堆栈封闭方式使用\n\n# ArrayList, HashSet, HashMap等Collections\n\n# 先检查再执行： if(condition(a)){handle(a);}\n两个线程可能同时进入， 两个过程分别是线程安全的","source":"_posts/线程不安全类与写法.md","raw":"---\ntitle: 线程不安全类与写法\ndate: 2018-09-04 11:29:24\ntags:\n---\n\n# StingBuilder -> StringBuffer\nStringBuffer线程安全， 方法通过synchronized实现， 单线程环境或者堆栈封闭情况下使用StringBuilder\n\n# SimpleDateFormat -> JodaTime\nSimpleDateFormat不是线程安全的， 可以通过堆栈封闭方式使用\n\n# ArrayList, HashSet, HashMap等Collections\n\n# 先检查再执行： if(condition(a)){handle(a);}\n两个线程可能同时进入， 两个过程分别是线程安全的","slug":"线程不安全类与写法","published":1,"updated":"2018-09-08T14:15:40.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjofoeav0000cd922qfu4aa8u","content":"<h1 id=\"StingBuilder-gt-StringBuffer\"><a href=\"#StingBuilder-gt-StringBuffer\" class=\"headerlink\" title=\"StingBuilder -&gt; StringBuffer\"></a>StingBuilder -&gt; StringBuffer</h1><p>StringBuffer线程安全， 方法通过synchronized实现， 单线程环境或者堆栈封闭情况下使用StringBuilder</p>\n<h1 id=\"SimpleDateFormat-gt-JodaTime\"><a href=\"#SimpleDateFormat-gt-JodaTime\" class=\"headerlink\" title=\"SimpleDateFormat -&gt; JodaTime\"></a>SimpleDateFormat -&gt; JodaTime</h1><p>SimpleDateFormat不是线程安全的， 可以通过堆栈封闭方式使用</p>\n<h1 id=\"ArrayList-HashSet-HashMap等Collections\"><a href=\"#ArrayList-HashSet-HashMap等Collections\" class=\"headerlink\" title=\"ArrayList, HashSet, HashMap等Collections\"></a>ArrayList, HashSet, HashMap等Collections</h1><h1 id=\"先检查再执行：-if-condition-a-handle-a\"><a href=\"#先检查再执行：-if-condition-a-handle-a\" class=\"headerlink\" title=\"先检查再执行： if(condition(a)){handle(a);}\"></a>先检查再执行： if(condition(a)){handle(a);}</h1><p>两个线程可能同时进入， 两个过程分别是线程安全的</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"StingBuilder-gt-StringBuffer\"><a href=\"#StingBuilder-gt-StringBuffer\" class=\"headerlink\" title=\"StingBuilder -&gt; StringBuffer\"></a>StingBuilder -&gt; StringBuffer</h1><p>StringBuffer线程安全， 方法通过synchronized实现， 单线程环境或者堆栈封闭情况下使用StringBuilder</p>\n<h1 id=\"SimpleDateFormat-gt-JodaTime\"><a href=\"#SimpleDateFormat-gt-JodaTime\" class=\"headerlink\" title=\"SimpleDateFormat -&gt; JodaTime\"></a>SimpleDateFormat -&gt; JodaTime</h1><p>SimpleDateFormat不是线程安全的， 可以通过堆栈封闭方式使用</p>\n<h1 id=\"ArrayList-HashSet-HashMap等Collections\"><a href=\"#ArrayList-HashSet-HashMap等Collections\" class=\"headerlink\" title=\"ArrayList, HashSet, HashMap等Collections\"></a>ArrayList, HashSet, HashMap等Collections</h1><h1 id=\"先检查再执行：-if-condition-a-handle-a\"><a href=\"#先检查再执行：-if-condition-a-handle-a\" class=\"headerlink\" title=\"先检查再执行： if(condition(a)){handle(a);}\"></a>先检查再执行： if(condition(a)){handle(a);}</h1><p>两个线程可能同时进入， 两个过程分别是线程安全的</p>\n"},{"title":"线程安全-同步容器","date":"2018-09-04T13:06:53.000Z","_content":"\n# ArrayList -> Vector, Stack\nVector内的方法都是synchronized， 线程安全性更好一些\nStack继承vector\n\n# HashMap -> HashTable\nHashTable进行了同步处理的key，value不能为null\n\n# Collections.synchronizedXXX(List, Set, Map)\n可以创建同步容器类\n\n# 总结\n同步容器不能保证线程安全， 即使同步容器add remove等操作都是synchronized修饰的。 比如一个线程访问remove操作， 一个线程同时操作get\n操作可能出现数组越界的异常。 \n\n使用iterator和foreach遍历同步容器的时候如果同时有增删操作会导致ConcurrentModificationException。 单线程也会出现。\n可以在循环时候做好标记， 循环结束再增删。\n","source":"_posts/线程安全-同步容器.md","raw":"---\ntitle: 线程安全-同步容器\ndate: 2018-09-04 21:06:53\ntags:\n---\n\n# ArrayList -> Vector, Stack\nVector内的方法都是synchronized， 线程安全性更好一些\nStack继承vector\n\n# HashMap -> HashTable\nHashTable进行了同步处理的key，value不能为null\n\n# Collections.synchronizedXXX(List, Set, Map)\n可以创建同步容器类\n\n# 总结\n同步容器不能保证线程安全， 即使同步容器add remove等操作都是synchronized修饰的。 比如一个线程访问remove操作， 一个线程同时操作get\n操作可能出现数组越界的异常。 \n\n使用iterator和foreach遍历同步容器的时候如果同时有增删操作会导致ConcurrentModificationException。 单线程也会出现。\n可以在循环时候做好标记， 循环结束再增删。\n","slug":"线程安全-同步容器","published":1,"updated":"2018-09-08T14:15:40.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjofoeav1000dd9222s9wkaks","content":"<h1 id=\"ArrayList-gt-Vector-Stack\"><a href=\"#ArrayList-gt-Vector-Stack\" class=\"headerlink\" title=\"ArrayList -&gt; Vector, Stack\"></a>ArrayList -&gt; Vector, Stack</h1><p>Vector内的方法都是synchronized， 线程安全性更好一些<br>Stack继承vector</p>\n<h1 id=\"HashMap-gt-HashTable\"><a href=\"#HashMap-gt-HashTable\" class=\"headerlink\" title=\"HashMap -&gt; HashTable\"></a>HashMap -&gt; HashTable</h1><p>HashTable进行了同步处理的key，value不能为null</p>\n<h1 id=\"Collections-synchronizedXXX-List-Set-Map\"><a href=\"#Collections-synchronizedXXX-List-Set-Map\" class=\"headerlink\" title=\"Collections.synchronizedXXX(List, Set, Map)\"></a>Collections.synchronizedXXX(List, Set, Map)</h1><p>可以创建同步容器类</p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>同步容器不能保证线程安全， 即使同步容器add remove等操作都是synchronized修饰的。 比如一个线程访问remove操作， 一个线程同时操作get<br>操作可能出现数组越界的异常。 </p>\n<p>使用iterator和foreach遍历同步容器的时候如果同时有增删操作会导致ConcurrentModificationException。 单线程也会出现。<br>可以在循环时候做好标记， 循环结束再增删。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"ArrayList-gt-Vector-Stack\"><a href=\"#ArrayList-gt-Vector-Stack\" class=\"headerlink\" title=\"ArrayList -&gt; Vector, Stack\"></a>ArrayList -&gt; Vector, Stack</h1><p>Vector内的方法都是synchronized， 线程安全性更好一些<br>Stack继承vector</p>\n<h1 id=\"HashMap-gt-HashTable\"><a href=\"#HashMap-gt-HashTable\" class=\"headerlink\" title=\"HashMap -&gt; HashTable\"></a>HashMap -&gt; HashTable</h1><p>HashTable进行了同步处理的key，value不能为null</p>\n<h1 id=\"Collections-synchronizedXXX-List-Set-Map\"><a href=\"#Collections-synchronizedXXX-List-Set-Map\" class=\"headerlink\" title=\"Collections.synchronizedXXX(List, Set, Map)\"></a>Collections.synchronizedXXX(List, Set, Map)</h1><p>可以创建同步容器类</p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>同步容器不能保证线程安全， 即使同步容器add remove等操作都是synchronized修饰的。 比如一个线程访问remove操作， 一个线程同时操作get<br>操作可能出现数组越界的异常。 </p>\n<p>使用iterator和foreach遍历同步容器的时候如果同时有增删操作会导致ConcurrentModificationException。 单线程也会出现。<br>可以在循环时候做好标记， 循环结束再增删。</p>\n"},{"title":"线程安全-并发容器JUC","date":"2018-09-07T03:40:15.000Z","_content":"\n# ArrayList -> CopyOnWriteArrayList\n读写分离， add操作被锁保护， 防止多线程操作时创建多个副本， 读在原数组上， 不用加锁； 最终一致性； 使用时另外开辟空间； \n缺点： 元素多可能写操作导致full gc； 不能用于实时读的场景， 更适合读多写少的场景； \n\n# HashSet, TreeSet -> CopyOnWriteArraySet, ConcurrentSkipListSet\nCopyOnWriteArraySet底层基于CopyOnWriteArrayList。\nConcurrentSkipListSet基于Map集合 remove, add, contains是线程安全的， 但是removeAll， addAll不是线程安全的。 不能保证每一次批量操作都不会被其他线程打断， 需要手动加其他控制， 比如加锁。 不支持null\t\n\n# HashMap, TreeMap -> ConcurrentHashMap, ConcurrentSkipListMap\nConcurrentHashMap不允许null， 除了插入删除操作外， 读取操作效率很高。 这个类有很好的并发性。 要 *重点理解原理*\nConcurrentSkipListMap key有序的， 支持更高的并发， 存取时间和线程数没有关系。 有更好的并发度。\n\n# 安全共享对象策略\n\n1. 线程限制： 一个被线程限制的对象， 由线程独占， 并且只能被占有他的线程修改\n2. 共享只读： 一个共享只读的对象， 在没有额外同步的情况下， 可以被多个线程并发访问， 但是任何线程都不能修改它\n3. 线程安全的对象： 一个线程安全的对象或者容器， 在内部通过同步机制来保证线程安全， 所以其他线程无需额外的同步就可以通过公共接口随意访问它\n4. 被守护对象： 被守护对象只能通过获取特定的锁来访问\n\n\n\n","source":"_posts/线程安全-并发容器JUC.md","raw":"---\ntitle: 线程安全-并发容器JUC\ndate: 2018-09-07 11:40:15\ntags:\n---\n\n# ArrayList -> CopyOnWriteArrayList\n读写分离， add操作被锁保护， 防止多线程操作时创建多个副本， 读在原数组上， 不用加锁； 最终一致性； 使用时另外开辟空间； \n缺点： 元素多可能写操作导致full gc； 不能用于实时读的场景， 更适合读多写少的场景； \n\n# HashSet, TreeSet -> CopyOnWriteArraySet, ConcurrentSkipListSet\nCopyOnWriteArraySet底层基于CopyOnWriteArrayList。\nConcurrentSkipListSet基于Map集合 remove, add, contains是线程安全的， 但是removeAll， addAll不是线程安全的。 不能保证每一次批量操作都不会被其他线程打断， 需要手动加其他控制， 比如加锁。 不支持null\t\n\n# HashMap, TreeMap -> ConcurrentHashMap, ConcurrentSkipListMap\nConcurrentHashMap不允许null， 除了插入删除操作外， 读取操作效率很高。 这个类有很好的并发性。 要 *重点理解原理*\nConcurrentSkipListMap key有序的， 支持更高的并发， 存取时间和线程数没有关系。 有更好的并发度。\n\n# 安全共享对象策略\n\n1. 线程限制： 一个被线程限制的对象， 由线程独占， 并且只能被占有他的线程修改\n2. 共享只读： 一个共享只读的对象， 在没有额外同步的情况下， 可以被多个线程并发访问， 但是任何线程都不能修改它\n3. 线程安全的对象： 一个线程安全的对象或者容器， 在内部通过同步机制来保证线程安全， 所以其他线程无需额外的同步就可以通过公共接口随意访问它\n4. 被守护对象： 被守护对象只能通过获取特定的锁来访问\n\n\n\n","slug":"线程安全-并发容器JUC","published":1,"updated":"2018-10-04T13:18:21.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjofoeav2000ed922zc1tp7yt","content":"<h1 id=\"ArrayList-gt-CopyOnWriteArrayList\"><a href=\"#ArrayList-gt-CopyOnWriteArrayList\" class=\"headerlink\" title=\"ArrayList -&gt; CopyOnWriteArrayList\"></a>ArrayList -&gt; CopyOnWriteArrayList</h1><p>读写分离， add操作被锁保护， 防止多线程操作时创建多个副本， 读在原数组上， 不用加锁； 最终一致性； 使用时另外开辟空间；<br>缺点： 元素多可能写操作导致full gc； 不能用于实时读的场景， 更适合读多写少的场景； </p>\n<h1 id=\"HashSet-TreeSet-gt-CopyOnWriteArraySet-ConcurrentSkipListSet\"><a href=\"#HashSet-TreeSet-gt-CopyOnWriteArraySet-ConcurrentSkipListSet\" class=\"headerlink\" title=\"HashSet, TreeSet -&gt; CopyOnWriteArraySet, ConcurrentSkipListSet\"></a>HashSet, TreeSet -&gt; CopyOnWriteArraySet, ConcurrentSkipListSet</h1><p>CopyOnWriteArraySet底层基于CopyOnWriteArrayList。<br>ConcurrentSkipListSet基于Map集合 remove, add, contains是线程安全的， 但是removeAll， addAll不是线程安全的。 不能保证每一次批量操作都不会被其他线程打断， 需要手动加其他控制， 比如加锁。 不支持null    </p>\n<h1 id=\"HashMap-TreeMap-gt-ConcurrentHashMap-ConcurrentSkipListMap\"><a href=\"#HashMap-TreeMap-gt-ConcurrentHashMap-ConcurrentSkipListMap\" class=\"headerlink\" title=\"HashMap, TreeMap -&gt; ConcurrentHashMap, ConcurrentSkipListMap\"></a>HashMap, TreeMap -&gt; ConcurrentHashMap, ConcurrentSkipListMap</h1><p>ConcurrentHashMap不允许null， 除了插入删除操作外， 读取操作效率很高。 这个类有很好的并发性。 要 <em>重点理解原理</em><br>ConcurrentSkipListMap key有序的， 支持更高的并发， 存取时间和线程数没有关系。 有更好的并发度。</p>\n<h1 id=\"安全共享对象策略\"><a href=\"#安全共享对象策略\" class=\"headerlink\" title=\"安全共享对象策略\"></a>安全共享对象策略</h1><ol>\n<li>线程限制： 一个被线程限制的对象， 由线程独占， 并且只能被占有他的线程修改</li>\n<li>共享只读： 一个共享只读的对象， 在没有额外同步的情况下， 可以被多个线程并发访问， 但是任何线程都不能修改它</li>\n<li>线程安全的对象： 一个线程安全的对象或者容器， 在内部通过同步机制来保证线程安全， 所以其他线程无需额外的同步就可以通过公共接口随意访问它</li>\n<li>被守护对象： 被守护对象只能通过获取特定的锁来访问</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"ArrayList-gt-CopyOnWriteArrayList\"><a href=\"#ArrayList-gt-CopyOnWriteArrayList\" class=\"headerlink\" title=\"ArrayList -&gt; CopyOnWriteArrayList\"></a>ArrayList -&gt; CopyOnWriteArrayList</h1><p>读写分离， add操作被锁保护， 防止多线程操作时创建多个副本， 读在原数组上， 不用加锁； 最终一致性； 使用时另外开辟空间；<br>缺点： 元素多可能写操作导致full gc； 不能用于实时读的场景， 更适合读多写少的场景； </p>\n<h1 id=\"HashSet-TreeSet-gt-CopyOnWriteArraySet-ConcurrentSkipListSet\"><a href=\"#HashSet-TreeSet-gt-CopyOnWriteArraySet-ConcurrentSkipListSet\" class=\"headerlink\" title=\"HashSet, TreeSet -&gt; CopyOnWriteArraySet, ConcurrentSkipListSet\"></a>HashSet, TreeSet -&gt; CopyOnWriteArraySet, ConcurrentSkipListSet</h1><p>CopyOnWriteArraySet底层基于CopyOnWriteArrayList。<br>ConcurrentSkipListSet基于Map集合 remove, add, contains是线程安全的， 但是removeAll， addAll不是线程安全的。 不能保证每一次批量操作都不会被其他线程打断， 需要手动加其他控制， 比如加锁。 不支持null    </p>\n<h1 id=\"HashMap-TreeMap-gt-ConcurrentHashMap-ConcurrentSkipListMap\"><a href=\"#HashMap-TreeMap-gt-ConcurrentHashMap-ConcurrentSkipListMap\" class=\"headerlink\" title=\"HashMap, TreeMap -&gt; ConcurrentHashMap, ConcurrentSkipListMap\"></a>HashMap, TreeMap -&gt; ConcurrentHashMap, ConcurrentSkipListMap</h1><p>ConcurrentHashMap不允许null， 除了插入删除操作外， 读取操作效率很高。 这个类有很好的并发性。 要 <em>重点理解原理</em><br>ConcurrentSkipListMap key有序的， 支持更高的并发， 存取时间和线程数没有关系。 有更好的并发度。</p>\n<h1 id=\"安全共享对象策略\"><a href=\"#安全共享对象策略\" class=\"headerlink\" title=\"安全共享对象策略\"></a>安全共享对象策略</h1><ol>\n<li>线程限制： 一个被线程限制的对象， 由线程独占， 并且只能被占有他的线程修改</li>\n<li>共享只读： 一个共享只读的对象， 在没有额外同步的情况下， 可以被多个线程并发访问， 但是任何线程都不能修改它</li>\n<li>线程安全的对象： 一个线程安全的对象或者容器， 在内部通过同步机制来保证线程安全， 所以其他线程无需额外的同步就可以通过公共接口随意访问它</li>\n<li>被守护对象： 被守护对象只能通过获取特定的锁来访问</li>\n</ol>\n"},{"title":"线程安全性-原子性","date":"2018-08-31T03:26:59.000Z","_content":"\n# 线程安全性定义\n\n当多个线程访问某个类时， 不管运行时环境采取何种调度方式或者这些线程如果交替执行， 并且在主调代码中不需要任何额外的同步或协同， 这个类都能表现出真确的行为， 这个类就是线程安全的。\n\n线程安全性主要体现在3个方面：\n1. 原子性\n2. 可见性\n3. 有序性\n\n# 原子性实现-Atomic包\n\n## AtomicXXX, CAS \n\n比如AtomicInteger类主要用到CAS的方式， 具体用到compareAndSwapInt函数， 累加前当前值（工作内存）和底层的值（主内存）需要比较，只有一样才累加。  并发环境下CAS失败率高， 一个线程的原子操作可能循环多次尝试，影响性能。  \t\n\n\n## AtomicLong, LongAdder\n\nJDK8新增了LongAdder, 和AtomicLong有相似点。 LongAdder有优点，把热点数据分离， 把AtomicLong内部核心数据value被分为一个数组（多个cell）。 每个线程访问时候根据哈希等方法映射到一个节点进行计数。 最终结果为各个节点数据求和累加。 LongAdder等于把AtomicLong单点的更新压力分散到多个节点上。 低并发环境下通过对base的直接更新可以保证和AtomicLong效率基本相同。\n缺点是统计时候如果有并发更新统计数据可能会有误差。 如果要生成全局唯一的序列号就不适合用LongAdder。\n\n## AtomicReference, AtomicReferenceFieldUpdater\n\n\tpublic class AtomicReferenceExample {\n    \tprivate static AtomicReference<Integer> count = new AtomicReference(0);\n    \tpublic static void main(String[] args) {\n        \tcount.compareAndSet(0, 2);\n        \tcount.compareAndSet(2, 4);\n        \tlog.info(\"count: {}\", count.get());\n    \t}\n\t}\n\n\n\tpublic class AtomicFieldUpdaterExample {\n    \tprivate static AtomicIntegerFieldUpdater<AtomicFieldUpdaterExample> updater =\n            AtomicIntegerFieldUpdater.newUpdater(AtomicFieldUpdaterExample.class, \"count\");\n    \t@Getter\n    \tpublic volatile int count = 100;\n\n    \tpublic static void main(String[] args) {\n        \tAtomicFieldUpdaterExample example = new AtomicFieldUpdaterExample();\n        \tif(updater.compareAndSet(example, 100, 120)) {\n            \tlog.info(\"update success 1, {}\", example.getCount());\n        \t}\n        \tif(updater.compareAndSet(example, 100, 120)){\n            \tlog.info(\"update success 2, {}\", example.getCount());\n        \t} else {\n            \tlog.info(\"update fail, {}\", example.getCount());\n        \t}\n    \t}\n\t}\n\t只能更新非static的volatile变量\n\n\n## AtomicStampReference: CAS的ABA问题\n\n一个线程把变量A变为B又变回A， 这时候需要维护一个变化的Stamp来反映变量确实变化过。\n\n# 原子性 - 锁\n\n## synchronized:依赖JVM的同步锁\n\n修饰代码块： 作用于调用的对象\n修饰方法： 作用于调用的对象\n修饰静态方法： 作用于所有对象\n修饰类： 作用于所有对象\n\n## Lock\n依赖特殊的CPU指令， 代码实现， Reentrantlock\n\n# 原子性 - 对比\n\n* Synchronized: 不可中断锁， 适合竞争不激烈， 可读性好\n* Lock: 可中断锁（unlock）， 多样化同步， 竞争激烈时能维持常态\n* Atomic： 竞争激烈时能维持常态， 比lock性能好， 只能同步一个值\n\n","source":"_posts/线程安全性-原子性.md","raw":"---\ntitle: 线程安全性-原子性\ndate: 2018-08-31 11:26:59\ntags:\n---\n\n# 线程安全性定义\n\n当多个线程访问某个类时， 不管运行时环境采取何种调度方式或者这些线程如果交替执行， 并且在主调代码中不需要任何额外的同步或协同， 这个类都能表现出真确的行为， 这个类就是线程安全的。\n\n线程安全性主要体现在3个方面：\n1. 原子性\n2. 可见性\n3. 有序性\n\n# 原子性实现-Atomic包\n\n## AtomicXXX, CAS \n\n比如AtomicInteger类主要用到CAS的方式， 具体用到compareAndSwapInt函数， 累加前当前值（工作内存）和底层的值（主内存）需要比较，只有一样才累加。  并发环境下CAS失败率高， 一个线程的原子操作可能循环多次尝试，影响性能。  \t\n\n\n## AtomicLong, LongAdder\n\nJDK8新增了LongAdder, 和AtomicLong有相似点。 LongAdder有优点，把热点数据分离， 把AtomicLong内部核心数据value被分为一个数组（多个cell）。 每个线程访问时候根据哈希等方法映射到一个节点进行计数。 最终结果为各个节点数据求和累加。 LongAdder等于把AtomicLong单点的更新压力分散到多个节点上。 低并发环境下通过对base的直接更新可以保证和AtomicLong效率基本相同。\n缺点是统计时候如果有并发更新统计数据可能会有误差。 如果要生成全局唯一的序列号就不适合用LongAdder。\n\n## AtomicReference, AtomicReferenceFieldUpdater\n\n\tpublic class AtomicReferenceExample {\n    \tprivate static AtomicReference<Integer> count = new AtomicReference(0);\n    \tpublic static void main(String[] args) {\n        \tcount.compareAndSet(0, 2);\n        \tcount.compareAndSet(2, 4);\n        \tlog.info(\"count: {}\", count.get());\n    \t}\n\t}\n\n\n\tpublic class AtomicFieldUpdaterExample {\n    \tprivate static AtomicIntegerFieldUpdater<AtomicFieldUpdaterExample> updater =\n            AtomicIntegerFieldUpdater.newUpdater(AtomicFieldUpdaterExample.class, \"count\");\n    \t@Getter\n    \tpublic volatile int count = 100;\n\n    \tpublic static void main(String[] args) {\n        \tAtomicFieldUpdaterExample example = new AtomicFieldUpdaterExample();\n        \tif(updater.compareAndSet(example, 100, 120)) {\n            \tlog.info(\"update success 1, {}\", example.getCount());\n        \t}\n        \tif(updater.compareAndSet(example, 100, 120)){\n            \tlog.info(\"update success 2, {}\", example.getCount());\n        \t} else {\n            \tlog.info(\"update fail, {}\", example.getCount());\n        \t}\n    \t}\n\t}\n\t只能更新非static的volatile变量\n\n\n## AtomicStampReference: CAS的ABA问题\n\n一个线程把变量A变为B又变回A， 这时候需要维护一个变化的Stamp来反映变量确实变化过。\n\n# 原子性 - 锁\n\n## synchronized:依赖JVM的同步锁\n\n修饰代码块： 作用于调用的对象\n修饰方法： 作用于调用的对象\n修饰静态方法： 作用于所有对象\n修饰类： 作用于所有对象\n\n## Lock\n依赖特殊的CPU指令， 代码实现， Reentrantlock\n\n# 原子性 - 对比\n\n* Synchronized: 不可中断锁， 适合竞争不激烈， 可读性好\n* Lock: 可中断锁（unlock）， 多样化同步， 竞争激烈时能维持常态\n* Atomic： 竞争激烈时能维持常态， 比lock性能好， 只能同步一个值\n\n","slug":"线程安全性-原子性","published":1,"updated":"2018-09-02T13:52:59.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjofoeav5000fd922fzlgdea4","content":"<h1 id=\"线程安全性定义\"><a href=\"#线程安全性定义\" class=\"headerlink\" title=\"线程安全性定义\"></a>线程安全性定义</h1><p>当多个线程访问某个类时， 不管运行时环境采取何种调度方式或者这些线程如果交替执行， 并且在主调代码中不需要任何额外的同步或协同， 这个类都能表现出真确的行为， 这个类就是线程安全的。</p>\n<p>线程安全性主要体现在3个方面：</p>\n<ol>\n<li>原子性</li>\n<li>可见性</li>\n<li>有序性</li>\n</ol>\n<h1 id=\"原子性实现-Atomic包\"><a href=\"#原子性实现-Atomic包\" class=\"headerlink\" title=\"原子性实现-Atomic包\"></a>原子性实现-Atomic包</h1><h2 id=\"AtomicXXX-CAS\"><a href=\"#AtomicXXX-CAS\" class=\"headerlink\" title=\"AtomicXXX, CAS\"></a>AtomicXXX, CAS</h2><p>比如AtomicInteger类主要用到CAS的方式， 具体用到compareAndSwapInt函数， 累加前当前值（工作内存）和底层的值（主内存）需要比较，只有一样才累加。  并发环境下CAS失败率高， 一个线程的原子操作可能循环多次尝试，影响性能。      </p>\n<h2 id=\"AtomicLong-LongAdder\"><a href=\"#AtomicLong-LongAdder\" class=\"headerlink\" title=\"AtomicLong, LongAdder\"></a>AtomicLong, LongAdder</h2><p>JDK8新增了LongAdder, 和AtomicLong有相似点。 LongAdder有优点，把热点数据分离， 把AtomicLong内部核心数据value被分为一个数组（多个cell）。 每个线程访问时候根据哈希等方法映射到一个节点进行计数。 最终结果为各个节点数据求和累加。 LongAdder等于把AtomicLong单点的更新压力分散到多个节点上。 低并发环境下通过对base的直接更新可以保证和AtomicLong效率基本相同。<br>缺点是统计时候如果有并发更新统计数据可能会有误差。 如果要生成全局唯一的序列号就不适合用LongAdder。</p>\n<h2 id=\"AtomicReference-AtomicReferenceFieldUpdater\"><a href=\"#AtomicReference-AtomicReferenceFieldUpdater\" class=\"headerlink\" title=\"AtomicReference, AtomicReferenceFieldUpdater\"></a>AtomicReference, AtomicReferenceFieldUpdater</h2><pre><code>public class AtomicReferenceExample {\n    private static AtomicReference&lt;Integer&gt; count = new AtomicReference(0);\n    public static void main(String[] args) {\n        count.compareAndSet(0, 2);\n        count.compareAndSet(2, 4);\n        log.info(&quot;count: {}&quot;, count.get());\n    }\n}\n\n\npublic class AtomicFieldUpdaterExample {\n    private static AtomicIntegerFieldUpdater&lt;AtomicFieldUpdaterExample&gt; updater =\n        AtomicIntegerFieldUpdater.newUpdater(AtomicFieldUpdaterExample.class, &quot;count&quot;);\n    @Getter\n    public volatile int count = 100;\n\n    public static void main(String[] args) {\n        AtomicFieldUpdaterExample example = new AtomicFieldUpdaterExample();\n        if(updater.compareAndSet(example, 100, 120)) {\n            log.info(&quot;update success 1, {}&quot;, example.getCount());\n        }\n        if(updater.compareAndSet(example, 100, 120)){\n            log.info(&quot;update success 2, {}&quot;, example.getCount());\n        } else {\n            log.info(&quot;update fail, {}&quot;, example.getCount());\n        }\n    }\n}\n只能更新非static的volatile变量\n</code></pre><h2 id=\"AtomicStampReference-CAS的ABA问题\"><a href=\"#AtomicStampReference-CAS的ABA问题\" class=\"headerlink\" title=\"AtomicStampReference: CAS的ABA问题\"></a>AtomicStampReference: CAS的ABA问题</h2><p>一个线程把变量A变为B又变回A， 这时候需要维护一个变化的Stamp来反映变量确实变化过。</p>\n<h1 id=\"原子性-锁\"><a href=\"#原子性-锁\" class=\"headerlink\" title=\"原子性 - 锁\"></a>原子性 - 锁</h1><h2 id=\"synchronized-依赖JVM的同步锁\"><a href=\"#synchronized-依赖JVM的同步锁\" class=\"headerlink\" title=\"synchronized:依赖JVM的同步锁\"></a>synchronized:依赖JVM的同步锁</h2><p>修饰代码块： 作用于调用的对象<br>修饰方法： 作用于调用的对象<br>修饰静态方法： 作用于所有对象<br>修饰类： 作用于所有对象</p>\n<h2 id=\"Lock\"><a href=\"#Lock\" class=\"headerlink\" title=\"Lock\"></a>Lock</h2><p>依赖特殊的CPU指令， 代码实现， Reentrantlock</p>\n<h1 id=\"原子性-对比\"><a href=\"#原子性-对比\" class=\"headerlink\" title=\"原子性 - 对比\"></a>原子性 - 对比</h1><ul>\n<li>Synchronized: 不可中断锁， 适合竞争不激烈， 可读性好</li>\n<li>Lock: 可中断锁（unlock）， 多样化同步， 竞争激烈时能维持常态</li>\n<li>Atomic： 竞争激烈时能维持常态， 比lock性能好， 只能同步一个值</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"线程安全性定义\"><a href=\"#线程安全性定义\" class=\"headerlink\" title=\"线程安全性定义\"></a>线程安全性定义</h1><p>当多个线程访问某个类时， 不管运行时环境采取何种调度方式或者这些线程如果交替执行， 并且在主调代码中不需要任何额外的同步或协同， 这个类都能表现出真确的行为， 这个类就是线程安全的。</p>\n<p>线程安全性主要体现在3个方面：</p>\n<ol>\n<li>原子性</li>\n<li>可见性</li>\n<li>有序性</li>\n</ol>\n<h1 id=\"原子性实现-Atomic包\"><a href=\"#原子性实现-Atomic包\" class=\"headerlink\" title=\"原子性实现-Atomic包\"></a>原子性实现-Atomic包</h1><h2 id=\"AtomicXXX-CAS\"><a href=\"#AtomicXXX-CAS\" class=\"headerlink\" title=\"AtomicXXX, CAS\"></a>AtomicXXX, CAS</h2><p>比如AtomicInteger类主要用到CAS的方式， 具体用到compareAndSwapInt函数， 累加前当前值（工作内存）和底层的值（主内存）需要比较，只有一样才累加。  并发环境下CAS失败率高， 一个线程的原子操作可能循环多次尝试，影响性能。      </p>\n<h2 id=\"AtomicLong-LongAdder\"><a href=\"#AtomicLong-LongAdder\" class=\"headerlink\" title=\"AtomicLong, LongAdder\"></a>AtomicLong, LongAdder</h2><p>JDK8新增了LongAdder, 和AtomicLong有相似点。 LongAdder有优点，把热点数据分离， 把AtomicLong内部核心数据value被分为一个数组（多个cell）。 每个线程访问时候根据哈希等方法映射到一个节点进行计数。 最终结果为各个节点数据求和累加。 LongAdder等于把AtomicLong单点的更新压力分散到多个节点上。 低并发环境下通过对base的直接更新可以保证和AtomicLong效率基本相同。<br>缺点是统计时候如果有并发更新统计数据可能会有误差。 如果要生成全局唯一的序列号就不适合用LongAdder。</p>\n<h2 id=\"AtomicReference-AtomicReferenceFieldUpdater\"><a href=\"#AtomicReference-AtomicReferenceFieldUpdater\" class=\"headerlink\" title=\"AtomicReference, AtomicReferenceFieldUpdater\"></a>AtomicReference, AtomicReferenceFieldUpdater</h2><pre><code>public class AtomicReferenceExample {\n    private static AtomicReference&lt;Integer&gt; count = new AtomicReference(0);\n    public static void main(String[] args) {\n        count.compareAndSet(0, 2);\n        count.compareAndSet(2, 4);\n        log.info(&quot;count: {}&quot;, count.get());\n    }\n}\n\n\npublic class AtomicFieldUpdaterExample {\n    private static AtomicIntegerFieldUpdater&lt;AtomicFieldUpdaterExample&gt; updater =\n        AtomicIntegerFieldUpdater.newUpdater(AtomicFieldUpdaterExample.class, &quot;count&quot;);\n    @Getter\n    public volatile int count = 100;\n\n    public static void main(String[] args) {\n        AtomicFieldUpdaterExample example = new AtomicFieldUpdaterExample();\n        if(updater.compareAndSet(example, 100, 120)) {\n            log.info(&quot;update success 1, {}&quot;, example.getCount());\n        }\n        if(updater.compareAndSet(example, 100, 120)){\n            log.info(&quot;update success 2, {}&quot;, example.getCount());\n        } else {\n            log.info(&quot;update fail, {}&quot;, example.getCount());\n        }\n    }\n}\n只能更新非static的volatile变量\n</code></pre><h2 id=\"AtomicStampReference-CAS的ABA问题\"><a href=\"#AtomicStampReference-CAS的ABA问题\" class=\"headerlink\" title=\"AtomicStampReference: CAS的ABA问题\"></a>AtomicStampReference: CAS的ABA问题</h2><p>一个线程把变量A变为B又变回A， 这时候需要维护一个变化的Stamp来反映变量确实变化过。</p>\n<h1 id=\"原子性-锁\"><a href=\"#原子性-锁\" class=\"headerlink\" title=\"原子性 - 锁\"></a>原子性 - 锁</h1><h2 id=\"synchronized-依赖JVM的同步锁\"><a href=\"#synchronized-依赖JVM的同步锁\" class=\"headerlink\" title=\"synchronized:依赖JVM的同步锁\"></a>synchronized:依赖JVM的同步锁</h2><p>修饰代码块： 作用于调用的对象<br>修饰方法： 作用于调用的对象<br>修饰静态方法： 作用于所有对象<br>修饰类： 作用于所有对象</p>\n<h2 id=\"Lock\"><a href=\"#Lock\" class=\"headerlink\" title=\"Lock\"></a>Lock</h2><p>依赖特殊的CPU指令， 代码实现， Reentrantlock</p>\n<h1 id=\"原子性-对比\"><a href=\"#原子性-对比\" class=\"headerlink\" title=\"原子性 - 对比\"></a>原子性 - 对比</h1><ul>\n<li>Synchronized: 不可中断锁， 适合竞争不激烈， 可读性好</li>\n<li>Lock: 可中断锁（unlock）， 多样化同步， 竞争激烈时能维持常态</li>\n<li>Atomic： 竞争激烈时能维持常态， 比lock性能好， 只能同步一个值</li>\n</ul>\n"},{"title":"线程安全性-有序性","date":"2018-09-02T02:30:53.000Z","_content":"\n# 有序性\n\njava内存模型， 允许编译器和处理器对指令重排序， 重排序结果不会影响单线程执行， 却会影响到多线程并发执行的正确性。\n\nsynchronized, lock同一时间只允许一个线程执行同步代码， 让线程们顺序执行当然保证了有序性\n\nvolatile也能保证一定的有序性\n\n\n## Happens-before原则\n\nJMM先天的有序性（不需要通过任何手段就能保证的有序性）\n * 程序次序原则， 代码按书写次序执行（适用于单线程， 逻辑上看是按次序执行的， 因为有重排序）\n * 锁定原则， unlock先行发生于lock\n * volatile变量规则， 对一个变量的写操作先行发生于读操作\n * 传递规则\n 。。。 \n 后面的4条都很显而易见\t","source":"_posts/线程安全性-有序性.md","raw":"---\ntitle: 线程安全性-有序性\ndate: 2018-09-02 10:30:53\ntags:\n---\n\n# 有序性\n\njava内存模型， 允许编译器和处理器对指令重排序， 重排序结果不会影响单线程执行， 却会影响到多线程并发执行的正确性。\n\nsynchronized, lock同一时间只允许一个线程执行同步代码， 让线程们顺序执行当然保证了有序性\n\nvolatile也能保证一定的有序性\n\n\n## Happens-before原则\n\nJMM先天的有序性（不需要通过任何手段就能保证的有序性）\n * 程序次序原则， 代码按书写次序执行（适用于单线程， 逻辑上看是按次序执行的， 因为有重排序）\n * 锁定原则， unlock先行发生于lock\n * volatile变量规则， 对一个变量的写操作先行发生于读操作\n * 传递规则\n 。。。 \n 后面的4条都很显而易见\t","slug":"线程安全性-有序性","published":1,"updated":"2018-10-08T06:32:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjofoeav5000gd9226x3gbxxo","content":"<h1 id=\"有序性\"><a href=\"#有序性\" class=\"headerlink\" title=\"有序性\"></a>有序性</h1><p>java内存模型， 允许编译器和处理器对指令重排序， 重排序结果不会影响单线程执行， 却会影响到多线程并发执行的正确性。</p>\n<p>synchronized, lock同一时间只允许一个线程执行同步代码， 让线程们顺序执行当然保证了有序性</p>\n<p>volatile也能保证一定的有序性</p>\n<h2 id=\"Happens-before原则\"><a href=\"#Happens-before原则\" class=\"headerlink\" title=\"Happens-before原则\"></a>Happens-before原则</h2><p>JMM先天的有序性（不需要通过任何手段就能保证的有序性）</p>\n<ul>\n<li>程序次序原则， 代码按书写次序执行（适用于单线程， 逻辑上看是按次序执行的， 因为有重排序）</li>\n<li>锁定原则， unlock先行发生于lock</li>\n<li>volatile变量规则， 对一个变量的写操作先行发生于读操作</li>\n<li>传递规则<br>。。。<br>后面的4条都很显而易见    </li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"有序性\"><a href=\"#有序性\" class=\"headerlink\" title=\"有序性\"></a>有序性</h1><p>java内存模型， 允许编译器和处理器对指令重排序， 重排序结果不会影响单线程执行， 却会影响到多线程并发执行的正确性。</p>\n<p>synchronized, lock同一时间只允许一个线程执行同步代码， 让线程们顺序执行当然保证了有序性</p>\n<p>volatile也能保证一定的有序性</p>\n<h2 id=\"Happens-before原则\"><a href=\"#Happens-before原则\" class=\"headerlink\" title=\"Happens-before原则\"></a>Happens-before原则</h2><p>JMM先天的有序性（不需要通过任何手段就能保证的有序性）</p>\n<ul>\n<li>程序次序原则， 代码按书写次序执行（适用于单线程， 逻辑上看是按次序执行的， 因为有重排序）</li>\n<li>锁定原则， unlock先行发生于lock</li>\n<li>volatile变量规则， 对一个变量的写操作先行发生于读操作</li>\n<li>传递规则<br>。。。<br>后面的4条都很显而易见    </li>\n</ul>\n"},{"title":"线程安全性-可见性","date":"2018-09-01T11:37:55.000Z","_content":"\n# 可见性\n\n导致共享变量在线程间不可见的原因\n\n1. 线程交叉执行\n2. 重排序\n3. 共享变量更新后的值没有在工作内存和主内存及时更新\n\n## JMM关于synchronized的规定\n\n1. 线程解锁前， 必须把共享变量最新值刷新到主内存\n2. 线程加锁前， 将清空工作变量中共享变量的值， 从而使用时需要从主内存重新读取最新的值\n\n## volatile\n\n通过加入内存屏障和禁止重排序优化来实现\n对volatile变量写操作时， 会在写操作后加入一条store屏障指令， 将本地内存中的共享变量刷新到主内存\n对volatile变量读操作时， 会在读操作前加入一条load屏障指令， 从内存中读取共享变量\n\n![reorder_read](reorder_read.png)\n![MESI Protocal](reorder_write.png)\n","source":"_posts/线程安全性-可见性.md","raw":"---\ntitle: 线程安全性-可见性\ndate: 2018-09-01 19:37:55\ntags:\n---\n\n# 可见性\n\n导致共享变量在线程间不可见的原因\n\n1. 线程交叉执行\n2. 重排序\n3. 共享变量更新后的值没有在工作内存和主内存及时更新\n\n## JMM关于synchronized的规定\n\n1. 线程解锁前， 必须把共享变量最新值刷新到主内存\n2. 线程加锁前， 将清空工作变量中共享变量的值， 从而使用时需要从主内存重新读取最新的值\n\n## volatile\n\n通过加入内存屏障和禁止重排序优化来实现\n对volatile变量写操作时， 会在写操作后加入一条store屏障指令， 将本地内存中的共享变量刷新到主内存\n对volatile变量读操作时， 会在读操作前加入一条load屏障指令， 从内存中读取共享变量\n\n![reorder_read](reorder_read.png)\n![MESI Protocal](reorder_write.png)\n","slug":"线程安全性-可见性","published":1,"updated":"2018-09-02T02:26:38.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjofoeav6000hd922i093b3c0","content":"<h1 id=\"可见性\"><a href=\"#可见性\" class=\"headerlink\" title=\"可见性\"></a>可见性</h1><p>导致共享变量在线程间不可见的原因</p>\n<ol>\n<li>线程交叉执行</li>\n<li>重排序</li>\n<li>共享变量更新后的值没有在工作内存和主内存及时更新</li>\n</ol>\n<h2 id=\"JMM关于synchronized的规定\"><a href=\"#JMM关于synchronized的规定\" class=\"headerlink\" title=\"JMM关于synchronized的规定\"></a>JMM关于synchronized的规定</h2><ol>\n<li>线程解锁前， 必须把共享变量最新值刷新到主内存</li>\n<li>线程加锁前， 将清空工作变量中共享变量的值， 从而使用时需要从主内存重新读取最新的值</li>\n</ol>\n<h2 id=\"volatile\"><a href=\"#volatile\" class=\"headerlink\" title=\"volatile\"></a>volatile</h2><p>通过加入内存屏障和禁止重排序优化来实现<br>对volatile变量写操作时， 会在写操作后加入一条store屏障指令， 将本地内存中的共享变量刷新到主内存<br>对volatile变量读操作时， 会在读操作前加入一条load屏障指令， 从内存中读取共享变量</p>\n<p><img src=\"reorder_read.png\" alt=\"reorder_read\"><br><img src=\"reorder_write.png\" alt=\"MESI Protocal\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"可见性\"><a href=\"#可见性\" class=\"headerlink\" title=\"可见性\"></a>可见性</h1><p>导致共享变量在线程间不可见的原因</p>\n<ol>\n<li>线程交叉执行</li>\n<li>重排序</li>\n<li>共享变量更新后的值没有在工作内存和主内存及时更新</li>\n</ol>\n<h2 id=\"JMM关于synchronized的规定\"><a href=\"#JMM关于synchronized的规定\" class=\"headerlink\" title=\"JMM关于synchronized的规定\"></a>JMM关于synchronized的规定</h2><ol>\n<li>线程解锁前， 必须把共享变量最新值刷新到主内存</li>\n<li>线程加锁前， 将清空工作变量中共享变量的值， 从而使用时需要从主内存重新读取最新的值</li>\n</ol>\n<h2 id=\"volatile\"><a href=\"#volatile\" class=\"headerlink\" title=\"volatile\"></a>volatile</h2><p>通过加入内存屏障和禁止重排序优化来实现<br>对volatile变量写操作时， 会在写操作后加入一条store屏障指令， 将本地内存中的共享变量刷新到主内存<br>对volatile变量读操作时， 会在读操作前加入一条load屏障指令， 从内存中读取共享变量</p>\n<p><img src=\"reorder_read.png\" alt=\"reorder_read\"><br><img src=\"reorder_write.png\" alt=\"MESI Protocal\"></p>\n"},{"title":"线程封闭","date":"2018-09-03T09:50:14.000Z","_content":"\n# 线程封闭方法\n\n1. Ad-hoc线程封闭\n程序控制实现， 最糟糕， 忽略\n2. 堆栈封闭： 局部变量，每个线程访问方法时都会各自拷贝局部变量，无并发问题\n\n3. ThreadLocal线程封闭： 每个thread线程内部都有一个map， 以线程本地对象作为key， 以线程的变量副本作为value。 map由threadlocal维护。 由threadlocal设置map的变量值， 获取值。 别的线程获取不到当前线程的副本值。\n\n4. JDBC的connection对象， connection对象返回连接池之前， 连接池不会将它分配给别的线程。connection对象本身不安全。","source":"_posts/线程封闭.md","raw":"---\ntitle: 线程封闭\ndate: 2018-09-03 17:50:14\ntags:\n---\n\n# 线程封闭方法\n\n1. Ad-hoc线程封闭\n程序控制实现， 最糟糕， 忽略\n2. 堆栈封闭： 局部变量，每个线程访问方法时都会各自拷贝局部变量，无并发问题\n\n3. ThreadLocal线程封闭： 每个thread线程内部都有一个map， 以线程本地对象作为key， 以线程的变量副本作为value。 map由threadlocal维护。 由threadlocal设置map的变量值， 获取值。 别的线程获取不到当前线程的副本值。\n\n4. JDBC的connection对象， connection对象返回连接池之前， 连接池不会将它分配给别的线程。connection对象本身不安全。","slug":"线程封闭","published":1,"updated":"2018-09-08T14:15:40.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjofoeav7000id922p4felnzs","content":"<h1 id=\"线程封闭方法\"><a href=\"#线程封闭方法\" class=\"headerlink\" title=\"线程封闭方法\"></a>线程封闭方法</h1><ol>\n<li>Ad-hoc线程封闭<br>程序控制实现， 最糟糕， 忽略</li>\n<li><p>堆栈封闭： 局部变量，每个线程访问方法时都会各自拷贝局部变量，无并发问题</p>\n</li>\n<li><p>ThreadLocal线程封闭： 每个thread线程内部都有一个map， 以线程本地对象作为key， 以线程的变量副本作为value。 map由threadlocal维护。 由threadlocal设置map的变量值， 获取值。 别的线程获取不到当前线程的副本值。</p>\n</li>\n<li><p>JDBC的connection对象， connection对象返回连接池之前， 连接池不会将它分配给别的线程。connection对象本身不安全。</p>\n</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"线程封闭方法\"><a href=\"#线程封闭方法\" class=\"headerlink\" title=\"线程封闭方法\"></a>线程封闭方法</h1><ol>\n<li>Ad-hoc线程封闭<br>程序控制实现， 最糟糕， 忽略</li>\n<li><p>堆栈封闭： 局部变量，每个线程访问方法时都会各自拷贝局部变量，无并发问题</p>\n</li>\n<li><p>ThreadLocal线程封闭： 每个thread线程内部都有一个map， 以线程本地对象作为key， 以线程的变量副本作为value。 map由threadlocal维护。 由threadlocal设置map的变量值， 获取值。 别的线程获取不到当前线程的副本值。</p>\n</li>\n<li><p>JDBC的connection对象， connection对象返回连接池之前， 连接池不会将它分配给别的线程。connection对象本身不安全。</p>\n</li>\n</ol>\n"},{"title":"线程池","date":"2018-10-04T06:14:25.000Z","_content":"\n# 线程池\n1. 重用存在的线程， 减少创建， 消亡开销\n2. 有效控制最大并发线程数，提高系统资源利用率\n3. 提供定时执行， 定期执行， 单线程， 并发数控制功能\n\n注意三个参数： corePoolSize, maximumPoolSize, workQueue\n\nworkQueue可以是SynchronousQueue直接切换， 也可以是无界队列（LinkedBlockingQueue）这时maximumPoolSize不起作用。\n也可以为有界队列（ArrayBlockingQueue）\n\n如果要减低cpu 内存消耗， 可以设置较小的线程池容量， 较大的队列容量。\n如果老阻塞， 可以增大线程池大小。\n\nkeepAliveTime:  线程没有任务执行时最多保持多久\nunit： KeepAliveTime时间单位\nthreadFactory: 线程工厂\nrejectHandler: 拒绝处理任务时的策略\n\n## 拒绝策略\n1. 默认为抛异常\n2. 用调用者所在线程执行任务\n3. 丢弃队列中最前的任务， 执行当前任务\n4. 直接丢弃任务\n\n## 线程池状态\n* Running： 能接受新提交的任务， 也能处理阻塞队列中的任务\n* Shutdown： 不能接受新的任务， 能处理阻塞队列中的任务\n* Stop: 不能再接受新任务， 不能处理队列中的任务， 终端在处理任务的线程\n* Tidying： 线程池中工作线程数为0， 可以进入该状态\n* Terminated\n\n## ThreadPoolExecutor提供的方法\n* execute(): 提交任务， 交给线程池执行\n* submit(): 提交任务， 能返回执行结果，execute+future\n* shutdown(): 等任务都执行完\n* shutdownNow(): 不等任务执行完就关闭\n\n* getTaskCount()\n* getCompletedTaskCount()\n* getPoolSize() 池中现在的线程数量\n* getActiveCount() 当前线程池正在执行任务的线程数\n\n可以在监控类中传入ThreadPoolExecutor实例， 记录下这些数据放入监控图表里面\n\n## Executor框架接口\n* Executors.newCachedThreadPool 可创建一个可缓存的线程池， 可以灵活回收空闲线程， 或者新建线程\n* newFixedThreadPool 定长线程池， 可控制最大并发数， 超出线程在队列中等待\n* newScheduledThreadPool 定长线程池， 支持定时和周期性任务执行\n* newSingleThreadExecutor: 单线程线程池， 每个任务按指定顺序（先到先出， 优先级）执行\n\n## 线程池合理配置\nCPU密集型任务， 就需要尽量压榨CPU， 参考值为NCPU+1\nIO密集型任务， 参考值为两倍CPU\n\n任务很小时候， 线程池调度时间和任务时间差不多， 不适合用线程池\n\n\n\n\n","source":"_posts/线程池.md","raw":"---\ntitle: 线程池\ndate: 2018-10-04 14:14:25\ntags:\n---\n\n# 线程池\n1. 重用存在的线程， 减少创建， 消亡开销\n2. 有效控制最大并发线程数，提高系统资源利用率\n3. 提供定时执行， 定期执行， 单线程， 并发数控制功能\n\n注意三个参数： corePoolSize, maximumPoolSize, workQueue\n\nworkQueue可以是SynchronousQueue直接切换， 也可以是无界队列（LinkedBlockingQueue）这时maximumPoolSize不起作用。\n也可以为有界队列（ArrayBlockingQueue）\n\n如果要减低cpu 内存消耗， 可以设置较小的线程池容量， 较大的队列容量。\n如果老阻塞， 可以增大线程池大小。\n\nkeepAliveTime:  线程没有任务执行时最多保持多久\nunit： KeepAliveTime时间单位\nthreadFactory: 线程工厂\nrejectHandler: 拒绝处理任务时的策略\n\n## 拒绝策略\n1. 默认为抛异常\n2. 用调用者所在线程执行任务\n3. 丢弃队列中最前的任务， 执行当前任务\n4. 直接丢弃任务\n\n## 线程池状态\n* Running： 能接受新提交的任务， 也能处理阻塞队列中的任务\n* Shutdown： 不能接受新的任务， 能处理阻塞队列中的任务\n* Stop: 不能再接受新任务， 不能处理队列中的任务， 终端在处理任务的线程\n* Tidying： 线程池中工作线程数为0， 可以进入该状态\n* Terminated\n\n## ThreadPoolExecutor提供的方法\n* execute(): 提交任务， 交给线程池执行\n* submit(): 提交任务， 能返回执行结果，execute+future\n* shutdown(): 等任务都执行完\n* shutdownNow(): 不等任务执行完就关闭\n\n* getTaskCount()\n* getCompletedTaskCount()\n* getPoolSize() 池中现在的线程数量\n* getActiveCount() 当前线程池正在执行任务的线程数\n\n可以在监控类中传入ThreadPoolExecutor实例， 记录下这些数据放入监控图表里面\n\n## Executor框架接口\n* Executors.newCachedThreadPool 可创建一个可缓存的线程池， 可以灵活回收空闲线程， 或者新建线程\n* newFixedThreadPool 定长线程池， 可控制最大并发数， 超出线程在队列中等待\n* newScheduledThreadPool 定长线程池， 支持定时和周期性任务执行\n* newSingleThreadExecutor: 单线程线程池， 每个任务按指定顺序（先到先出， 优先级）执行\n\n## 线程池合理配置\nCPU密集型任务， 就需要尽量压榨CPU， 参考值为NCPU+1\nIO密集型任务， 参考值为两倍CPU\n\n任务很小时候， 线程池调度时间和任务时间差不多， 不适合用线程池\n\n\n\n\n","slug":"线程池","published":1,"updated":"2018-10-04T13:18:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjofoeav8000jd9220xmfa5k9","content":"<h1 id=\"线程池\"><a href=\"#线程池\" class=\"headerlink\" title=\"线程池\"></a>线程池</h1><ol>\n<li>重用存在的线程， 减少创建， 消亡开销</li>\n<li>有效控制最大并发线程数，提高系统资源利用率</li>\n<li>提供定时执行， 定期执行， 单线程， 并发数控制功能</li>\n</ol>\n<p>注意三个参数： corePoolSize, maximumPoolSize, workQueue</p>\n<p>workQueue可以是SynchronousQueue直接切换， 也可以是无界队列（LinkedBlockingQueue）这时maximumPoolSize不起作用。<br>也可以为有界队列（ArrayBlockingQueue）</p>\n<p>如果要减低cpu 内存消耗， 可以设置较小的线程池容量， 较大的队列容量。<br>如果老阻塞， 可以增大线程池大小。</p>\n<p>keepAliveTime:  线程没有任务执行时最多保持多久<br>unit： KeepAliveTime时间单位<br>threadFactory: 线程工厂<br>rejectHandler: 拒绝处理任务时的策略</p>\n<h2 id=\"拒绝策略\"><a href=\"#拒绝策略\" class=\"headerlink\" title=\"拒绝策略\"></a>拒绝策略</h2><ol>\n<li>默认为抛异常</li>\n<li>用调用者所在线程执行任务</li>\n<li>丢弃队列中最前的任务， 执行当前任务</li>\n<li>直接丢弃任务</li>\n</ol>\n<h2 id=\"线程池状态\"><a href=\"#线程池状态\" class=\"headerlink\" title=\"线程池状态\"></a>线程池状态</h2><ul>\n<li>Running： 能接受新提交的任务， 也能处理阻塞队列中的任务</li>\n<li>Shutdown： 不能接受新的任务， 能处理阻塞队列中的任务</li>\n<li>Stop: 不能再接受新任务， 不能处理队列中的任务， 终端在处理任务的线程</li>\n<li>Tidying： 线程池中工作线程数为0， 可以进入该状态</li>\n<li>Terminated</li>\n</ul>\n<h2 id=\"ThreadPoolExecutor提供的方法\"><a href=\"#ThreadPoolExecutor提供的方法\" class=\"headerlink\" title=\"ThreadPoolExecutor提供的方法\"></a>ThreadPoolExecutor提供的方法</h2><ul>\n<li>execute(): 提交任务， 交给线程池执行</li>\n<li>submit(): 提交任务， 能返回执行结果，execute+future</li>\n<li>shutdown(): 等任务都执行完</li>\n<li><p>shutdownNow(): 不等任务执行完就关闭</p>\n</li>\n<li><p>getTaskCount()</p>\n</li>\n<li>getCompletedTaskCount()</li>\n<li>getPoolSize() 池中现在的线程数量</li>\n<li>getActiveCount() 当前线程池正在执行任务的线程数</li>\n</ul>\n<p>可以在监控类中传入ThreadPoolExecutor实例， 记录下这些数据放入监控图表里面</p>\n<h2 id=\"Executor框架接口\"><a href=\"#Executor框架接口\" class=\"headerlink\" title=\"Executor框架接口\"></a>Executor框架接口</h2><ul>\n<li>Executors.newCachedThreadPool 可创建一个可缓存的线程池， 可以灵活回收空闲线程， 或者新建线程</li>\n<li>newFixedThreadPool 定长线程池， 可控制最大并发数， 超出线程在队列中等待</li>\n<li>newScheduledThreadPool 定长线程池， 支持定时和周期性任务执行</li>\n<li>newSingleThreadExecutor: 单线程线程池， 每个任务按指定顺序（先到先出， 优先级）执行</li>\n</ul>\n<h2 id=\"线程池合理配置\"><a href=\"#线程池合理配置\" class=\"headerlink\" title=\"线程池合理配置\"></a>线程池合理配置</h2><p>CPU密集型任务， 就需要尽量压榨CPU， 参考值为NCPU+1<br>IO密集型任务， 参考值为两倍CPU</p>\n<p>任务很小时候， 线程池调度时间和任务时间差不多， 不适合用线程池</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"线程池\"><a href=\"#线程池\" class=\"headerlink\" title=\"线程池\"></a>线程池</h1><ol>\n<li>重用存在的线程， 减少创建， 消亡开销</li>\n<li>有效控制最大并发线程数，提高系统资源利用率</li>\n<li>提供定时执行， 定期执行， 单线程， 并发数控制功能</li>\n</ol>\n<p>注意三个参数： corePoolSize, maximumPoolSize, workQueue</p>\n<p>workQueue可以是SynchronousQueue直接切换， 也可以是无界队列（LinkedBlockingQueue）这时maximumPoolSize不起作用。<br>也可以为有界队列（ArrayBlockingQueue）</p>\n<p>如果要减低cpu 内存消耗， 可以设置较小的线程池容量， 较大的队列容量。<br>如果老阻塞， 可以增大线程池大小。</p>\n<p>keepAliveTime:  线程没有任务执行时最多保持多久<br>unit： KeepAliveTime时间单位<br>threadFactory: 线程工厂<br>rejectHandler: 拒绝处理任务时的策略</p>\n<h2 id=\"拒绝策略\"><a href=\"#拒绝策略\" class=\"headerlink\" title=\"拒绝策略\"></a>拒绝策略</h2><ol>\n<li>默认为抛异常</li>\n<li>用调用者所在线程执行任务</li>\n<li>丢弃队列中最前的任务， 执行当前任务</li>\n<li>直接丢弃任务</li>\n</ol>\n<h2 id=\"线程池状态\"><a href=\"#线程池状态\" class=\"headerlink\" title=\"线程池状态\"></a>线程池状态</h2><ul>\n<li>Running： 能接受新提交的任务， 也能处理阻塞队列中的任务</li>\n<li>Shutdown： 不能接受新的任务， 能处理阻塞队列中的任务</li>\n<li>Stop: 不能再接受新任务， 不能处理队列中的任务， 终端在处理任务的线程</li>\n<li>Tidying： 线程池中工作线程数为0， 可以进入该状态</li>\n<li>Terminated</li>\n</ul>\n<h2 id=\"ThreadPoolExecutor提供的方法\"><a href=\"#ThreadPoolExecutor提供的方法\" class=\"headerlink\" title=\"ThreadPoolExecutor提供的方法\"></a>ThreadPoolExecutor提供的方法</h2><ul>\n<li>execute(): 提交任务， 交给线程池执行</li>\n<li>submit(): 提交任务， 能返回执行结果，execute+future</li>\n<li>shutdown(): 等任务都执行完</li>\n<li><p>shutdownNow(): 不等任务执行完就关闭</p>\n</li>\n<li><p>getTaskCount()</p>\n</li>\n<li>getCompletedTaskCount()</li>\n<li>getPoolSize() 池中现在的线程数量</li>\n<li>getActiveCount() 当前线程池正在执行任务的线程数</li>\n</ul>\n<p>可以在监控类中传入ThreadPoolExecutor实例， 记录下这些数据放入监控图表里面</p>\n<h2 id=\"Executor框架接口\"><a href=\"#Executor框架接口\" class=\"headerlink\" title=\"Executor框架接口\"></a>Executor框架接口</h2><ul>\n<li>Executors.newCachedThreadPool 可创建一个可缓存的线程池， 可以灵活回收空闲线程， 或者新建线程</li>\n<li>newFixedThreadPool 定长线程池， 可控制最大并发数， 超出线程在队列中等待</li>\n<li>newScheduledThreadPool 定长线程池， 支持定时和周期性任务执行</li>\n<li>newSingleThreadExecutor: 单线程线程池， 每个任务按指定顺序（先到先出， 优先级）执行</li>\n</ul>\n<h2 id=\"线程池合理配置\"><a href=\"#线程池合理配置\" class=\"headerlink\" title=\"线程池合理配置\"></a>线程池合理配置</h2><p>CPU密集型任务， 就需要尽量压榨CPU， 参考值为NCPU+1<br>IO密集型任务， 参考值为两倍CPU</p>\n<p>任务很小时候， 线程池调度时间和任务时间差不多， 不适合用线程池</p>\n"},{"title":"缓存学习笔记","date":"2018-10-09T05:41:14.000Z","_content":"\n# 缓存特征\n* 命中率： 命中数/(命中数+没有命中数)\n* 最大元素（空间）\n\n一旦数据超过最大元素将会触发缓存情况策略， 需要合理设置最大元素数量， 提高命中率和效率\n* 清空策略： FIFO, LFU, LRU, 过期时间， 随机等\n\nFIFO： 最先进入的数据当缓存不够， 或者达到最大元素限制时候会优先被清除掉， 主要比较元素的创建时间， \t在数据实时性要求场景下可以选择该策略， 优先保证最新数据可用\n\nLFU： 无论是否过期， 根据元素使用次数来判断， 清除使用次数最少的元素来释放空间， 主要比较元素的命中次数，在保证高频数据有效性场景下可以使用\n\nLRU： 无论是否过期， 比较元素最近get时间， 删除最远使用的元素。 在热点数据场景下较适用\n\n# 影响缓存命中率的因素\n* 业务场景和业务需求： 适合读多写少的业务场景， 实时性越低越适合缓存\n* 缓存的设计（粒度和策略）： 粒度越小命中率就会越高， 更新缓存比移除命中率更高， 但是系统复杂度更高\n* 缓存的容量和基础设施： 应用内置的缓存比较容易出现单击瓶颈， 分布式缓存更容易扩展。 所以需要做好系统容量规划， 并考虑是否可扩展\n单个节点出现故障的时候， 需要避免缓存失效， 最大程度降低影响。 可通过一致性哈希算法和节点冗余的方式来避免这个问题\n\n从架构师角度为了提高缓存命中率： \n竟可能多的从缓存获取数据并避免缓存失效， 这比较考验架构师能力， 需要从业务需求， 缓存粒度， 缓存策略， 技术选型等方面通盘考虑权衡。 竟可能聚焦在高频访问并时效性要求不高的热点业务上。 通过缓存预加载（预热）， 增加存储容量， 调整缓存粒度， 更新缓存等方法来提高命中率。\n\n## 缓存分类和应用场景\n * 本地缓存： 编程实现（成员变量， 局部变量， 静态变量）、 Guava Cache\n * 分布式缓存： Memcache、 Redis\n\n## Guava Cache\n![Guava Cache](GuavaCache.png)\n继承了ConcurrentHashMap的思路， 使用多个segment方式的细粒度锁保证线程安全和高并发的需求。 key被封装在weak reference引用中。 value被封装在weak或者soft reference引用中。 可以统计命中率， 异常率等统计数据\n\n## Memcache\n![memcache](memcache.png)\n应用广的开源分布式缓存产品， 本身不支持， cache的分布式主要在客户端实现。 客户端路由（一致性哈希算法）， 除了计算key的哈希值还计算每个mencahce server节点的哈希值。 \n通过查找哈希值大于key对应的hash值的最小server作为存储该key的目标server。 \n如果找不到直接把最小哈希值的server作为目标server， 增加删除单个节点不会对集群有大的影响。\n增加了虚拟节点的设计进一步提高可用性。\n\n\n### memcache内存结构\nmemcache是一个高效的分布式内存cache， 了解内存结构能更高根据数据特点进行调优。\n![memcache2](memcache2.png)\n每个slab有多个page， page默认大小为1M。 同一个slab中的chunk大小一定。 相同大小chunk的slab被组织在一起称为slab_class。\nmemcache内存分配的方式为allocater， slab数量有限和启动参数有关。 相邻slab的chunk大小基本按1.25比例增长（启动时-f 设定）。 \n放slab时候， slab以page为单位申请内存， page再按chunk大小进行切分， 得到chunk数组来存数据。 \n如果没有chunk了， 进行LRU把最近最少使用的chunk中的数据清理掉。 \n\n* chunk中总会有内存浪费\n* memcache的LRU算法不是针对全局， 只是针对slab的\n* memcache只会以page（1M）的大小申请内存， 对新数据大小有限制， key最大为250个字节\n* 单进程32位机最大使用内存2G， 64位机没有限制\n* 不能遍历里面存的所有item。 过于缓慢还会阻塞其他操作\n* memcache的高性能来源于两个阶段的hash结构，第一个阶段客户端通过key值算出一个节点，第二阶段在服务端查找item并返回客户端\n\n## Redis\n![redis](redis.png)\n可以使用复制特性来扩展读性能， 主从备份\n可以通过客户端分片提高些性能\n读性能能到11万次每秒\n写性能能到81000次每秒\n支持操作原子性和几个操作合起来之后的原子性\n1. 可以多个库， 最多16个， 数据能移动\n2. 支持事务\nmulti开启事务， 所有操作会被加入队列中\nexec开始执行\ndiscard相当于rollback\n\n### 五种数据类型\n1. 字符串（String）\nvalue最大长度512M\n二进制安全的， 存入和获取数据相同\nincr num 如果num不存在num默认为1， 之后incr递增。 还可以使用incrby。 如果不是整型就报错\n2. 哈希（hash）\n3. 字符串列表（list）\n能在链表的头和尾插入和删除元素， 效率高。\n可以使用arraylist方式存\n或者linkedlist方式， 双向链表\n可以用于消息队列的服务， 实现多个程序消息交互。rpoplpush, 实现一个备份队列， 防止消息没有被消费成功\n4. 字符串集合（set）\n不允许出现重复元素\n差集运算 sdiff, 交集运算 sinter， 并集运算 sunion\n唯一性场景（唯一的ip）， 数据集关联关系场景\n5. 有序字符串集合（sorted set）\n每一个成员都有一个分数关联用来排序， 成员值不能相同， 但是分数可以相同。 因为有序所以即使访问集合中部的成员也比较高效\n游戏排名，构建索引数据， 微博热点可以用到。\n \n### 持久化的方式\n1. RDB方式\n默认支持，不需要配置， 在指定时间间隔内将内存中的数据及快照写入到磁盘。\n优势： 灾难恢复容易， 启动效率更好\n劣势： 写之前宕机， 数据就丢失了， 不能保证高可用； 因为通过子进程分叉的方式持久化， 数据量大的时候可能导致系统停止几百毫秒。\n配置： save 60 10000 意思是每一分钟至少10000个key有变化就持久化一次\t \n2. AOF方式\n将以日志的方式记录服务器每一个操作， *在redis服务器启动之初会读取该文件重新构建数据库*。 保证启动后数据库中的数据是完整的。\n优势： 更高的数据安全性， 数据一致性问题\n劣势： aof文件比rdb文件大。 运行效率比较低\n配置： appendonly no默认不打开 同步策略可以修改为always（每次修改同步一次, everysec(每秒同步一次)\n3. 不持久化\n4. 同时使用RDB AOF\n\n","source":"_posts/缓存学习笔记.md","raw":"---\ntitle: 缓存学习笔记\ndate: 2018-10-09 13:41:14\ntags:\n---\n\n# 缓存特征\n* 命中率： 命中数/(命中数+没有命中数)\n* 最大元素（空间）\n\n一旦数据超过最大元素将会触发缓存情况策略， 需要合理设置最大元素数量， 提高命中率和效率\n* 清空策略： FIFO, LFU, LRU, 过期时间， 随机等\n\nFIFO： 最先进入的数据当缓存不够， 或者达到最大元素限制时候会优先被清除掉， 主要比较元素的创建时间， \t在数据实时性要求场景下可以选择该策略， 优先保证最新数据可用\n\nLFU： 无论是否过期， 根据元素使用次数来判断， 清除使用次数最少的元素来释放空间， 主要比较元素的命中次数，在保证高频数据有效性场景下可以使用\n\nLRU： 无论是否过期， 比较元素最近get时间， 删除最远使用的元素。 在热点数据场景下较适用\n\n# 影响缓存命中率的因素\n* 业务场景和业务需求： 适合读多写少的业务场景， 实时性越低越适合缓存\n* 缓存的设计（粒度和策略）： 粒度越小命中率就会越高， 更新缓存比移除命中率更高， 但是系统复杂度更高\n* 缓存的容量和基础设施： 应用内置的缓存比较容易出现单击瓶颈， 分布式缓存更容易扩展。 所以需要做好系统容量规划， 并考虑是否可扩展\n单个节点出现故障的时候， 需要避免缓存失效， 最大程度降低影响。 可通过一致性哈希算法和节点冗余的方式来避免这个问题\n\n从架构师角度为了提高缓存命中率： \n竟可能多的从缓存获取数据并避免缓存失效， 这比较考验架构师能力， 需要从业务需求， 缓存粒度， 缓存策略， 技术选型等方面通盘考虑权衡。 竟可能聚焦在高频访问并时效性要求不高的热点业务上。 通过缓存预加载（预热）， 增加存储容量， 调整缓存粒度， 更新缓存等方法来提高命中率。\n\n## 缓存分类和应用场景\n * 本地缓存： 编程实现（成员变量， 局部变量， 静态变量）、 Guava Cache\n * 分布式缓存： Memcache、 Redis\n\n## Guava Cache\n![Guava Cache](GuavaCache.png)\n继承了ConcurrentHashMap的思路， 使用多个segment方式的细粒度锁保证线程安全和高并发的需求。 key被封装在weak reference引用中。 value被封装在weak或者soft reference引用中。 可以统计命中率， 异常率等统计数据\n\n## Memcache\n![memcache](memcache.png)\n应用广的开源分布式缓存产品， 本身不支持， cache的分布式主要在客户端实现。 客户端路由（一致性哈希算法）， 除了计算key的哈希值还计算每个mencahce server节点的哈希值。 \n通过查找哈希值大于key对应的hash值的最小server作为存储该key的目标server。 \n如果找不到直接把最小哈希值的server作为目标server， 增加删除单个节点不会对集群有大的影响。\n增加了虚拟节点的设计进一步提高可用性。\n\n\n### memcache内存结构\nmemcache是一个高效的分布式内存cache， 了解内存结构能更高根据数据特点进行调优。\n![memcache2](memcache2.png)\n每个slab有多个page， page默认大小为1M。 同一个slab中的chunk大小一定。 相同大小chunk的slab被组织在一起称为slab_class。\nmemcache内存分配的方式为allocater， slab数量有限和启动参数有关。 相邻slab的chunk大小基本按1.25比例增长（启动时-f 设定）。 \n放slab时候， slab以page为单位申请内存， page再按chunk大小进行切分， 得到chunk数组来存数据。 \n如果没有chunk了， 进行LRU把最近最少使用的chunk中的数据清理掉。 \n\n* chunk中总会有内存浪费\n* memcache的LRU算法不是针对全局， 只是针对slab的\n* memcache只会以page（1M）的大小申请内存， 对新数据大小有限制， key最大为250个字节\n* 单进程32位机最大使用内存2G， 64位机没有限制\n* 不能遍历里面存的所有item。 过于缓慢还会阻塞其他操作\n* memcache的高性能来源于两个阶段的hash结构，第一个阶段客户端通过key值算出一个节点，第二阶段在服务端查找item并返回客户端\n\n## Redis\n![redis](redis.png)\n可以使用复制特性来扩展读性能， 主从备份\n可以通过客户端分片提高些性能\n读性能能到11万次每秒\n写性能能到81000次每秒\n支持操作原子性和几个操作合起来之后的原子性\n1. 可以多个库， 最多16个， 数据能移动\n2. 支持事务\nmulti开启事务， 所有操作会被加入队列中\nexec开始执行\ndiscard相当于rollback\n\n### 五种数据类型\n1. 字符串（String）\nvalue最大长度512M\n二进制安全的， 存入和获取数据相同\nincr num 如果num不存在num默认为1， 之后incr递增。 还可以使用incrby。 如果不是整型就报错\n2. 哈希（hash）\n3. 字符串列表（list）\n能在链表的头和尾插入和删除元素， 效率高。\n可以使用arraylist方式存\n或者linkedlist方式， 双向链表\n可以用于消息队列的服务， 实现多个程序消息交互。rpoplpush, 实现一个备份队列， 防止消息没有被消费成功\n4. 字符串集合（set）\n不允许出现重复元素\n差集运算 sdiff, 交集运算 sinter， 并集运算 sunion\n唯一性场景（唯一的ip）， 数据集关联关系场景\n5. 有序字符串集合（sorted set）\n每一个成员都有一个分数关联用来排序， 成员值不能相同， 但是分数可以相同。 因为有序所以即使访问集合中部的成员也比较高效\n游戏排名，构建索引数据， 微博热点可以用到。\n \n### 持久化的方式\n1. RDB方式\n默认支持，不需要配置， 在指定时间间隔内将内存中的数据及快照写入到磁盘。\n优势： 灾难恢复容易， 启动效率更好\n劣势： 写之前宕机， 数据就丢失了， 不能保证高可用； 因为通过子进程分叉的方式持久化， 数据量大的时候可能导致系统停止几百毫秒。\n配置： save 60 10000 意思是每一分钟至少10000个key有变化就持久化一次\t \n2. AOF方式\n将以日志的方式记录服务器每一个操作， *在redis服务器启动之初会读取该文件重新构建数据库*。 保证启动后数据库中的数据是完整的。\n优势： 更高的数据安全性， 数据一致性问题\n劣势： aof文件比rdb文件大。 运行效率比较低\n配置： appendonly no默认不打开 同步策略可以修改为always（每次修改同步一次, everysec(每秒同步一次)\n3. 不持久化\n4. 同时使用RDB AOF\n\n","slug":"缓存学习笔记","published":1,"updated":"2018-11-13T11:50:06.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjofoeav9000kd922y6mmq4by","content":"<h1 id=\"缓存特征\"><a href=\"#缓存特征\" class=\"headerlink\" title=\"缓存特征\"></a>缓存特征</h1><ul>\n<li>命中率： 命中数/(命中数+没有命中数)</li>\n<li>最大元素（空间）</li>\n</ul>\n<p>一旦数据超过最大元素将会触发缓存情况策略， 需要合理设置最大元素数量， 提高命中率和效率</p>\n<ul>\n<li>清空策略： FIFO, LFU, LRU, 过期时间， 随机等</li>\n</ul>\n<p>FIFO： 最先进入的数据当缓存不够， 或者达到最大元素限制时候会优先被清除掉， 主要比较元素的创建时间，     在数据实时性要求场景下可以选择该策略， 优先保证最新数据可用</p>\n<p>LFU： 无论是否过期， 根据元素使用次数来判断， 清除使用次数最少的元素来释放空间， 主要比较元素的命中次数，在保证高频数据有效性场景下可以使用</p>\n<p>LRU： 无论是否过期， 比较元素最近get时间， 删除最远使用的元素。 在热点数据场景下较适用</p>\n<h1 id=\"影响缓存命中率的因素\"><a href=\"#影响缓存命中率的因素\" class=\"headerlink\" title=\"影响缓存命中率的因素\"></a>影响缓存命中率的因素</h1><ul>\n<li>业务场景和业务需求： 适合读多写少的业务场景， 实时性越低越适合缓存</li>\n<li>缓存的设计（粒度和策略）： 粒度越小命中率就会越高， 更新缓存比移除命中率更高， 但是系统复杂度更高</li>\n<li>缓存的容量和基础设施： 应用内置的缓存比较容易出现单击瓶颈， 分布式缓存更容易扩展。 所以需要做好系统容量规划， 并考虑是否可扩展<br>单个节点出现故障的时候， 需要避免缓存失效， 最大程度降低影响。 可通过一致性哈希算法和节点冗余的方式来避免这个问题</li>\n</ul>\n<p>从架构师角度为了提高缓存命中率：<br>竟可能多的从缓存获取数据并避免缓存失效， 这比较考验架构师能力， 需要从业务需求， 缓存粒度， 缓存策略， 技术选型等方面通盘考虑权衡。 竟可能聚焦在高频访问并时效性要求不高的热点业务上。 通过缓存预加载（预热）， 增加存储容量， 调整缓存粒度， 更新缓存等方法来提高命中率。</p>\n<h2 id=\"缓存分类和应用场景\"><a href=\"#缓存分类和应用场景\" class=\"headerlink\" title=\"缓存分类和应用场景\"></a>缓存分类和应用场景</h2><ul>\n<li>本地缓存： 编程实现（成员变量， 局部变量， 静态变量）、 Guava Cache</li>\n<li>分布式缓存： Memcache、 Redis</li>\n</ul>\n<h2 id=\"Guava-Cache\"><a href=\"#Guava-Cache\" class=\"headerlink\" title=\"Guava Cache\"></a>Guava Cache</h2><p><img src=\"GuavaCache.png\" alt=\"Guava Cache\"><br>继承了ConcurrentHashMap的思路， 使用多个segment方式的细粒度锁保证线程安全和高并发的需求。 key被封装在weak reference引用中。 value被封装在weak或者soft reference引用中。 可以统计命中率， 异常率等统计数据</p>\n<h2 id=\"Memcache\"><a href=\"#Memcache\" class=\"headerlink\" title=\"Memcache\"></a>Memcache</h2><p><img src=\"memcache.png\" alt=\"memcache\"><br>应用广的开源分布式缓存产品， 本身不支持， cache的分布式主要在客户端实现。 客户端路由（一致性哈希算法）， 除了计算key的哈希值还计算每个mencahce server节点的哈希值。<br>通过查找哈希值大于key对应的hash值的最小server作为存储该key的目标server。<br>如果找不到直接把最小哈希值的server作为目标server， 增加删除单个节点不会对集群有大的影响。<br>增加了虚拟节点的设计进一步提高可用性。</p>\n<h3 id=\"memcache内存结构\"><a href=\"#memcache内存结构\" class=\"headerlink\" title=\"memcache内存结构\"></a>memcache内存结构</h3><p>memcache是一个高效的分布式内存cache， 了解内存结构能更高根据数据特点进行调优。<br><img src=\"memcache2.png\" alt=\"memcache2\"><br>每个slab有多个page， page默认大小为1M。 同一个slab中的chunk大小一定。 相同大小chunk的slab被组织在一起称为slab_class。<br>memcache内存分配的方式为allocater， slab数量有限和启动参数有关。 相邻slab的chunk大小基本按1.25比例增长（启动时-f 设定）。<br>放slab时候， slab以page为单位申请内存， page再按chunk大小进行切分， 得到chunk数组来存数据。<br>如果没有chunk了， 进行LRU把最近最少使用的chunk中的数据清理掉。 </p>\n<ul>\n<li>chunk中总会有内存浪费</li>\n<li>memcache的LRU算法不是针对全局， 只是针对slab的</li>\n<li>memcache只会以page（1M）的大小申请内存， 对新数据大小有限制， key最大为250个字节</li>\n<li>单进程32位机最大使用内存2G， 64位机没有限制</li>\n<li>不能遍历里面存的所有item。 过于缓慢还会阻塞其他操作</li>\n<li>memcache的高性能来源于两个阶段的hash结构，第一个阶段客户端通过key值算出一个节点，第二阶段在服务端查找item并返回客户端</li>\n</ul>\n<h2 id=\"Redis\"><a href=\"#Redis\" class=\"headerlink\" title=\"Redis\"></a>Redis</h2><p><img src=\"redis.png\" alt=\"redis\"><br>可以使用复制特性来扩展读性能， 主从备份<br>可以通过客户端分片提高些性能<br>读性能能到11万次每秒<br>写性能能到81000次每秒<br>支持操作原子性和几个操作合起来之后的原子性</p>\n<ol>\n<li>可以多个库， 最多16个， 数据能移动</li>\n<li>支持事务<br>multi开启事务， 所有操作会被加入队列中<br>exec开始执行<br>discard相当于rollback</li>\n</ol>\n<h3 id=\"五种数据类型\"><a href=\"#五种数据类型\" class=\"headerlink\" title=\"五种数据类型\"></a>五种数据类型</h3><ol>\n<li>字符串（String）<br>value最大长度512M<br>二进制安全的， 存入和获取数据相同<br>incr num 如果num不存在num默认为1， 之后incr递增。 还可以使用incrby。 如果不是整型就报错</li>\n<li>哈希（hash）</li>\n<li>字符串列表（list）<br>能在链表的头和尾插入和删除元素， 效率高。<br>可以使用arraylist方式存<br>或者linkedlist方式， 双向链表<br>可以用于消息队列的服务， 实现多个程序消息交互。rpoplpush, 实现一个备份队列， 防止消息没有被消费成功</li>\n<li>字符串集合（set）<br>不允许出现重复元素<br>差集运算 sdiff, 交集运算 sinter， 并集运算 sunion<br>唯一性场景（唯一的ip）， 数据集关联关系场景</li>\n<li>有序字符串集合（sorted set）<br>每一个成员都有一个分数关联用来排序， 成员值不能相同， 但是分数可以相同。 因为有序所以即使访问集合中部的成员也比较高效<br>游戏排名，构建索引数据， 微博热点可以用到。</li>\n</ol>\n<h3 id=\"持久化的方式\"><a href=\"#持久化的方式\" class=\"headerlink\" title=\"持久化的方式\"></a>持久化的方式</h3><ol>\n<li>RDB方式<br>默认支持，不需要配置， 在指定时间间隔内将内存中的数据及快照写入到磁盘。<br>优势： 灾难恢复容易， 启动效率更好<br>劣势： 写之前宕机， 数据就丢失了， 不能保证高可用； 因为通过子进程分叉的方式持久化， 数据量大的时候可能导致系统停止几百毫秒。<br>配置： save 60 10000 意思是每一分钟至少10000个key有变化就持久化一次     </li>\n<li>AOF方式<br>将以日志的方式记录服务器每一个操作， <em>在redis服务器启动之初会读取该文件重新构建数据库</em>。 保证启动后数据库中的数据是完整的。<br>优势： 更高的数据安全性， 数据一致性问题<br>劣势： aof文件比rdb文件大。 运行效率比较低<br>配置： appendonly no默认不打开 同步策略可以修改为always（每次修改同步一次, everysec(每秒同步一次)</li>\n<li>不持久化</li>\n<li>同时使用RDB AOF</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"缓存特征\"><a href=\"#缓存特征\" class=\"headerlink\" title=\"缓存特征\"></a>缓存特征</h1><ul>\n<li>命中率： 命中数/(命中数+没有命中数)</li>\n<li>最大元素（空间）</li>\n</ul>\n<p>一旦数据超过最大元素将会触发缓存情况策略， 需要合理设置最大元素数量， 提高命中率和效率</p>\n<ul>\n<li>清空策略： FIFO, LFU, LRU, 过期时间， 随机等</li>\n</ul>\n<p>FIFO： 最先进入的数据当缓存不够， 或者达到最大元素限制时候会优先被清除掉， 主要比较元素的创建时间，     在数据实时性要求场景下可以选择该策略， 优先保证最新数据可用</p>\n<p>LFU： 无论是否过期， 根据元素使用次数来判断， 清除使用次数最少的元素来释放空间， 主要比较元素的命中次数，在保证高频数据有效性场景下可以使用</p>\n<p>LRU： 无论是否过期， 比较元素最近get时间， 删除最远使用的元素。 在热点数据场景下较适用</p>\n<h1 id=\"影响缓存命中率的因素\"><a href=\"#影响缓存命中率的因素\" class=\"headerlink\" title=\"影响缓存命中率的因素\"></a>影响缓存命中率的因素</h1><ul>\n<li>业务场景和业务需求： 适合读多写少的业务场景， 实时性越低越适合缓存</li>\n<li>缓存的设计（粒度和策略）： 粒度越小命中率就会越高， 更新缓存比移除命中率更高， 但是系统复杂度更高</li>\n<li>缓存的容量和基础设施： 应用内置的缓存比较容易出现单击瓶颈， 分布式缓存更容易扩展。 所以需要做好系统容量规划， 并考虑是否可扩展<br>单个节点出现故障的时候， 需要避免缓存失效， 最大程度降低影响。 可通过一致性哈希算法和节点冗余的方式来避免这个问题</li>\n</ul>\n<p>从架构师角度为了提高缓存命中率：<br>竟可能多的从缓存获取数据并避免缓存失效， 这比较考验架构师能力， 需要从业务需求， 缓存粒度， 缓存策略， 技术选型等方面通盘考虑权衡。 竟可能聚焦在高频访问并时效性要求不高的热点业务上。 通过缓存预加载（预热）， 增加存储容量， 调整缓存粒度， 更新缓存等方法来提高命中率。</p>\n<h2 id=\"缓存分类和应用场景\"><a href=\"#缓存分类和应用场景\" class=\"headerlink\" title=\"缓存分类和应用场景\"></a>缓存分类和应用场景</h2><ul>\n<li>本地缓存： 编程实现（成员变量， 局部变量， 静态变量）、 Guava Cache</li>\n<li>分布式缓存： Memcache、 Redis</li>\n</ul>\n<h2 id=\"Guava-Cache\"><a href=\"#Guava-Cache\" class=\"headerlink\" title=\"Guava Cache\"></a>Guava Cache</h2><p><img src=\"GuavaCache.png\" alt=\"Guava Cache\"><br>继承了ConcurrentHashMap的思路， 使用多个segment方式的细粒度锁保证线程安全和高并发的需求。 key被封装在weak reference引用中。 value被封装在weak或者soft reference引用中。 可以统计命中率， 异常率等统计数据</p>\n<h2 id=\"Memcache\"><a href=\"#Memcache\" class=\"headerlink\" title=\"Memcache\"></a>Memcache</h2><p><img src=\"memcache.png\" alt=\"memcache\"><br>应用广的开源分布式缓存产品， 本身不支持， cache的分布式主要在客户端实现。 客户端路由（一致性哈希算法）， 除了计算key的哈希值还计算每个mencahce server节点的哈希值。<br>通过查找哈希值大于key对应的hash值的最小server作为存储该key的目标server。<br>如果找不到直接把最小哈希值的server作为目标server， 增加删除单个节点不会对集群有大的影响。<br>增加了虚拟节点的设计进一步提高可用性。</p>\n<h3 id=\"memcache内存结构\"><a href=\"#memcache内存结构\" class=\"headerlink\" title=\"memcache内存结构\"></a>memcache内存结构</h3><p>memcache是一个高效的分布式内存cache， 了解内存结构能更高根据数据特点进行调优。<br><img src=\"memcache2.png\" alt=\"memcache2\"><br>每个slab有多个page， page默认大小为1M。 同一个slab中的chunk大小一定。 相同大小chunk的slab被组织在一起称为slab_class。<br>memcache内存分配的方式为allocater， slab数量有限和启动参数有关。 相邻slab的chunk大小基本按1.25比例增长（启动时-f 设定）。<br>放slab时候， slab以page为单位申请内存， page再按chunk大小进行切分， 得到chunk数组来存数据。<br>如果没有chunk了， 进行LRU把最近最少使用的chunk中的数据清理掉。 </p>\n<ul>\n<li>chunk中总会有内存浪费</li>\n<li>memcache的LRU算法不是针对全局， 只是针对slab的</li>\n<li>memcache只会以page（1M）的大小申请内存， 对新数据大小有限制， key最大为250个字节</li>\n<li>单进程32位机最大使用内存2G， 64位机没有限制</li>\n<li>不能遍历里面存的所有item。 过于缓慢还会阻塞其他操作</li>\n<li>memcache的高性能来源于两个阶段的hash结构，第一个阶段客户端通过key值算出一个节点，第二阶段在服务端查找item并返回客户端</li>\n</ul>\n<h2 id=\"Redis\"><a href=\"#Redis\" class=\"headerlink\" title=\"Redis\"></a>Redis</h2><p><img src=\"redis.png\" alt=\"redis\"><br>可以使用复制特性来扩展读性能， 主从备份<br>可以通过客户端分片提高些性能<br>读性能能到11万次每秒<br>写性能能到81000次每秒<br>支持操作原子性和几个操作合起来之后的原子性</p>\n<ol>\n<li>可以多个库， 最多16个， 数据能移动</li>\n<li>支持事务<br>multi开启事务， 所有操作会被加入队列中<br>exec开始执行<br>discard相当于rollback</li>\n</ol>\n<h3 id=\"五种数据类型\"><a href=\"#五种数据类型\" class=\"headerlink\" title=\"五种数据类型\"></a>五种数据类型</h3><ol>\n<li>字符串（String）<br>value最大长度512M<br>二进制安全的， 存入和获取数据相同<br>incr num 如果num不存在num默认为1， 之后incr递增。 还可以使用incrby。 如果不是整型就报错</li>\n<li>哈希（hash）</li>\n<li>字符串列表（list）<br>能在链表的头和尾插入和删除元素， 效率高。<br>可以使用arraylist方式存<br>或者linkedlist方式， 双向链表<br>可以用于消息队列的服务， 实现多个程序消息交互。rpoplpush, 实现一个备份队列， 防止消息没有被消费成功</li>\n<li>字符串集合（set）<br>不允许出现重复元素<br>差集运算 sdiff, 交集运算 sinter， 并集运算 sunion<br>唯一性场景（唯一的ip）， 数据集关联关系场景</li>\n<li>有序字符串集合（sorted set）<br>每一个成员都有一个分数关联用来排序， 成员值不能相同， 但是分数可以相同。 因为有序所以即使访问集合中部的成员也比较高效<br>游戏排名，构建索引数据， 微博热点可以用到。</li>\n</ol>\n<h3 id=\"持久化的方式\"><a href=\"#持久化的方式\" class=\"headerlink\" title=\"持久化的方式\"></a>持久化的方式</h3><ol>\n<li>RDB方式<br>默认支持，不需要配置， 在指定时间间隔内将内存中的数据及快照写入到磁盘。<br>优势： 灾难恢复容易， 启动效率更好<br>劣势： 写之前宕机， 数据就丢失了， 不能保证高可用； 因为通过子进程分叉的方式持久化， 数据量大的时候可能导致系统停止几百毫秒。<br>配置： save 60 10000 意思是每一分钟至少10000个key有变化就持久化一次     </li>\n<li>AOF方式<br>将以日志的方式记录服务器每一个操作， <em>在redis服务器启动之初会读取该文件重新构建数据库</em>。 保证启动后数据库中的数据是完整的。<br>优势： 更高的数据安全性， 数据一致性问题<br>劣势： aof文件比rdb文件大。 运行效率比较低<br>配置： appendonly no默认不打开 同步策略可以修改为always（每次修改同步一次, everysec(每秒同步一次)</li>\n<li>不持久化</li>\n<li>同时使用RDB AOF</li>\n</ol>\n"}],"PostAsset":[{"_id":"source/_posts/缓存学习笔记/memcache.png","slug":"memcache.png","post":"cjofoeav9000kd922y6mmq4by","modified":0,"renderable":0},{"_id":"source/_posts/Hexo-blog-framework/github_config.png","slug":"github_config.png","post":"cjofoeaue0000d922bhwxv17r","modified":0,"renderable":0},{"_id":"source/_posts/monit报警邮件配置避坑/stmp.png","slug":"stmp.png","post":"cjofoeaun0003d922rs8e5ion","modified":0,"renderable":0},{"_id":"source/_posts/线程安全性-可见性/reorder_read.png","slug":"reorder_read.png","post":"cjofoeav6000hd922i093b3c0","modified":0,"renderable":0},{"_id":"source/_posts/线程安全性-可见性/reorder_write.png","slug":"reorder_write.png","post":"cjofoeav6000hd922i093b3c0","modified":0,"renderable":0},{"_id":"source/_posts/并发基本概念/JMM.png","slug":"JMM.png","post":"cjofoeauw0009d922ppjuarv4","modified":0,"renderable":0},{"_id":"source/_posts/并发基本概念/JMM_caozuo.png","slug":"JMM_caozuo.png","post":"cjofoeauw0009d922ppjuarv4","modified":0,"renderable":0},{"_id":"source/_posts/并发基本概念/MESI_protocal.jpg","slug":"MESI_protocal.jpg","post":"cjofoeauw0009d922ppjuarv4","modified":0,"renderable":0},{"_id":"source/_posts/并发基本概念/ad_disad.png","slug":"ad_disad.png","post":"cjofoeauw0009d922ppjuarv4","modified":0,"renderable":0},{"_id":"source/_posts/缓存学习笔记/GuavaCache.png","slug":"GuavaCache.png","post":"cjofoeav9000kd922y6mmq4by","modified":0,"renderable":0},{"_id":"source/_posts/缓存学习笔记/memcache2.png","slug":"memcache2.png","post":"cjofoeav9000kd922y6mmq4by","modified":0,"renderable":0},{"_id":"source/_posts/缓存学习笔记/redis.png","slug":"redis.png","post":"cjofoeav9000kd922y6mmq4by","modified":0,"renderable":0}],"PostCategory":[],"PostTag":[],"Tag":[]}}